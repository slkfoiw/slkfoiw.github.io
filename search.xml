<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2024/06/28/deeplearning/question/"/>
      <url>/2024/06/28/deeplearning/question/</url>
      
        <content type="html"><![CDATA[<p>这里为什么要除以embedding向量的开方？（似乎好多地方求embedding都有这个操作</p><p><img src="/../../images%5Ctmp%5Cimage-20240504102504742.png" alt="image-20240504102504742"></p><p>oake模块下base.py文件中Validator类有什么作用呢？我看了论文，这个模块里的objects.py、globals.py、blocks.py应该是三个蒸馏吧，三个文件里都继承了base.py里的DataSet类和Validator类。这三个文件里的DataSet类已经实现了蒸馏的图像处理部分，可是没懂这个Validator类在做什么。</p><p><img src="/../..%5Cimages%5Ctmp%5Cimage-20240504181309157.png" alt="image-20240504181309157"></p><p>oadp&#x2F;oake&#x2F;objects.py里Dataset类的_expand方法有什么用？为什么要扩大bbox，而且还分了很多种扩大模式？</p><p><img src="/../..%5Cimages%5Ctmp%5Cimage-20240505105718481.png" alt="image-20240505105718481"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>OO第三单元总结</title>
      <link href="/2024/06/11/oo/2024-06-11-oo-unit4-summary/"/>
      <url>/2024/06/11/oo/2024-06-11-oo-unit4-summary/</url>
      
        <content type="html"><![CDATA[<h1 id="正向建模与开发"><a href="#正向建模与开发" class="headerlink" title="正向建模与开发"></a>正向建模与开发</h1><p>根据指导书给出的需求：</p><ol><li>首先肯定需要有一个图书馆，图书馆承担着处理请求的任务，并需要记录所有图书、用户的信息。</li><li>图书馆里要有书架、借还处、预定处、用户以及之后作业引入的漂流角这些对象<ul><li>书籍就在这些对象之间流动，所以这些对象里需要一个装着书籍信息的容器。</li><li>需要接收图书、移除图书的动作。参考实验课的提示，我让书架、借还处、预定处、漂流角都通过与图书馆通信来完成，而不直接互相通信，这样每个地方都抽象出来接收图书、移除图书的两个动作，可扩展性强。</li></ul></li><li>由于预约处要保留预约信息，所以我额外设计了一个类，该类的每个对象存储一条预约信息</li></ol><h1 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h1><h2 id="第一次作业"><a href="#第一次作业" class="headerlink" title="第一次作业"></a>第一次作业</h2><ul><li>图书馆类下管理着一个书架、借还处、预定处以及所有书本、用户，对于每种请求都有对应的一个方法去处理</li><li>书架、借还处、预定处、用户类中有一个管理图书的容器，并有相应的增删图书的方法。第一次作业我用的HashMap存储图书及其数量，也就是说每种图书的所有副本共用一个对象，value来记录副本数量，这样扩展性较差，后续作业有所修改</li><li>不同位置不直接通信，而是通过图书馆来移动图书</li><li>图书对象的一致性问题：由于每次读入的请求中的图书都是一个新的对象，但在书架、借还处、预定处、用户间流动的图书应该是图书馆里管理的图书，所以我用了一个checkBookId的方法，返回图书馆里的图书对象的引用。</li></ul><p><img src="/../../images/OO/unit4-1.jpg" alt="unit4-1"></p><h2 id="第二次作业"><a href="#第二次作业" class="headerlink" title="第二次作业"></a>第二次作业</h2><p>根据新增加的需求：</p><ol><li>增加了漂流角类，属性和方法与书架、借还处、预定处这些类似</li><li>图书馆里增加新请求类型的处理方法和整理图书的方法</li><li>新增加了图书借阅期限，所以官方包里的LibraryBookId无法满足需求，于是新建了一个继承自LibraryBookId的Book类，记录每本书的借还时间</li><li>图书管理容器的修改：由于第二次作业，每个图书副本可能会具有不同的属性，例如借阅次数、借阅日期、归还日期，所以原本的HashMap容器不能满足副本之间的差异管理，于是改用ArrayList，每个副本都对应一个图书对象。</li></ol><p><img src="/../../images/OO/unit4-2.jpg" alt="unit4-2"></p><h2 id="第三次作业"><a href="#第三次作业" class="headerlink" title="第三次作业"></a>第三次作业</h2><p>第三次作业的需求较为简单，几乎不需要怎么动架构，只需要在用户类（即Student）里增加积分属性和相应的调整动作即可，然后根据指导书添加处理方法，在恰当的时候调整用户的积分即可，不过还是有一些细节需要注意：</p><ol><li>积分有上限，这意味着不同的增、减顺序会导致积分结果不一样，最开始我忽略了这一点，不过改正也很简单，只要保证先减后增就行了</li><li>积分为负才不能借阅、预约，而不是非正，也是刚开始没注意的点</li></ol><p><img src="/../../images/OO/unit4-3.jpg" alt="unit4-3"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="架构设计思维的演进"><a href="#架构设计思维的演进" class="headerlink" title="架构设计思维的演进"></a>架构设计思维的演进</h2><p>第一单元表达式的架构设计是让我对面向过程和面向对象的两者区别有最深体会的时候，表达式处理所涉及到的递归下降和c语言里的递归函数很像，实验课给了一个很好的架构参考，让我对“递归”在面向对象里的应用有了具象化的认识。</p><p>第二单元电梯的设计学习到了多线程的相关知识，与同步进行的OS很多知识相呼应，让我对线程间通信、生产者-消费者这样的问题有了更深的印象，也帮助了我第四单元的架构设计。</p><p>第三单元的JML和第四单元的UML主要是对设计方面的训练，JML让我了解了规格化设计的过程，它很好的避免了二义性，并且给测试提供了思路。UML虽然作为一个单独的单元，但其实一直贯穿整个课程，每次作业之前都会画个粗略的类图帮助我理清思路，不过之前不太清楚每种元素的作用，连线比较随意，这个单元就更规范化了，并且还学习了状态图、顺序图，相信这些知识都会在未来帮助我更好地规范设计。</p><p>总的来说，随着课程的深入，我对面向对象有了更清晰的认知，在了解了SOLID原则后，每次我的架构设计都尽可能往这上面靠，虽然可能并不完美，但是比学期初的我一定是有很大不同的。</p><h2 id="测试思维的演进"><a href="#测试思维的演进" class="headerlink" title="测试思维的演进"></a>测试思维的演进</h2><p>我的测试思维演进应该说是一个从手动构造数据，到自动化评测，再到发现两者缺一不可的过程。首先，这学期我学会了自动化测试，在上学期的OOpre课程我只会手动构造数据，但这学期的作业仅靠手动构造数据是肯定不够的。</p><p>第一单元我实现了一个比较完整的评测机，数据生成器部分比较难写，正确性的检验倒是挺好实现的。而到第二单元的时候就是数据生成器部分容易实现，而正确性检验比较难了，由于本人能力有限再加上时间不够，所以基本都是靠大佬的评测机活过来的（超级感谢）。第三单元又学会了Junit单元测试，上学期的OOpre课程已经有涉及，但当时我不能理解其妙义，这学期发现它和JML结合一起倒是非常好用。第四单元相对重视架构设计，所以在测试方面没有其他的变化。</p><p>在这门课程中，我测试思维上最大的收获就是一定要格外重视高并发的情况，也是这个点让我觉得手动构造数据和自动化随机生成数据二者缺一不可。在第二单元，我发现仅靠评测机的随机数据是不行的，必须考虑一些高并发的极端情况，尤其是到了第三单元，这种现象也很明显，这让我意识到手动构造一些极端情况的数据也是十分有必要的。这两个单元都让我对高并发有了深刻的认识，想起之前老师在课上提到的12306，此刻对这个例子有了具象化的认知，以前的我只会觉得12306挺难用的，但现在从设计者的角度再看，不禁感叹12306要承担起节假日、春运时海量的访问还不崩，真的太不容易了。所以高并发在实际项目、工程中也是关键点，在以后的设计中，我也会把这点牢记在心，把极端情况考虑在内。</p><h2 id="课程收获"><a href="#课程收获" class="headerlink" title="课程收获"></a>课程收获</h2><ol><li>锻炼了我写代码、调试的能力。多线程单元debug的时候虽然痛苦，但收获颇丰。</li><li>掌握了Java这门面向对象的语言。不仅学习了多线程、递归下降等知识，还学习到了很多设计方法、设计原则。</li><li>每个单元迭代式的开发，让我学会了先设计再实现的开发方式。好的架构设计确实能提高效率，在实际应用中也能提高项目扩展性，方便增加需求。</li><li>学会了自动化测试、单元测试等测试方法，对高并发的处理有了深刻认识。</li></ol>]]></content>
      
      
      <categories>
          
          <category> OO </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>文件系统</title>
      <link href="/2024/05/27/os/2024-05-27-os-file-system/"/>
      <url>/2024/05/27/os/2024-05-27-os-file-system/</url>
      
        <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>为什么不定义为指针，是因为这是要写入文件的数据，如果你在程序运行的时候构建了这个链表，计算出了当前next的地址（实际上是主存的地址）然后写入辅存，可能下次把这些数据调入主存的时候就不在这个地址了。</p><p>文件管理的要求</p><p>用户视角：使用<strong>逻辑文件</strong>，即内容是什么</p><p>操作系统视角：组织和管理<strong>物理文件</strong>，即怎么存</p><p>按逻辑结构分：有结构文件（由记录组成，分为定长记录、可变长记录）、无结构文件（由二进制流或字符流组成，无明显的逻辑结构）</p><p>按文件中物理结构分：顺序文件、链接文件、索引文件</p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>也是文件，是由文件说明索引组成的用于文件检索的特殊文件，文件目录的内容是文件访问和控制的信息（不包括文件内容）。</p><h3 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h3><ol><li><p>基本信息：文件名</p></li><li><p>文件类型：</p><ul><li><p>有&#x2F;无结构（记录文件，流式文件）;</p></li><li><p>内容（二进制，文本）</p></li><li><p>用途（源代码，目标代码，可执行文件，数据）</p></li><li><p>属性attribute（如系统，隐含等）</p></li><li><p>文件组织（如顺序，索引等）</p></li></ul></li><li><p>地址信息：存放位置、文件长度</p></li><li><p>访问控制信息：文件所有者、访问权限</p></li><li><p>使用信息：创建时间、最后一次读&#x2F;写访问的时间和用户</p></li></ol><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>单级目录</p><p>两级目录</p><p>多级目录</p><h1 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h1><h2 id="文件控制块"><a href="#文件控制块" class="headerlink" title="文件控制块"></a>文件控制块</h2><p><strong>基本信息</strong></p><ul><li>文件名：字符串，通常在不同系统中允许不同的最大长度，可修改</li><li>物理位置；</li><li>文件逻辑结构：有&#x2F;无结构（记录文件，流式文件）</li><li>文件物理结构：（如顺序，索引等）</li></ul><p><strong>访问控制信息</strong></p><ul><li>文件所有者（属主）：通常是创建文件的用户，或者改变已有文件的属主；</li><li>访问权限（控制各用户可使用的访问方式）：如读、写、执行、删除等；</li></ul><p><strong>使用信息</strong></p><p>创建时间，上一次修改时间，当前使用信息等。</p><h2 id="文件物理结构"><a href="#文件物理结构" class="headerlink" title="文件物理结构"></a>文件物理结构</h2><h3 id="顺序-连续结构"><a href="#顺序-连续结构" class="headerlink" title="顺序&#x2F;连续结构"></a>顺序&#x2F;连续结构</h3><p>容易出现磁盘碎片，适用于变化不大的文件</p><h3 id="串联-链接文件"><a href="#串联-链接文件" class="headerlink" title="串联&#x2F;链接文件"></a>串联&#x2F;链接文件</h3><p>随机存取效率太低，如果访问文件的最后的内容，实际上是要访问整个文件。</p><p>可靠性问题，如指针出错;</p><p>链接指针占用一定的空间</p><h3 id="索引结构"><a href="#索引结构" class="headerlink" title="索引结构"></a>索引结构</h3><p>一个文件的信息存放在若干个不连续物理块中。系统为每个文件建立一个专用数据结构：索引表，并将这些物理块的块号存放在该索引中。索引表就是磁盘块地址数组，其中第i个条目指向文件的第i块</p><p>索引表可放在文件目录中、文件的开头等</p><p>索引文件在存储区中占两个区：索引区和数据区。索引区存放索引表，数据区存放数据文件本身。</p><p>访问索引文件需要两步操作：</p><ol><li>读取文件索引区，由逻辑块号查得物理块号</li><li>访问物理块号而获得所需信息</li></ol><p><strong>优点：</strong></p><ul><li>保持了链接结构的优点，又避免了其缺点</li><li>即能顺序存取，又能随机存取</li><li>满足了文件动态增长、插入删除的要求</li><li>能充分利用外存空间</li></ul><p><strong>缺点：</strong></p><p>索引表本身带来了系统开销，如：内外存空间，存取时间</p><h4 id="索引表的组织"><a href="#索引表的组织" class="headerlink" title="索引表的组织"></a>索引表的组织</h4><ul><li>链接模式：一个盘块一个索引表，多个索引表链接起来</li><li>多级索引（间接索引）：将一个大文件的所有索引表（二级索引)的地址放在另一个索引表（一级索引)中</li><li>综合模式：直接索引方式与间接索引方式结合</li></ul><h2 id="目录的实现"><a href="#目录的实现" class="headerlink" title="目录的实现"></a>目录的实现</h2><h3 id="目录项的内容"><a href="#目录项的内容" class="headerlink" title="目录项的内容"></a>目录项的内容</h3><ul><li>直接法：目录项＝文件名＋文件控制块（属性信息、在外存上的存放位置）。如MS-DOS&#x2F;Windows；</li><li>间接法：目录项＝文件名＋文件控制块的地址（索引号）。如Unix（inode）</li></ul><p>不管是何种方法，给定一个文件名，即可返回相应的文件信息</p><h3 id="长文件名问题"><a href="#长文件名问题" class="headerlink" title="长文件名问题"></a>长文件名问题</h3><p>方法1：在目录项中，将文件名的长度固定为255个字符。缺点：浪费空间，很少文件用很长的名字；</p><p>方法2：每个目录项的长度可变，分为三部分：目录项长度、文件的属性信息（此两项长度固定）、文件名（长度可变）。缺点：文件被删除后，该目录项所占用的空间不太好回收利用；</p><p>方法3：目录项本身的长度固定，把长度可变的文件名统一放在目录文件的末尾。</p><h3 id="目录的搜索方法"><a href="#目录的搜索方法" class="headerlink" title="目录的搜索方法"></a>目录的搜索方法</h3><p>顺序查寻法</p><p>Hash方法&#x2F;散列法</p><h3 id="便于共享的目录组织"><a href="#便于共享的目录组织" class="headerlink" title="便于共享的目录组织"></a>便于共享的目录组织</h3><p>硬链接：多个文件名指向同一inode，一个文件拥有多个有效路径名</p><p>软连接&#x2F;符号链接：一个文件实际上是一个文本文件，包含了另一个文件的位置信息（路径名）</p><h2 id="保护文件的方法"><a href="#保护文件的方法" class="headerlink" title="保护文件的方法"></a>保护文件的方法</h2><p>建立副本</p><p>定时转储（unix采用）：每隔一定时间把文件转储到其他存储介质上，当文件发生故障，就用转储的文件来复原，把有故障的文件恢复到转储时刻文件的状态</p><p>规定文件的权限</p><h2 id="文件系统的性能问题"><a href="#文件系统的性能问题" class="headerlink" title="文件系统的性能问题"></a>文件系统的性能问题</h2><p>块高速缓存</p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>prompt提示</title>
      <link href="/2024/05/22/deeplearning/2024-05-22-prompt/"/>
      <url>/2024/05/22/deeplearning/2024-05-22-prompt/</url>
      
        <content type="html"><![CDATA[<p>连续提示：使用可学习的向量，而非手工设计的向量</p><p>离散提示：手工设计的提示词</p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>磁盘管理</title>
      <link href="/2024/05/20/os/2024-5-20-os-disk-management/"/>
      <url>/2024/05/20/os/2024-5-20-os-disk-management/</url>
      
        <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>扇区sector：对于磁盘，每个磁道的扇区数并不是常量</p><p>磁道track：从外往里数，也就是说最外面为0磁道。外道数据访问速度更快（相同角速度下，半径越大线速度越大）</p><p>柱面cylinder：不同盘片相同半径的磁道所组成的圆柱</p><p>磁头head：每个磁盘有两个面，每个面都有一个磁头</p><h2 id="Flash-Disk"><a href="#Flash-Disk" class="headerlink" title="Flash Disk"></a>Flash Disk</h2><p>优点：低功耗、大容量、数据访问速度快</p><p>缺点：容量、价格、寿命、可靠性、读写不对称（读快、写慢）</p><p>两种技术：NADND、NOR</p><h1 id="磁盘的组织与调度"><a href="#磁盘的组织与调度" class="headerlink" title="磁盘的组织与调度"></a>磁盘的组织与调度</h1><p>主引导记录MBR</p><p>硬盘分区表DPT：64字节。分为四小部分，每个部分表示一个分区的信息，占16字节</p><h2 id="CHS模式"><a href="#CHS模式" class="headerlink" title="CHS模式"></a>CHS模式</h2><p>柱面数NC：最大1024（10位）</p><p>磁头数NH：表示硬盘总共有几个磁头，也就是几个盘片，最多256个（8位）</p><p>扇区数NS：表示每一条磁道上有几个扇区，由于所有的0扇区用于存放固件以及一些硬盘的专用的文件，最大为<strong>63</strong> (用 6 位存储)。用户可见扇区从1开始</p><p>8.46GB问题:<br>$$<br>1024 \times 256 \times 63 &#x3D; 16,515,072 \<br>\text{这个扇区之前的所有物理扇区所包含的字节数} &#x3D;  16,515,072 \times 512B &#x3D; 8.46GB<br>$$</p><h2 id="LBA模式"><a href="#LBA模式" class="headerlink" title="LBA模式"></a>LBA模式</h2><p>Logic Block Address，将磁盘驱动器可以看做一个一维的逻辑块的数组，逻辑块是最小的传输单位</p><p>CHS与LBA地址转换<br>$$<br>LBA &#x3D; (NH×NS×C) + (NS×H) + (S-1)\<br>\<br>C &#x3D; LBA &#x2F; (NS×NH)\<br>H &#x3D; (LBA &#x2F; NS) mod NH\<br>S &#x3D; (LBA mod NS) + 1<br>$$</p><h1 id="磁盘空间的管理"><a href="#磁盘空间的管理" class="headerlink" title="磁盘空间的管理"></a>磁盘空间的管理</h1><p>位图：空闲为1，已分配为0</p><p>空闲表法：将所有空闲块记录在一个表中。主要记录两项内容：起始块号，块数</p><p>空闲链表法：把所有空闲块链成一个表，链会很长</p><p>成组链接法：把空白物理块分成组，再通过指针把组与组之间链接起来</p><h1 id="磁盘访问时间"><a href="#磁盘访问时间" class="headerlink" title="磁盘访问时间"></a>磁盘访问时间</h1><p>寻道时间：指的是把磁臂（磁头）从当前位置移动到指定磁道上所经历的时间。<strong>Ts</strong>&#x3D;启动磁盘的时间s + 磁头移动n条磁道所花费的时间之和（m x n, m为常数）</p><p>旋转延迟时间：平均旋转延迟时间<strong>Tr</strong>&#x3D;转一圈所需时间&#x2F;2&#x3D;1&#x2F;（2*转速r）</p><p>传输时间：把数据从磁盘读出，或向磁盘写入数据所经历的时间，<strong>Tt</strong> &#x3D; 每次所读&#x2F;写的字节数b&#x2F;（转速r*磁道上的字节数）</p><p>总访问时间Ta &#x3D; Ts + Tr + Tt</p><h1 id="磁盘调度算法"><a href="#磁盘调度算法" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h1><ol><li>先来先服务算法（FCFS）</li><li>最短寻道时间优先算法（SSTF，Shortest Seek Time First）：优先选择距当前磁头最近的访问请求进行服务，主要考虑寻道优先。可能出现饥饿现象</li><li>扫描算法（SCAN）</li><li>循环扫描算法（C-SCAN）：移动臂到达最后一个柱面后，立即带动读写磁头快速返回到0号柱面，<strong>返回时不为任何的等待访问者服务</strong>，返回后可再次进行扫描。</li><li>LOOK</li><li>C-LOOK</li></ol><h1 id="提高磁盘I-O性能"><a href="#提高磁盘I-O性能" class="headerlink" title="提高磁盘I&#x2F;O性能"></a>提高磁盘I&#x2F;O性能</h1><ul><li><p>缓存</p></li><li><p>优化数据布局</p></li><li><p>提前读：顺序访问时，常采用提前读入下一块到缓冲区中</p></li><li><p>延迟写：将本应立即写回磁盘的数据挂到空闲缓冲区的队列的末尾。直到该数据块移到链头时才将其写回磁盘，再作为空闲区分配出去</p></li><li><p>虚拟盘：利用内存空间去仿真磁盘（RAM盘）</p><p>Vitual disk 与disk cache的区别是：</p><ul><li><p>Vitual disk的存放的内容由用户完全控制</p></li><li><p>Disk cache中的内容完全是由操作系统控制</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IO管理</title>
      <link href="/2024/05/17/os/2024-05-17-os-io-management/"/>
      <url>/2024/05/17/os/2024-05-17-os-io-management/</url>
      
        <content type="html"><![CDATA[<h1 id="I-O管理概述"><a href="#I-O管理概述" class="headerlink" title="I&#x2F;O管理概述"></a>I&#x2F;O管理概述</h1><h2 id="I-O设备分类"><a href="#I-O设备分类" class="headerlink" title="I&#x2F;O设备分类"></a>I&#x2F;O设备分类</h2><p>按 数据组织&#x2F;信息交换的单位 分类：</p><ul><li>块设备：传输快，可寻址</li><li>字符设备：传输慢，不可寻址，常采用中断驱动方式</li></ul><p>按资源分配：</p><ul><li>独占式设备：只允许各个进程串行使用。如打印机</li><li>共享设备：允许多个进程同时使用（微观上交替使用）。如硬盘</li><li>虚拟设备：在一类设备上模拟另一类设备，常用的方法是，用共享设备模拟独占设备，用高速设备模拟低速设备。如：用Spooling技术将打印机变成共享设备。</li></ul><p>按用途分类：</p><ul><li>存储设备：磁盘、磁带；</li><li>传输设备：网卡，Modem；</li><li>人机交互设备：显示器、键盘、鼠标。</li></ul><h2 id="I-O管理示意"><a href="#I-O管理示意" class="headerlink" title="I&#x2F;O管理示意"></a>I&#x2F;O管理示意</h2><ul><li>逻辑I&#x2F;O :完成设备无关的操作，如设备分配，设备回收，数据准备等；</li><li>设备驱动程序：负责对设备控制器进行控制（通过读写其中的寄存器）。</li><li>中断服务程序：设备工作结束后负责向 CPU 发中断信号,中断服务程序完成相应处理。</li></ul><h1 id="I-O硬件组成"><a href="#I-O硬件组成" class="headerlink" title="I&#x2F;O硬件组成"></a>I&#x2F;O硬件组成</h1><h2 id="设备控制器"><a href="#设备控制器" class="headerlink" title="设备控制器"></a>设备控制器</h2><h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><ul><li>接受和识别CPU命令：用控制寄存器</li><li>数据交换：在CPU与控制器、控制器与设备之间，用数据寄存器</li><li>设备状态的了解和报告：用状态寄存器</li><li>设备地址识别：识别CPU要读写哪个寄存器，要实现I&#x2F;O地址（见下“I&#x2F;O端口地址”）</li><li>缓冲区</li><li>对设备传来的数据进行差错检测</li></ul><h3 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h3><p>控制器与CPU接口：数据寄存器、控制寄存器、状态寄存器，采用内存映射或专门的I&#x2F;O指令</p><p>控制器与设备接口：数据信号、控制信号、状态信号</p><p>I&#x2F;O逻辑：用于实现CPU对I&#x2F;O设备的控制</p><h3 id="I-O端口地址"><a href="#I-O端口地址" class="headerlink" title="I&#x2F;O端口地址"></a>I&#x2F;O端口地址</h3><p>定义：接口电路中每个寄存器具有唯一的地址</p><p>所有I&#x2F;O端口地址形成I&#x2F;O端口的地址空间，I&#x2F;O指令形式与I&#x2F;O地址相互关联，主要有以下形式：</p><ol><li><p>内存映像地址–&gt;内存映像I&#x2F;O模式：控制器的内存&#x2F;寄存器作为物理内存空间的一部分</p><p>优点：</p><ul><li>不需要特殊的保护机制来阻止用户进程进行相应的I&#x2F;O 操作。操作系统要避免把包含了控制寄存器的那部分地址空间放入用户的虚拟地址空间中</li><li>引用内存的每一条指令都适用于引用控制寄存器</li></ul><p>缺点：不允许对一个控制寄存器的内容进行高速缓存（如果我们把设备控制寄存器进行了高速缓存，那么第一次引用的时候就把它 放入了高速缓存。以后再对它的引用都是从高速缓存当中取值，而不会再去对设备进行相应的检测）</p></li><li><p>I&#x2F;O独立编址–&gt;I&#x2F;O专用指令：Intel体系架构in&#x2F;out指令</p><p>优点：</p><ul><li>外设不占用内存的地址空间</li><li>编程时易于区分是对内存操作还是对I&#x2F;O操作</li></ul><p>缺点：I&#x2F;O端口操作的指令类型少，操作不灵活</p></li></ol><h2 id="I-O控制方式！"><a href="#I-O控制方式！" class="headerlink" title="I&#x2F;O控制方式！"></a>I&#x2F;O控制方式！</h2><h3 id="程序控制I-O-PIO-Programmed-I-O"><a href="#程序控制I-O-PIO-Programmed-I-O" class="headerlink" title="程序控制I&#x2F;O(PIO,Programmed I&#x2F;O)"></a>程序控制I&#x2F;O(PIO,Programmed I&#x2F;O)</h3><p>CPU<strong>轮询</strong>检查状态寄存器</p><h3 id="中断驱动方式-Interrupt-driven-I-O"><a href="#中断驱动方式-Interrupt-driven-I-O" class="headerlink" title="中断驱动方式(Interrupt-driven I&#x2F;O)"></a>中断驱动方式(Interrupt-driven I&#x2F;O)</h3><ol><li>CPU发出读&#x2F;写命令后，将等待I&#x2F;O的进程阻塞，切换到其他进程。</li><li>当I&#x2F;O完成后，设备控制器向CPU发出中断信号。</li><li>CPU在每个指令周期的<strong>末尾</strong>检查中断，若检测到中断信号，则保存当前进程的运行环境信息，转去执行中断处理程序处理该中断。</li><li>处理中断的过程中，CPU从控制器读<strong>一个字</strong>的数据传送到CPU寄存器，再写入主存</li><li>CPU恢复等待I&#x2F;O的进程的运行环境，继续执行</li></ol><h3 id="直接存储访问方式-DMA-Direct-Memory-Access"><a href="#直接存储访问方式-DMA-Direct-Memory-Access" class="headerlink" title="直接存储访问方式(DMA, Direct Memory Access)"></a>直接存储访问方式(DMA, Direct Memory Access)</h3><p>主要用于<strong>块设备</strong>的I&#x2F;O控制，不再一个字一个字传送，但是块必须是<strong>连续的</strong>。CPU仅在传送开始和结束时进行干预，I&#x2F;O设备与内存可以直接交互，不需要经过CPU</p><p>过程：</p><ol><li><p>由程序设置DMA控制器中的若干寄存器值（如内存始址，传送字节数），然后发起I&#x2F;O操作；</p></li><li><p>DMA控制器完成内存与外设的成批数据交换；</p></li><li><p>在操作完成时由DMA控制器向CPU发出中断</p></li></ol><p>DMA控制器和I&#x2F;O控制器类似，有如下寄存器：</p><ul><li>命令&#x2F;状态寄存器（CR）：用于接收从CPU发送来的I&#x2F;O命令，或有关控制信息，或设备的状态。</li><li>内存地址寄存器（MAR）：在输入时，它存放把数据从设备传送到内存的起始目标地址，在输出时，它存放由内存到设备的内存源地址。</li><li>数据寄存器（DR）：用于暂存从设备到内存，或从内存到设备的数据。</li><li>数据计数器（DC）：存放本次CPU要读或写的字（节）数。</li></ul><p>优点：</p><p>CPU只需干预I&#x2F;O操作的开始和结束，而后续成批的数据读写则无需CPU控制，适于高速设备。</p><p>缺点：</p><ul><li>数据传送的方向、存放数据的内存地址及传送数据的长度等都由CPU控制，占用了CPU时间。</li><li>每个设备占用一个DMA控制器，当设备增加时，需要增加新的DMA控制器</li></ul><table><thead><tr><th>区别</th><th>中断驱动</th><th>DMA</th></tr></thead><tbody><tr><td>何时中断？</td><td>每个单位数据传送完成后中断CPU</td><td>传送的一批数据完成后中断</td></tr><tr><td>谁控制数据传送？</td><td>CPU控制完成数据传送，涉及程序切换，需要保护和恢复现场</td><td>由DMA控制器控制完成的，在传输过程中不需要CPU干预，DMA控制器直接在主存和I&#x2F;O设备之间传送数据，只有开始和结束才需要CPU干预</td></tr><tr><td></td><td>具有对异常事件的处理能力</td><td>适用于数据块的传输</td></tr></tbody></table><h3 id="通道技术（Channel）"><a href="#通道技术（Channel）" class="headerlink" title="通道技术（Channel）"></a>通道技术（Channel）</h3><p>I&#x2F;O通道是专门负责输入输出的处理器，独立于CPU。</p><p>与DMA的原理几乎是一样的，通道是一个特殊功能的处理器，它有自己的指令和程序专门负责数据输入输出的传输控制。CPU将“传输控制”的功能下放给通道后只负责“数据处理”功能。这样，通道与CPU分时使用内存，实现了CPU内部运算与I&#x2F;O设备的并行工作</p><table><thead><tr><th>区别</th><th>DMA</th><th>通道</th></tr></thead><tbody><tr><td></td><td>数据的传送方向、存放数据的内存起始地址和数据块长度都由CPU控制</td><td>是一个特殊的处理器，有自己的指令和程序，通过执行通道程序实现对数据传输的控制，所以通道具有更强的独立处理I&#x2F;O的功能</td></tr><tr><td></td><td>通常只能控制一台或者少数几台同类设备</td><td>一个通道可同时控制多种设备</td></tr></tbody></table><h2 id="I-O软件组成"><a href="#I-O软件组成" class="headerlink" title="I&#x2F;O软件组成"></a>I&#x2F;O软件组成</h2><p><img src="/../../images/OS/IO%E8%BD%AF%E4%BB%B6%E7%BB%84%E6%88%90" alt="I/O软件组成"></p><h3 id="逻辑设备表LUT-Logical-Unit-Table"><a href="#逻辑设备表LUT-Logical-Unit-Table" class="headerlink" title="逻辑设备表LUT(Logical Unit Table)"></a>逻辑设备表LUT(Logical Unit Table)</h3><p>为了实现设备的独立性，系统必须设置一张逻辑设备表，用于将应用程序中所使用的逻辑设备名映射为物理设备名。</p><p>该表的每个表目中包含了三项，逻辑设备名（设备类型）、物理设备名、设备驱动程序的入口地址</p><h1 id="I-O缓冲管理"><a href="#I-O缓冲管理" class="headerlink" title="I&#x2F;O缓冲管理"></a>I&#x2F;O缓冲管理</h1><h1 id="I-O设备管理"><a href="#I-O设备管理" class="headerlink" title="I&#x2F;O设备管理"></a>I&#x2F;O设备管理</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>通道可以有多个，一个通道管理多个控制器，一个控制器管理多个设备</p><h3 id="设备控制表DCT"><a href="#设备控制表DCT" class="headerlink" title="设备控制表DCT"></a>设备控制表DCT</h3><p>每个设备一张DCT，用于记录设备情况</p><ul><li>设备队列队首指针：凡因为请求本设备而未得到满足的进程，其PCB都应按照一定的策略排成一个队，称该队列为设备请求队列或简称设备队列，其队首指针指向队首PCB；</li><li>设备状态：当设备处于使用状态时，应该把设备忙&#x2F;闲标志置为1；</li><li>控制器表指针：该指针指向该设备所连接的控制器的控制表；</li><li>重复执行次数：外部设备在传送数据时，较容易发生数据传送错误。在许多系统中，如果发生传送错误，并不立即认为传送失败，而是令它重传，并由系统规定设备在工作中发生错误时应重复执行的次数</li></ul><h3 id="控制器控制表CCT"><a href="#控制器控制表CCT" class="headerlink" title="控制器控制表CCT"></a>控制器控制表CCT</h3><h3 id="通道控制表CHCT"><a href="#通道控制表CHCT" class="headerlink" title="通道控制表CHCT"></a>通道控制表CHCT</h3><h3 id="系统设备表SDT"><a href="#系统设备表SDT" class="headerlink" title="系统设备表SDT"></a>系统设备表SDT</h3><p>记录了系统中全部设备的情况，每个设备对应一个表目</p><h2 id="假脱机技术（SPOOLing技术）"><a href="#假脱机技术（SPOOLing技术）" class="headerlink" title="假脱机技术（SPOOLing技术）"></a>假脱机技术（SPOOLing技术）</h2><p>用户空间的I&#x2F;O软件</p><p>也称为虚拟设备技术，可把独享设备转变成具有共享特征的虚拟设备，从而提高设备利用率</p><h3 id="SPOOLing程序和外设进行数据交换：实际I-O"><a href="#SPOOLing程序和外设进行数据交换：实际I-O" class="headerlink" title="SPOOLing程序和外设进行数据交换：实际I&#x2F;O"></a>SPOOLing程序和外设进行数据交换：实际I&#x2F;O</h3><ul><li>SPOOLing程序预先从外设读取数据并加以缓冲，在以后需要的时候输入到应用程序</li><li>SPOOLing程序接受应用程序的输出数据并加以缓冲，在以后适当的时候输出到外设</li></ul><h3 id="应用程序和SPOOLing程序交换数据：虚拟I-O"><a href="#应用程序和SPOOLing程序交换数据：虚拟I-O" class="headerlink" title="应用程序和SPOOLing程序交换数据：虚拟I&#x2F;O"></a>应用程序和SPOOLing程序交换数据：虚拟I&#x2F;O</h3><p>应用程序进行I&#x2F;O操作时，实际上是从SPOOLing程序的缓冲池中读出数据或把数据送入缓冲池，而不是跟实际的外设进行I&#x2F;O操作</p><h1 id="I-O性能问题"><a href="#I-O性能问题" class="headerlink" title="I&#x2F;O性能问题"></a>I&#x2F;O性能问题</h1><h2 id="两个途径"><a href="#两个途径" class="headerlink" title="两个途径"></a>两个途径</h2><ul><li>使CPU利用率尽可能不被I&#x2F;O降低：可以使用缓冲技术减少或缓解速度差异，同时使用异步I&#x2F;O使CPU不等待 I&#x2F;O</li><li>使CPU尽可能摆脱I&#x2F;O：使用DMA、通道等I&#x2F;O部件让CPU摆脱I&#x2F;O操作的影响</li></ul><h2 id="I-O操作的两个步骤"><a href="#I-O操作的两个步骤" class="headerlink" title="I&#x2F;O操作的两个步骤"></a>I&#x2F;O操作的两个步骤</h2><ol><li>把磁盘数据装载进内核的内存空间</li><li>把内核内存空间的数据copy到用户内存空间中</li></ol><h2 id="五种模型"><a href="#五种模型" class="headerlink" title="五种模型"></a>五种模型</h2><ol><li>阻塞I&#x2F;O：指I&#x2F;O调用结果返回之前,当前进程会被挂起(进入睡眠状态) ，只有在得到返回结果后, 才能继续执行。</li><li>I&#x2F;O多路复用：进程调用一个管理I&#x2F;O的特殊库函数，此库函数可以接受并管理多个I&#x2F;O请求，进程则可以同时等待多个I&#x2F;O请求，可以提高效率。第二阶段依然需要工作进程参与库函数把内核空间数据复制到用户空间，第二阶段依旧阻塞</li><li>非阻塞I&#x2F;O：进程发起I&#x2F;O调用，I&#x2F;O自己知道需过一段时间完成，就立即通知进程进行别的操作，则为非阻塞I&#x2F;O</li><li>事件（信号）驱动I&#x2F;O：进程发起调用,通过回调函数, 内核会记住是哪个进程申请的,一旦第一阶段完成了,就可以向这个进程发起通知,这样第一阶段就是非阻塞的,进程不需要忙等了, 但是第二阶段依然是阻塞的</li><li>异步I&#x2F;O：无论第一第二段, 不再向系统调用提出任何反馈, 只有数据完全复制到服务进程内存中后, 才向服务进程返回ok的信息,其它时间,进程可以随意做自己的事情,直到内核通知ok信息</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>OO第三单元总结</title>
      <link href="/2024/05/16/oo/2024-05-16-oo-unit3-summary/"/>
      <url>/2024/05/16/oo/2024-05-16-oo-unit3-summary/</url>
      
        <content type="html"><![CDATA[<h1 id="测试过程"><a href="#测试过程" class="headerlink" title="测试过程"></a>测试过程</h1><h2 id="黑箱测试和白箱测试"><a href="#黑箱测试和白箱测试" class="headerlink" title="黑箱测试和白箱测试"></a>黑箱测试和白箱测试</h2><p>黑箱测试注重“结果”，它只关心程序能否完成需求，而不关心代码实现方式、内部架构；白箱测试注重“过程”，需要去关注代码内部结构、实现方法，测试时要关注方法覆盖率、分支覆盖率等。</p><p>互测我一般采用的是黑箱测试，对自己的代码主要采用的是黑箱测试，同时有部分的白箱测试。</p><h2 id="对单元测试、功能测试、集成测试、压力测试、回归测试的理解"><a href="#对单元测试、功能测试、集成测试、压力测试、回归测试的理解" class="headerlink" title="对单元测试、功能测试、集成测试、压力测试、回归测试的理解"></a>对单元测试、功能测试、集成测试、压力测试、回归测试的理解</h2><ol><li>单元测试：对代码的最小单元进行测试，如一个方法、一个类。典型的例子就是Junit，这个单元的作业也要求了用Junit完成一些方法的单元测试，它是一种白箱测试。</li><li>功能测试：关注系统的功能性需求，通常是从使用者的角度出发，观察测试系统的输入和输出是否符合预期，是一种黑箱测试。</li><li>集成测试：在将单个软件模块组合在一起形成完整的系统后，测试这些模块之间的交互是否正常的过程。它的目标是验证不同模块之间的接口是否正确，并且模块之间的通信是否按照预期工作。集成测试可以帮助发现模块之间的兼容性问题和集成错误。</li><li>压力测试：在正常操作条件的前提下，输入具有压力的数据量，以确定程序在超出正常工作负载的情况下的表现，它主要考虑一些极端情况，如高并发、大量数据、极端数据。个人感觉这个单元的重点就是压力测试，强测中大量压力测试，算法稍微设计不合理就会CPU_TIME_LIMIT_EXCEED。</li><li>回归测试：对代码进行修改后重新运行之前的测试样例，以确保没有引入新的错误或者影响到现有的功能。我在测试过程中会经常使用此方法，因为本单元作业很多地方需要对算法进行优化，我一般第一版是没有进行算法优化的，我会保留第一版运行后的输出结果，后续修改算法后会重新运行这些样例，然后与之前的输出结果进行比对。</li></ol><h2 id="数据构造策略"><a href="#数据构造策略" class="headerlink" title="数据构造策略"></a>数据构造策略</h2><p>很明显感觉到这个单元随机生成数据无法很好得保证正确率，尤其是性能方面。所以需要手动构造一些极端数据，比如构造高并发的指令数据，反复执行某个指令，看看运行时间是否超过限制；构造边界数据，避免数据溢出导致的出错。</p><h1 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h1><p>本单元的架构基本是参照着JML实现各个类和方法，在此基础上添加了UnionFind、Dijkstra类做性能的优化，Sender类单纯是为了满足MyNetwork小于500的要求分出去的一个方法。</p><p><img src="/../../images/OO/unit3.jpg" alt="架构图"></p><h1 id="性能改进"><a href="#性能改进" class="headerlink" title="性能改进"></a>性能改进</h1><h2 id="HashMap替代ArrayList"><a href="#HashMap替代ArrayList" class="headerlink" title="HashMap替代ArrayList"></a>HashMap替代ArrayList</h2><p>JML中的描述都是数组形式，所以刚开始很自然地选择了ArrayList，但是这些数据结构有很多查找操作，所以最后都改成了HashMap，以降低查找操作的时间复杂度</p><h2 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h2><p>用于判断两个人是否有联系，抽象出来就是判断图中两个结点是否属于同一个连通子图。</p><p>实现细节方面，首先进行了路径压缩的优化，避免每次查找时都要递归。其次，由于人与人之间的关系会修改，有可能会断开连接（即关系图中结点之间的边可能会被删掉），所以需要重建并查集，这里借鉴了“写时复制”的思想，</p><ol><li>在MyNetwork里设置了一个标记resetUnion，初始为false</li><li>若有添加人的命令，则在并查集中加入该person</li><li>若有添加关系的命令，则调用union把两人放入同一个集合</li><li>若有修改关系的命令<ul><li>若resetUnion为false，则看修改关系是否会导致两个人的连接被删除，若会删除，则resetUnion置为true</li><li>若resetUnion为true，就不要管了(千万别因为没删关系就重新置为false)，这说明之前有命令已经导致并查集需要重建</li></ul></li><li>当要查询两个人之间是否关联时<ul><li>若resetUnion为false，则直接调用isSameSet()判断两人是否连接</li><li>若resetUnion为true，则先调用initialize()清空，然后调用setup()重建并查集，然后查询。同时不要忘了<strong>把restUnion置为false</strong></li></ul></li></ol><h2 id="dijkstra求最短路径"><a href="#dijkstra求最短路径" class="headerlink" title="dijkstra求最短路径"></a>dijkstra求最短路径</h2><p>这个没什么好说的，数据结构课讲过的算法，但是不记得了，然后又重新学了一遍。java可以用优先队列实现，但是注意比较器不要用两个数相减的方式比大小，会爆int。</p><h3 id="动态维护"><a href="#动态维护" class="headerlink" title="动态维护"></a>动态维护</h3><p>在添加人、关系的时候就计算出来结果，每新添加人、关系时都要判断是否需要修改，这个方法用在计算bestAquaintance、tripleSum、valueSum等地方。能动态维护的都要动态维护，事实上这个单元不能出现任何复杂度大于O(n^2)的方法……不然强测一定会寄</p><h1 id="Junit测试"><a href="#Junit测试" class="headerlink" title="Junit测试"></a>Junit测试</h1><p>上学期已经用Junit做过一些单元测试，但是本单元的Junit让我新学会了用Parameters做参数化测试。参数化测试可以生成多组数据一同进行测试，保证了数据的覆盖率，生成过程中我会尽量考虑所有情况，例如生成关系时稠密图、稀疏图都要有一定的生成概率，Message信息每种类型都要有可能出现。</p><p>断言时JML就派上用场了，根据JML的规格信息一一编写断言。注意对于pure方法，要保证属性前后没有发生任何改变，所有可能会有深浅克隆的问题，我的解决办法是在数据生成阶段就进行克隆，用一个shadowNetwork与Network同步生成数据，保证二者一模一样。</p><p>用junit进行测试确实帮助我发现了一些代码的bug，例如sendMessage后message没有正确移除，然后发现我的remove语句有问题。</p><p>不过编写Junit的过程也确实很繁琐，而且要保证数据生成没有问题，有时候还得先改junit的bug<del>(汗流浃背了)</del>。</p><h1 id="学习体会"><a href="#学习体会" class="headerlink" title="学习体会"></a>学习体会</h1><p>本单元了解了JML的语法，训练了根据JML给出的规格编写代码的能力，体会到了JML语言的严谨性，但是理解JML的过程非常痛苦，有时候还会看错括号。</p><p>另外，本单元对性能优化的要求非常高，对我算法的学习有很大帮助，有的算法以前学过但是忘了，所以又重新复习、实践了一遍；有的算法是第一次了解，学到了新知识非常好！<del>(虽然后来可能因为优化不够被替换掉了)</del>。</p><p>这个单元也有很多遗憾，感觉我对高并发的情况考虑还是不够周全，所以每次作业最后都出现了一些CTLE的bug，哎需要好好反思，这个问题在第二单元也出现过，感觉它其实是一个在实际应用中也很需要关注的问题。总之，牢记这次的教训！</p>]]></content>
      
      
      <categories>
          
          <category> OO </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>OADP</title>
      <link href="/2024/05/02/deeplearning/2024-05-02-ovd/"/>
      <url>/2024/05/02/deeplearning/2024-05-02-ovd/</url>
      
        <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><h2 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h2><p>把一个大的模型（教师模型）里面的知识萃取蒸馏出来，并浓缩到一个小的（学生）模型中。是一种用于模型压缩和迁移学习的技术，其主要思想是通过将一个大型模型的知识传递给一个小型模型来提高小型模型的性能。</p><h2 id="软标签和硬标签"><a href="#软标签和硬标签" class="headerlink" title="软标签和硬标签"></a>软标签和硬标签</h2><table><thead><tr><th></th><th>硬标签</th><th>软标签</th></tr></thead><tbody><tr><td>定义</td><td>一种离散的、确定性的类别表示方式。每个样本被赋予一个明确的、唯一的类别标签</td><td>一种连续的、概率分布形式的类别表示方式。每个样本的标签是一个概率向量，表示它属于每个类别的概率。</td></tr><tr><td>应用</td><td>常用于传统的监督学习任务，如分类问题</td><td>常用于<strong>知识蒸馏</strong>等场景，其中<strong>大型模型的输出可以作为软标签传递给小型模型</strong>。</td></tr><tr><td></td><td></td><td>软标签包含了样本与多个类别之间的相似度信息，因此它们可以使模型更加平滑地处理类别之间的边界，并减少对单一类别的过度依赖</td></tr></tbody></table><h2 id="蒸馏温度"><a href="#蒸馏温度" class="headerlink" title="蒸馏温度"></a>蒸馏温度</h2><p>知识蒸馏中的一个超参数，它控制了模型预测的软标签分布的“软化”程度。蒸馏温度的作用是在生成软标签时引入一个温度参数，从而调整标签的相对概率分布。这个温度参数通常是一个正的实数。例如分类问题最后总是用softmax函数将输出转化为概率分布，用上蒸馏温度就变成如下形式：<br>$$<br>softmax(z&#x2F;T)_i &#x3D; \frac{e^{z_i&#x2F;T}}{\sum_j e^{z_j&#x2F;T}}<br>$$</p><p>作用：</p><p>软标签的平滑性： 增加蒸馏温度会使软标签的概率分布更平滑。较高的温度将导致更平缓的概率曲线，使得模型更容易学到相对均匀的分布。这对于小型模型的训练过程中更容易捕捉大型模型的知识，因为软标签的平滑性有助于抑制训练时的过拟合。</p><p>控制标签的尖峰性： 较低的温度会使软标签的分布更接近硬标签，即更尖锐，更接近确定性。这可能使得模型更注重大型模型中预测概率最高的类别，但相对容易受到噪声的影响。</p><p>控制模型的自信程度： 蒸馏温度还可以影响模型的自信度。较高的温度导致模型更不确定，而较低的温度则会使模型更自信。这可以在训练过程中控制模型的泛化行为。</p><p>控制损失函数的平坦性： 由于知识蒸馏的损失函数通常涉及到交叉熵，温度参数也可以影响损失函数的平坦性。这有助于更稳定地训练小型模型，特别是当大型模型和小型模型结构不同或训练数据较小的情况下。</p><h1 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h1><ol><li><p>Object-Aware Knowledge Extraction：adaptively transforms object proposals and adopts object-aware mask attention to obtain precise and complete knowledge of objects.</p></li><li><p>Distillation Pyramid：introduces global and block distillation for more comprehensive knowledge transfer to compensate for the missing relation information in object distillation</p><ul><li>knowledge extraction</li><li>knowledge transfer</li></ul></li></ol><p>obj token和cls token的区别是什么呢？论文的意思好像是obj关注的是图像的提议框里的对象，cls关注的是整个这张图像，一个是部分，一个是整体，但是obj的生成不也要用“这个图像包含哪个<strong>类别</strong>的目标”的信息，岂不是和cls一样了？</p><h1 id="mmdection"><a href="#mmdection" class="headerlink" title="mmdection"></a>mmdection</h1><ul><li><strong>apis</strong> 为模型推理提供高级 API。</li><li><strong>structures</strong> 提供 bbox、mask 和 DetDataSample 等数据结构。</li><li><strong>datasets</strong> 支持用于目标检测、实例分割和全景分割的各种数据集。<ul><li><strong>transforms</strong> 包含各种数据增强变换。</li><li><strong>samplers</strong> 定义了不同的数据加载器采样策略。</li></ul></li><li><strong>models</strong> 是检测器最重要的部分，包含检测器的不同组件。<ul><li><strong>detectors</strong> 定义所有检测模型类。</li><li><strong>data_preprocessors</strong> 用于预处理模型的输入数据。</li><li><strong>backbones</strong> 包含各种骨干网络。</li><li><strong>necks</strong> 包含各种模型颈部组件。</li><li><strong>dense_heads</strong> 包含执行密集预测的各种检测头。</li><li><strong>roi_heads</strong> 包含从 RoI 预测的各种检测头。</li><li><strong>seg_heads</strong> 包含各种分割头。</li><li><strong>losses</strong> 包含各种损失函数。</li><li><strong>task_modules</strong> 为检测任务提供模块，例如 assigners、samplers、box coders 和 prior generators。</li><li><strong>layers</strong> 提供了一些基本的神经网络层。</li></ul></li><li><strong>engine</strong> 是运行时组件的一部分。<ul><li><strong>runner</strong> 为 <a href="https://mmengine.readthedocs.io/zh_CN/latest/tutorials/runner.html">MMEngine 的执行器</a>提供扩展。</li><li><strong>schedulers</strong> 提供用于调整优化超参数的调度程序。</li><li><strong>optimizers</strong> 提供优化器和优化器封装。</li><li><strong>hooks</strong> 提供执行器的各种钩子。</li></ul></li><li><strong>evaluation</strong> 为评估模型性能提供不同的指标。</li><li><strong>visualization</strong> 用于可视化检测结果。</li></ul><h2 id="faster-RCNN核心代码"><a href="#faster-RCNN核心代码" class="headerlink" title="faster RCNN核心代码"></a>faster RCNN核心代码</h2><p>mmdet&#x2F;models&#x2F;backbones&#x2F;resnet.py</p><p>mmdet&#x2F;models&#x2F;necks&#x2F;fpn.py</p><p>mmdet&#x2F;models&#x2F;dense_heads&#x2F;rpn_head.py</p><p>mmdet&#x2F;models&#x2F;roi_heads&#x2F;standard_roi_head.py</p><h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><p>teacher甚至student是指代什么？</p><blockquote><p>知识蒸馏里的术语</p></blockquote><p>embedding和全连接有什么区别？感觉两者都是把高维向量平铺开。</p><blockquote><p>embedding层主要用于处理离散型数据，而全连接层则可以处理任意类型的数据</p></blockquote><p>nn.BatchNorm2d和nn.LayerNorm有什么区别和联系？</p><blockquote><ol><li><p>计算<br>$$<br>nn.BatchNorm2d : \text{E}[x]c &#x3D; \frac{1}{N \times H \times W} \sum_{n&#x3D;1}^N \sum_{h&#x3D;1}^{H} \sum_{w&#x3D;1}^{W} x_{n,c,h,w} \nn.LayerNorm : \text{E}[x]{c} &#x3D; \frac{1}{H \times W}\sum_{h&#x3D;1}^{H} \sum_{w&#x3D;1}^{W} x_{c,h,w}<br>$$</p></li><li><p>应用场景</p><ul><li>BatchNorm通常用于CNN（卷积神经网络）的卷积层之后，用于调整数据的分布，加速网络训练。由于BatchNorm依赖于mini-batch的统计数据，因此它对于较小的batch size可能不太稳定。</li><li>LayerNorm则常用于RNN（循环神经网络）和Transformer等模型，因为它们在处理序列数据时，每个样本的长度可能不同，而LayerNorm可以对每个样本进行独立的归一化操作。</li></ul></li></ol></blockquote><p>nn.MultiheadAttention和F.multi_head_attention_forward有什么区别?</p><blockquote><p>相比 <code>nn.MultiheadAttention</code>，<code>F.multi_head_attention_forward</code> 提供了更底层的控制，允许用户直接操作多头注意力的各个组成部分。然而，由于它不是一个模块，因此它通常不会被直接嵌入到神经网络模型中。相反，它可能被 <code>nn.MultiheadAttention</code> 或其他高级模块所使用。</p></blockquote><p>ABCMeta是什么？</p><blockquote><p>ABCMeta是一个元类（metaclass），用于定义抽象基类的元信息。通过将ABCMeta作为元类，可以在类定义阶段对类进行检查和修饰。ABCMeta元类提供了一些功能，例如检查子类是否实现了抽象方法、注册具体实现类等。</p><p>在Python中，类是通过类来创建的，而<strong>创建类的类就是元类</strong>。元类的主要目的是控制类的创建行为。Python的特别之处在于可以创建自定义元类，而ABCMeta就是这样一个自定义元类，用于创建自定义的抽象基类。</p></blockquote><p>logits是什么？</p><blockquote><p>logits（或称为分数、原始分数、未校准的输出等）是模型输出的原始、未归一化的预测值</p></blockquote><p>这里为什么要除以embedding向量的开方？一种初始化规则？</p><p><img src="/../../images/tmp/image-20240504102504742.png" alt="image-20240504102504742"></p><p>oake模块下base.py文件中Validator类有什么作用呢？</p><p><img src="/../../images/tmp/image-20240504181309157.png" alt="image-20240504181309157"></p><blockquote><p>OKAE这三文件都可以单独运行，独立的把需要的特征提取出来保存。因为OADP中global、block和object使用的蒸馏特征在提取的时候会特别耗时，所以作者把这三个蒸馏特征的提取过程单独用这三个文件预先生成之后保存起来了，后面DP部分训练时候是直接读取的这些特征</p></blockquote><p>oadp&#x2F;oake&#x2F;objects.py里Dataset类的_expand方法有什么用？为什么要扩大bbox，而且还分了很多种扩大模式？</p><blockquote><p>为了把proposal的不规则区域转化成正方形，因为CLIP的输入是224*224的正方形，可以认为这样expand之后有助于减小输入CLIP特征的形变</p></blockquote><p>Compose和nn.Sequential有什么区别和联系？</p><blockquote><ol><li>联系：</li></ol><ul><li>二者都提供了一种顺序执行的方式，可以将多个操作或层按照特定的顺序组合在一起。</li><li>它们都简化了模型的构建过程，使得代码更加清晰和易于管理。</li></ul><ol><li>区别：</li></ol><ul><li>功能和应用领域：Compose主要用于<strong>组合图像预处理操作</strong>，是torchvision.transforms模块中的一个类。而nn.Sequential则用于<strong>构建神经网络模型</strong>，是PyTorch中torch.nn模块的一个容器类。</li><li>组成部分：Compose中的操作通常是对图像的变换，如裁剪、旋转、标准化等。而nn.Sequential中的层通常是神经网络的各种组成部分，如线性层、卷积层、激活函数等。</li><li>使用方式：Compose通常与图像数据集一起使用，用于在将数据输入到神经网络之前进行预处理。而nn.Sequential则直接定义了一个神经网络模型，可以通过前向传播函数将数据传递给模型并获得输出。</li></ul></blockquote><p>oadp&#x2F;dp&#x2F;classifiers.py的BaseClassifier类中的bg_embedding是什么？</p><p>mixin是什么意思？</p><blockquote><p>Mixin实质上是一个带有部分或全部实现的接口或类，它可以被其他类继承或混入，从而将这些功能组合到子类中。Mixin模式的主要作用是代码复用，通过减少代码冗余度，使代码更加清晰、可维护和易于扩展。</p></blockquote><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://t.csdnimg.cn/RGdL1">知识蒸馏</a></p><p><code>zip</code> 是 Python 的一个内置函数，用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的对象</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for foreground, bbox in zip(foregrounds, bboxes):  </span><br><span class="line">    objects.append(self._object(image, bbox))  </span><br><span class="line">    masks.append(self._mask(foreground, bbox))</span><br><span class="line">//zip 在这里用于并行地遍历两个列表（或任何可迭代对象），确保在每次迭代中，foregrounds 和 bboxes 的对应元素都被一起处理</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>注意力机制</title>
      <link href="/2024/04/28/deeplearning/2024-04-28-attetion/"/>
      <url>/2024/04/28/deeplearning/2024-04-28-attetion/</url>
      
        <content type="html"><![CDATA[<h1 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h1><ol><li>决定需要关注输入的哪部分：在处理大量信息时，注意力机制能够帮助模型或个体确定哪些部分是重要的，并集中资源进行处理。例如，在机器翻译任务中，注意力机制可以帮助模型确定源语言句子中哪些词汇对目标语言的翻译更为重要。</li><li>分配有限的信息处理资源给重要的部分：通过给重要的信息部分分配更多的注意力，模型可以更有效地利用资源，从而提高处理效率和准确性，解决信息过载问题。这类似于人类视觉注意力机制，通过快速扫描全局图像，获得需要重点关注的目标区域，然后对这一区域投入更多注意力资源，以获取更多细节信息，同时抑制其他无用信息。</li></ol><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ol><li>查询向量Query：指的是查询的范围，自主提示，即主观意识的特征向量</li><li>键向量Key：指的是被比对的项，非自主提示，即物体的突出特征信息向量</li><li>值向量Value：物体本身的特征向量，通常和Key成对出现</li></ol><h1 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h1><p>对于每一个Query，计算所有Key与它的相关性，然后根据这个相关性去找对应的Value（Key、Value成对出现），Query和Key相关性高的其对应Value要重点关注（分配更高的注意力权重）。</p><p>计算Key与Query的相关性<br>$$<br>scores_i &#x3D; Query \cdot Key_i<br>$$<br>softmax进行归一化，得到权重系数<br>$$<br>\alpha_i &#x3D; softmax(scores_i) &#x3D; \frac{e^{scores_i}}{\sum_{j&#x3D;1}^{Lx} e^{scores_j}}<br>$$<br>对Value进行加权求和，得到Attetion Value<br>$$<br>Attetion &#x3D; \sum_{i&#x3D;1}^{Lx} \alpha_i \cdot Value_i<br>$$</p><h2 id="自注意力机制"><a href="#自注意力机制" class="headerlink" title="自注意力机制"></a>自注意力机制</h2><p>提出背景：输入向量大小不一，并且不同向量之间有一定的关系，但是实际训练的时候无法充分发挥这些输入之间的关系，导致模型训练结果效果不会。</p><p>特色：让机器注意到整个输入中不同部分之间的相关性。是一组元素内部相互做注意力机制，因此自注意力机制也叫做内部注意力机制。</p><p>实现过程：Q、K、V是同一个东西，活着三者来源于同一个输入X。</p><ol><li>对于每一个输入向量X，分别乘上系数$W^q、W^k、W^v$（需要学习的参数），得到Q、K、V。</li><li>利用Q和K计算每两个输入向量之间的相关性（scores），一般采用点积计算</li><li>用softmax归一化，得到注意力权重</li><li>用权重乘每个Value，最终得到输出向量Z</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># 自注意力机制</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def soft_max(z):</span><br><span class="line">    t = np.exp(z)</span><br><span class="line">    a = np.exp(z) / np.expand_dims(np.sum(t, axis=1), 1)</span><br><span class="line">    return a</span><br><span class="line"></span><br><span class="line"># 每一行为一个序列单元的查询向量</span><br><span class="line">Query = np.array([</span><br><span class="line">    [1,0,2],</span><br><span class="line">    [2,2,2],</span><br><span class="line">    [2,1,3]</span><br><span class="line">]) </span><br><span class="line"></span><br><span class="line"># 每一行为一个查询单元的键向量</span><br><span class="line">Key = np.array([</span><br><span class="line">    [0,1,1],</span><br><span class="line">    [4,4,0],</span><br><span class="line">    [2,3,1]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"># 每一行为一个查询单元的值向量</span><br><span class="line">Value = np.array([</span><br><span class="line">    [1,2,3],</span><br><span class="line">    [2,8,0],</span><br><span class="line">    [2,6,3]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">scores = Query @ Key.T # 计算每一个序列单元的分数，即代表重要程度。结果的每一行为所有序列单元相对于某一个Query的重要程度</span><br><span class="line">print(scores)</span><br><span class="line">scores = soft_max(scores)//对scores做归一化处理，使得一行的和为1</span><br><span class="line">print(scores)</span><br><span class="line">out = scores @ Value //每一行代表每个序列单元新的编码</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure><p>缺点：</p><ol><li>自注意力机制过滤了不重要的信息，会导致模型有效信息的抓取能力比CNN弱，因为模型无法利用图像本身具有的尺度、平移不变性以及图像的特征局部性这些先验知识，只能通过大量数据进行学习。所以一般自注意力机制在大数据的基础上才能有效地建立准确的全局关系，而在小数据的情况下可能效果不如CNN。</li><li>没有考虑向量的位置信息</li></ol><h2 id="多头注意力机制"><a href="#多头注意力机制" class="headerlink" title="多头注意力机制"></a>多头注意力机制</h2><p>提出背景：使用自注意力机制的模型，对当前位置的信息进行编码时，会过度的将注意力集中于自身的位置，有效信息抓取能力变差。</p><p>特色：用独立学习得到的h组（一般h&#x3D;8）不同的线性投影（linear projections）来变换Q、K、V。 然后，这h组变换后的Q、K、V将并行地送到注意力汇聚中。 最后，将这h个注意力汇聚的输出拼接在一起， 并且通过另一个可以学习的线性投影进行变换， 以产生最终输出。</p><p>实现过程：</p><ol><li>对于一个输入向量X， 定义多组W：$W_0^q、W_0^k、W_0^v…W_7^q、W_7^k、W_7^v$</li><li>每组都按上述自注意力机制实现过程走一遍，得到多个输出$Z_0…Z_7$</li><li>将多个输出拼接后乘以一个矩阵转化为跟输入X相同的维度</li></ol><h2 id="通道注意力机制"><a href="#通道注意力机制" class="headerlink" title="通道注意力机制"></a>通道注意力机制</h2><p>提出背景：之前都是关注图片不同位置的重要性，而图片的另一个维度就是通道，所有也可以计算不同通道的重要性。</p><h2 id="CA-coordinate-attettion-注意力机制"><a href="#CA-coordinate-attettion-注意力机制" class="headerlink" title="CA(coordinate attettion)注意力机制"></a>CA(coordinate attettion)注意力机制</h2><p>提出背景：现有的注意力机制在求取通道注意力的时候，一般采用的全局最大池化&#x2F;平均池化，这样会造成物体空间信息的损失。</p><p>特色：在引入通道注意力机制的同时，引入空间注意力机制。</p><p>实现过程：将位置信息嵌入到通道注意力中</p><p><img src="D:/mynotes/images/CA注意力机制.PNG" alt="CA注意力机制"></p><p>CA注意力机制分为两个并行阶段。</p><ol><li>首先将输入特征图(CxHxW)分别在宽度、高度两个方向进行全局平均池化，获得在宽度、高度两个方向的特征图(Cx1xH、CxWx1)。</li><li>将两个并行阶段合并，将宽和高转置到同一个维度，然后堆叠，将宽高特征合并得到特征层C x 1 x (H+W)</li><li>利用卷积+标准化+激活函数获得特征</li><li>再次分开为两个并行阶段：Cx1xH、CxWx1</li><li>利用1x1卷积调整通道数后取sigmoid获得宽、高维度上的注意力情况，扩展成CxHxW矩阵，乘上原有的特征图</li></ol>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Transformer模型</title>
      <link href="/2024/04/27/deeplearning/2024-04-27-transformer/"/>
      <url>/2024/04/27/deeplearning/2024-04-27-transformer/</url>
      
        <content type="html"><![CDATA[<h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p><img src="/../../images/deepLearning/Transformer%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png" alt="Transformer整体架构"></p><p>图上全部为训练过程，去掉虚线框里的就是推理过程（没有正确答案输入的部分了）</p><h2 id="Word-Embedding词嵌入"><a href="#Word-Embedding词嵌入" class="headerlink" title="Word Embedding词嵌入"></a>Word Embedding词嵌入</h2><p>将输入(输入句子有m个词)转化为向量，假设嵌入维度为n，则一个词对应一个n维向量，整个向量维度为m x n。</p><h2 id="Positional-Encoding位置编码"><a href="#Positional-Encoding位置编码" class="headerlink" title="Positional Encoding位置编码"></a>Positional Encoding位置编码</h2><p>$$<br>PE(pos, 2i) &#x3D; sin(\frac{pos}{10000^{2i&#x2F;d_{model}}}) \<br>PE(pos, 2i+1) &#x3D; cos(\frac{pos}{10000^{2i&#x2F;d_{model}}})<br>$$</p><p>将每个位置信息编码后与对应位置词的编码相加，这样后面的自注意力机制可以同时考虑输入的词本身和顺序信息。</p><h2 id="Encoder-多次反复使用，一般为6次"><a href="#Encoder-多次反复使用，一般为6次" class="headerlink" title="Encoder(多次反复使用，一般为6次)"></a>Encoder(多次反复使用，一般为6次)</h2><h3 id="多头注意力机制"><a href="#多头注意力机制" class="headerlink" title="多头注意力机制"></a>多头注意力机制</h3><h3 id="Add-Norm"><a href="#Add-Norm" class="headerlink" title="Add&amp;Norm"></a>Add&amp;Norm</h3><ol><li>残差结构：将输入矩阵X与上一步得到的矩阵相加，这里是经过多头注意力机制得到的矩阵Z，待会Feed Forward后得到的矩阵还会有一个Add&amp;Norm步骤</li><li>LayerNorm：对一个样本的所有特征计算均值和方差，然后归一化</li></ol><h3 id="Feed-Forward"><a href="#Feed-Forward" class="headerlink" title="Feed Forward"></a>Feed Forward</h3><p>就是普通的全连接网络<br>$$<br>FFN(x) &#x3D; max(0, xW_1 + b_1)W_2 + b_2<br>$$</p><h2 id="Decoder-多次反复使用，一般为6次"><a href="#Decoder-多次反复使用，一般为6次" class="headerlink" title="Decoder(多次反复使用，一般为6次)"></a>Decoder(多次反复使用，一般为6次)</h2><p>与Encoder差不多，但是新增加了一个Masked Multi-Head Attention。</p><h3 id="Masked-Multi-Head-Attention（带掩码的多头注意力机制）"><a href="#Masked-Multi-Head-Attention（带掩码的多头注意力机制）" class="headerlink" title="Masked Multi-Head Attention（带掩码的多头注意力机制）"></a>Masked Multi-Head Attention（带掩码的多头注意力机制）</h3><blockquote><p>Transformer训练过程采用了Teacher Forcing的训练模型，会将原始输入和正确答案都会喂给模型</p></blockquote><p>为了防止模型知道后续输出单词（正确答案）的信息，需要掩码机制掩盖后面词的信息。</p><p>实现方式：构造掩码矩阵（下三角矩阵），将归一化后的注意力分数与掩码矩阵按位相乘。其他部分和多头注意力机制一样。</p><p><img src="/../../images/deepLearning/%E6%8E%A9%E7%A0%81%E7%9F%A9%E9%98%B5.png" alt="掩码矩阵"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://t.csdnimg.cn/lire2">自然语言处理Transformer模型最详细讲解（图解版）</a></p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CLIP</title>
      <link href="/2024/04/26/deeplearning/2024-04-26-clip/"/>
      <url>/2024/04/26/deeplearning/2024-04-26-clip/</url>
      
        <content type="html"><![CDATA[<p>CLIP:Constrastive Language-Image Pre-training</p><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>embedding：一种将高维数据(如文本或图像)转换为较低维度的向量表示的技术</p><h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><p><img src="/../../images/deepLearning/CLIP.png" alt="CLIP结构"></p><h1 id="推理过程"><a href="#推理过程" class="headerlink" title="推理过程"></a>推理过程</h1><p>把需要分类的图片送入image encoder得到特征，拿图片的特征和所有文本特征算余弦相似性，选最相似的那个文本特征对应的句子，从而完成了分类任务</p><h2 id="余弦相似度cosine-similarity"><a href="#余弦相似度cosine-similarity" class="headerlink" title="余弦相似度cosine similarity"></a>余弦相似度cosine similarity</h2><p>用来度量文本与图像之间的对应关系，值越大表示对应关系越强。其实就是计算两个向量夹角的余弦值。</p><h1 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h1><p>图片和文字配对，分别输入到Image Encoder、Text Encoder得到特征。若每个training batch有n个图像-文本对，就可以得到n个图片-文本对。</p><p>配对的图片-文本对就是正样本，描述的是同一个东西。特征矩阵里对角线上的都是正样本，矩阵中非对角线上的元素都是负样本。有了正负样本，模型就可以通过<strong>对比学习</strong>的方式去训练，不需要任何手工标注。</p><h2 id="Image-Encoder：ViT"><a href="#Image-Encoder：ViT" class="headerlink" title="Image Encoder：ViT"></a>Image Encoder：ViT</h2><p>结构如图，概括一下就是一个Patch+Position Embedding加多个Transformer Encoder</p><p><img src="/../../images/deepLearning/ViT%E7%BB%93%E6%9E%84.png" alt="ViT结构"></p><h3 id="一个Patch-Position-Embedding"><a href="#一个Patch-Position-Embedding" class="headerlink" title="一个Patch+Position Embedding"></a>一个Patch+Position Embedding</h3><p>对输入图像进行卷积，得到的矩阵平铺展开为一个一维向量存储图片的序列信息（mx1)。向量中的每个值代表原图像中的一个卷积核大小的块状区域，代表一个序列单元。当然卷积核会有n个，所有是个mxn的特征矩阵</p><blockquote><p>平铺完成后，我们会在图片序列中添加上Cls Token，<strong>该Token会作为一个单位的序列信息</strong>一起进行特征提取，<strong>图中的这个0*就是Cls Token</strong></p></blockquote><p>添加完成Cls Token后，再<strong>为所有特征添加上位置信息</strong>，<strong>这样网络才有区分不同区域的能力</strong>。添加方式其实也非常简单，我们生成一个<strong>197, 768的参数矩阵</strong>，这个参数矩阵是可训练的，把这个矩阵加上<strong>197, 768的特征层</strong>即可。</p><h3 id="多个Transformer-Block"><a href="#多个Transformer-Block" class="headerlink" title="多个Transformer Block"></a>多个Transformer Block</h3><p>上一步获得的序列信息输入，通过自注意力机制，关注每个块的重要程度。</p><ol><li>Multi-Head Attetion</li><li>两个连接层</li></ol><h2 id="Text-Encoder：Bert"><a href="#Text-Encoder：Bert" class="headerlink" title="Text Encoder：Bert"></a>Text Encoder：Bert</h2><p>和Image Encoder类似</p><blockquote><p>补充：</p><ol><li>Unicode编码几乎可以表示全世界的所有语言字符，常说的ASCII编码是Unicode编码的一个子集。Unicode码点是字符在Unicode字符集中的唯一标识，而UTF-8则是将Unicode码点转换为字节序列的一种编码方式。</li><li>UTF-8是Unicode的一种实现方式，也被称为Unicode转换格式（UTF），是“二进制表示”。它是对Unicode字符集进行编码的一种编码方式，给Unicode字符集加了一个存储类型前缀。</li><li>有时为了不让字典太大,只会把出现频次大于某个阈值的词丢到字典里边,剩下所有的词都统一编码成#UNK</li></ol></blockquote><h2 id="综合图像和文本特征"><a href="#综合图像和文本特征" class="headerlink" title="综合图像和文本特征"></a>综合图像和文本特征</h2><p>$$<br>min(\sum_{i&#x3D;1}^N\sum_{j&#x3D;1}^N (I_i \cdot T_j)<em>{i \not&#x3D; j} - \sum</em>{i&#x3D;1}^N (I_i \cdot T_i))<br>$$</p><p>得到图像特征和文本特征后，接下来的训练任务转为最大化 N 个正样本的余弦相似度, 最小化$N^2 - N$个负样本的余弦相似度，即最大化对角线中的数值, 最小化其它非对角线的数值</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.zhihu.com/tardis/zm/art/34656727?source_id=1005">zero-shot learning</a></p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Faster RCNN</title>
      <link href="/2024/04/21/deeplearning/2024-04-21-fasterrcnn/"/>
      <url>/2024/04/21/deeplearning/2024-04-21-fasterrcnn/</url>
      
        <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>bbox(Bouding Box边界框)：包含物体的最小矩形</p><p>NMS(非极大值抑制Non-Maximum Suppression)：选出IoU值最高的框，去掉与它的IoU值较高的框（即重复区域较大），然后再选出IoU次大的框，重复上述过程。</p><p>two-stage方法：如R-CNN系列算法，其主要思路是先通过启发式方法（selective search）或者 CNN 网络（RPN)产生一系列稀疏的候选框，然后对这些候选框进行分类(classification)与回归(bounding box regression)，two-stage方法的优势是准确度高；<br>one-stage方法：如YOLO和SSD，其主要思路是均匀地在图片多个层数的特征图上进行密集抽样，抽样时可以采用不同尺度和长宽比，然后利用CNN提取特征后直接进行分类与回归，整个过程只需要一步，所以其优势是速度快。但是均匀的密集采样的一个重要缺点是训练比较困难，这主要是因为正样本与负样本（背景）极其不均衡，导致模型准确度稍低。</p><h1 id="Fast-RCNN的改进"><a href="#Fast-RCNN的改进" class="headerlink" title="Fast RCNN的改进"></a>Fast RCNN的改进</h1><table><thead><tr><th>RCNN</th><th>Fast RCNN</th></tr></thead><tbody><tr><td>对一张图片提取了大量候选区域，并把它们都输入到CNN进行特征提取，这些候选区域有大量重复，造成特征提取的浪费</td><td>将整个图片归一化后直接送入CNN，<strong>卷积层不进行候选区的特征提取</strong>，在最后一个池化层加入候选区域坐标信息，进行特征提取的计算</td></tr><tr><td>目标分类与候选框的回归是独立的两个操作，并且需要大量特征作为训练样本</td><td>将目标分类与候选框回归统一到CNN网络中来，不需要额外存储特征</td></tr></tbody></table><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p><img src="/../../images/deepLearning/FastRCNN%E6%A1%86%E6%9E%B6.png" alt="FastRCNN框架"></p><h1 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h1><h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><p>提出背景：<strong>Fast R-CNN通过选择性搜索</strong>（selective search）找出所有的候选框，仍然比较耗时</p><p>解决方法：<strong>加入一个提取边缘的神经网络，把找候选框的工作交给这个神经网络（称作Region Proposal Network，RPN）</strong></p><p>具体做法如下：</p><ol><li>将RPN放在一个卷积层的后面</li><li>RPN直接训练得到候选区域</li></ol><h2 id="结构-检测过程"><a href="#结构-检测过程" class="headerlink" title="结构(检测过程)"></a>结构(检测过程)</h2><p>基本框架如下：<br><img src="/../../images/deepLearning/FasterRCNN%E6%A1%86%E6%9E%B6.png" alt="FasterRCNN框架"></p><p>具体结构如下：</p><p><img src="/../../images/deepLearning/FasterRCNN%E5%85%B7%E4%BD%93%E7%BB%93%E6%9E%84.png" alt="FasterRCNN具体结构"></p><h3 id="conv-layers"><a href="#conv-layers" class="headerlink" title="conv layers"></a>conv layers</h3><p>特征提取网络，用于提取特征。通过一组conv+relu+pooling层来提取图像的feature maps。</p><ol><li>13个conv层：kernel_size&#x3D;3,  padding&#x3D;1,  stride&#x3D;1。因为$n &#x3D; \frac{n + 2p - f}{s} + 1$，所以经过每个卷积层后feature map维度不变。</li><li>13个relu层：不改变特征图维度</li><li>4个pooling层：kernel_size&#x3D;2,  padding&#x3D;0,  stride&#x3D;2。每池化一次，特征图维度变为原来的1&#x2F;2，最终变为原来的1&#x2F;16</li></ol><h3 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h3><p>区域候选网络，提前做了一部分检测，完成了目标定位，但还没分出具体类别。流程如下：</p><p>![FasterRCNN RPN部分](..&#x2F;..&#x2F;images&#x2F;deepLearning&#x2F;FasterRCNN RPN部分.png)</p><p>拿到conv layers的feature map（M&#x2F;16 x N&#x2F;16）后，先经过一个3x3卷积，卷积核个数为256，所以通过这个卷积层后feature map的通道数也是256(M&#x2F;16 x N&#x2F;16 x 256)。</p><p>之后分成两个任务：</p><ul><li><p>上部分cls layer分类：判断所有预设anchor内是否有目标（二分类），即是正样本（positive）还是负样本（negative）。</p><blockquote><p>补充anchor：对于feature maps的每一个像素点，设置3 x 3种预设anchor，比例3种：1:1、1:2、2:1；边长3种：按原始目标大小灵活设置。这样比例和边长一一配对就可以得到3x3&#x3D;9种预设锚框。</p></blockquote><ol><li>设anchor种类为k(即上文的9个)。M&#x2F;16 x N&#x2F;16 x 256的特征经过1x1卷积就得到了(M&#x2F;16)x(N&#x2F;16)x2k的输出.“2”是因为这里做的是一个二分类且用的softmax，所以feature map上每个点的每个anchor对应2个值。</li><li>reshape层对feature map进行维度变换，使得有一个单独的维度为2 ，方便在softmax进行操作</li><li>softmax进行分类</li><li>reshape恢复原状</li></ol></li><li><p>下部分reg layer回归：bbox regression(边界框修正)，修正anchors得到较为准确的proposals</p><p>(M&#x2F;16)x(N&#x2F;16)x256的特征通过1x1卷积得到(M&#x2F;16)x(N&#x2F;16)x4k的输出，“4”是因为这里是生成每个anchor的坐标偏移量（用于修正anchor），[tx,ty,tw,th]共4个所以是4k。注意，这里输出的是<strong>坐标偏移量</strong>，不是坐标本身，要得到修正后的anchor还要用原坐标和这个偏移量运算一下才行。</p></li></ul><p>两个任务再proposal层合并，proposal层负责综合正样本positive anchor和对应bbox修正后得到的proposals，输出一系列proposals左上角和右下角坐标轴，同时剔除太小和超出边界的proposal。</p><h3 id="RoI-Pooling（兴趣域池化）"><a href="#RoI-Pooling（兴趣域池化）" class="headerlink" title="RoI Pooling（兴趣域池化）"></a>RoI Pooling（兴趣域池化）</h3><ol><li><p>收集RPN生成的proposals，并将每个proposal映射到对应feature map中的区域</p></li><li><p>把这个区域划分成pooled_w x pooled_h个网格</p></li><li><p>对网格的每部分做max pooling</p><blockquote><p>这么做是因为全连接层每次输入特征的维度必须是相同的。这样保证大小不同的proposal最后输出都是相同大小（pooled_w x pooled_h）。</p></blockquote></li><li><p>生成的结果proposals feature maps（pooled_w x pooled_h x 256）送入后续全连接层继续做分类（具体哪一个类别）和回归。</p></li></ol><h3 id="classification-and-regression"><a href="#classification-and-regression" class="headerlink" title="classification and regression"></a>classification and regression</h3><ul><li>利用proposals feature maps计算出具体的类别</li><li>再做一次bbox regression获得检测框最终的精确位置。</li></ul><h2 id="训练过程（two-stage）"><a href="#训练过程（two-stage）" class="headerlink" title="训练过程（two stage）"></a>训练过程（two stage）</h2><p><img src="/../../images/deepLearning/FasterRCNN%E5%8F%8C%E9%98%B6%E6%AE%B5.png" alt="FasterRCNN双阶段检测"></p><ul><li>训练RPN网络</li><li>训练分类网络</li></ul><p><img src="/../../images/deepLearning/FasterRCNN%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.png" alt="训练过程"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://blog.csdn.net/kk123k/article/details/86515513">R-CNN论文详细解读</a></p><p><a href="http://t.csdnimg.cn/PnIKI">Faster RCNN</a></p><p>[超级详细的Faster RCNN解读](一文读懂Faster RCNN - 你再好好想想的文章 - 知乎<br><a href="https://zhuanlan.zhihu.com/p/31426458">https://zhuanlan.zhihu.com/p/31426458</a>)</p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>OO第二单元总结</title>
      <link href="/2024/04/20/oo/2024-04-20-oo-unit2-summary/"/>
      <url>/2024/04/20/oo/2024-04-20-oo-unit2-summary/</url>
      
        <content type="html"><![CDATA[<h2 id="架构分析"><a href="#架构分析" class="headerlink" title="架构分析"></a>架构分析</h2><h3 id="第一次作业"><a href="#第一次作业" class="headerlink" title="第一次作业"></a>第一次作业</h3><p><img src="/../../images/OO/unit2-1.png" alt="第一次作业架构"></p><p>三种线程：输入线程、调度线程、电梯线程</p><p>输入线程和调度线程共享waitQueue队列，调度线程和电梯线程共享processingQueue队列（有六个，放一个列表里统一管理）。</p><p>Passengers类用来放进入电梯的乘客，其实和RequestQueue类差不多，但是因为这部分不需要同步控制，所以很多操作都不需要，于是我新建了一个Passenger类管理。</p><p>Strategy我按指导书的要求建了这么一个类，不过在后面的作业中发现这个类好像没什么用，我就删掉了。</p><h3 id="第二次作业"><a href="#第二次作业" class="headerlink" title="第二次作业"></a>第二次作业</h3><p><img src="/../../images/OO/unit2-2.png" alt="第二次作业架构"></p><p>第二次作业增加了电梯重置请求，我在第一次作业的基础上做出了如下修改：</p><ol><li><p>修改单电梯调度：研讨课发现好多人都用的LOOK算法，比我自己写的逻辑清晰很多，所以第二次作业我也改为Look算法，参考了往年的学长的博客，电梯的Action分为：OPEN、CLOSE、REVERSE、MOVE、WAIT。每次都从T_T中选择一种，然后调整电梯的属性。</p></li><li><p>增加多电梯调度：receive方法拒绝自由竞争，我用的均分方法，但是忽略了高并发的问题，强测别狠狠hack了T_T</p></li><li><p>增加reset处理：本来尝试新增SafeResetRqst类，增加ArrayList&lt;SafeResetRqst&gt;  resetRequests对象，作为InputThread和ElevatorThread之间的一个托盘，但是导致ScheduleThread不太好分配（可能出现检测到某个电梯的resetRqst为空，然后在往该电梯的请求队列中分配请求时该电梯的resetRqst不为空的清空）。</p><p>于是换成新增ResetTable类，每个电梯都可以与InputThread、ScheduleThread共享resetTable对象，但是只改变自己对应的resetRequest，然后ScheduleThread中多电梯调度通过调用resetTable类中的dispatch方法实现。</p></li><li><p>结束条件改变：因为waitQueue会重新接受来自电梯乘客表、等待队列的请求，所以ScheduleThread、ElevatorThread结束条件改变。我参考了往年学长的方法，用了单例模式设置一个Counter类的counter对象来计数，当InputThread结束且总请求数sum&#x3D;&#x3D;完成请求数finished时，则可以结束ScheduleThread、ElevatorThread。</p></li></ol><h3 id="第三次作业"><a href="#第三次作业" class="headerlink" title="第三次作业"></a>第三次作业</h3><p><img src="/../../images/OO/unit2-3.png" alt="unit2-3"></p><p>第三次作业增加了重置为双轿电梯的请求。我在第二次作业的基础上做了比较大的改动，具体有如下几个方面：</p><ol><li>增加类ElevatorFactory：使用简单工厂模式生产不同的电梯，同时把需要共享的对象waitQueue、processQueues、resetTable作为ElevatorFactory类的属性，这样可以在”生产”电梯时给每个电梯“装配”这些属性。此外，这个类我也使用了单例模式，方便在其他类调用这个类里的方法。</li><li>增加类DoubleElevatorA、DoubleElevatorB管理双轿电梯：SingleElevator、DoubleElevatorA、DoubleElevatorB都是ElevatorThread的子类，其中SingleElevator就是之前作业实现的普通的单轿厢电梯</li><li>新建了一个类Status让双轿电梯共享彼此的状态：同一个井道的两个电梯必须知道互相的状态，避免在换乘楼层发生碰撞。</li><li>DoubleElevator的单电梯调度策略：在Look算法的基础上做了以下两点修改<ol><li>在电梯里没人且电梯请求队列为空时，增加了一个判断“电梯如果在换乘楼层，则继续移动一层”：为了防止两个轿厢相撞，电梯最好不要在换乘楼层久待，所以没请求的时候就赶紧离开</li><li>电梯的Action枚举里增加了一个动作FORCE_OPEN_AND_REVERSE，即电梯到达换乘层时必须强制开门把电梯里的乘客仍回waitQueue，然后转向：这个动作放在LOOK算法的实现方法getAction()的最开始判断。为什么要把FORCE_OPEN和REVERSE这个动作放一起呢？最开始没理清，没把这两个放一起，导致之前的代码其他的动作判断全都得加判断“电梯如果在换乘楼层，根据方向判断是否需要反向，如果不需要转向再判断…(原本的LOOK算法逻辑)”。后来突然意识到电梯到达换乘楼层就肯定不能继续MOVE了，一定要转向的（REVERSE），那干脆这两个动作就放一起好了（感觉这个就很像OS里说的原语，不可分割）。这样之前的代码逻辑除了上面说的那一点，其它都不用改动了。</li></ol></li><li>删除strategy类：第三次作业了，我仍不知道这个类有什么作用，所有就把它删掉然后把单电梯调度策略写在电梯线程里了。</li></ol><h3 id="协作图"><a href="#协作图" class="headerlink" title="协作图"></a>协作图</h3><p><img src="/../../images/OO/unit2-%E5%8D%8F%E4%BD%9C%E5%9B%BE.png" alt="unit2-协作图"></p><p>三个线程组成两个“生产者-消费者”模式，其中电梯线程重置时需要将未完成的请求重新传递回总请求队列，再次由调度线程分配。</p><h3 id="变与不变"><a href="#变与不变" class="headerlink" title="变与不变"></a>变与不变</h3><p>三次作业中，请求队列表和电梯里的乘客表没有特别大变化，三个线程的结构没变，但是每个线程内部易变</p><ol><li>输入线程：请求类型增加，逻辑修改简单，只需略微修改</li><li>调度线程：分配策略需要改动</li><li>电梯线程：随着电梯类型的改变，电梯的调度策略有略微变化</li></ol><h2 id="同步块的设置和锁的选择"><a href="#同步块的设置和锁的选择" class="headerlink" title="同步块的设置和锁的选择"></a>同步块的设置和锁的选择</h2><p>同步块我全部使用的方法同步块，听到好几个同学代码块同步造成“缝隙”出现难以复现的bug，感觉还是在方法里同步不容易出问题（虽然可能会造成一些不必要的同步影响性能）。大多数共享对象的类里的方法我都是用synchronized修饰来同步，最后一次作业为了防止两个轿厢相撞新建的类Status里，我用的是读写锁。因为感觉大部分的共享对象还是写操作为主，读操作不多，用读写锁收益不大（<del>但是好歹学了读写锁，还是想用用，所以最后一次作业尝试了一下</del>），而且读写锁不能直接用wait()，实现等待需要新建一个Condition类的对象与锁关联，有点麻烦。</p><h2 id="调度器设计"><a href="#调度器设计" class="headerlink" title="调度器设计"></a>调度器设计</h2><p>调度器单开一个线程ScheduleThread，当一个“中间商”，从Input Thread的总请求池拿请求，然后根据自己的调度策略分配给特定电梯的请求队列。</p><h3 id="调度策略"><a href="#调度策略" class="headerlink" title="调度策略"></a>调度策略</h3><p>第一次作业不需要自己实现调度策略。</p><p>第二次作业用的均分策略，设置一个circleNum，从0-5循环，每次分配完一个请求就+1，等于6就归零。如果当前circleNum对应的电梯在重置，就跳过。但是这么分其实并不完全平均，所以互测被hack了（详见bug分析）</p><p>第三次作业的调度策略可能是估算等待时间和权重赋值的结合吧。因为第二次作业性能挺差的，然后第三次作业的时间较为充裕，所有还是想改改调度策略。调度逻辑如下：</p><ul><li>对于每个请求者，遍历所有电梯</li><li>对于每一个电梯<ul><li><p>查看电梯的当前状态，计算电梯移动到请求者所在楼层需要多久。</p></li><li><p>考虑一些特殊情况：</p><ul><li>对于单轿电梯，如果当前电梯在<strong>重置</strong>，score翻倍。</li><li>如果当前电梯的<strong>请求队列人数过多</strong>（这个“多”的权值自己设置，我设置的是超过电梯最大限乘人数就算多），score翻倍。</li><li>对于双轿电梯，如果该请求者能进去该电梯但是该电梯<strong>不能直接把它运送到目的地</strong>，score翻倍。</li></ul></li></ul></li><li>找出score分最小的电梯，准备把请求者分配给它。<ul><li>如果该电梯还在重置，就等它重置完再把请求者加入到它的等待队列。</li><li>如果该电梯不在重置或者是双轿电梯，就直接把请求者加入到它的等待队列。</li></ul></li></ul><p>可以看出来，这个分配策略非常粗糙，处处透着不严谨：时间计算不严谨，不考虑同步问题，只看开始计算这一瞬间电梯状态如何；权重赋值不严谨，对于重置、请求队列人数过多、不能直接运送到目的地这些特殊情况我都直接当成效果差不多的不利条件，都把score分翻倍，没有赋予不同的权值。但是最终分配策略的效果似乎还可以？反正强测性能分还不错，挺让我意外的。但是其实这个分配策略对高并发的处理依旧不完善（见bug分析）</p><h2 id="bug分析"><a href="#bug分析" class="headerlink" title="bug分析"></a>bug分析</h2><p>第一次作业没用LOOK写单电梯调度策略，然后自己设计的策略逻辑又非常复杂，导致电梯出现移动到非法楼层的问题，bug出现在中测，强测、互测没出问题。</p><p>第二次作业在互测被高并发的数据点hack到了，因为如果某一时刻重置的电梯很多，并且这一时刻来了大量请求，就会出现所有请求都被分配给那个没重置的电梯的情况。于是修改成每个电梯请求队列设置一个上限，超过了就不再分配，同时让重置的电梯可以接受请求者。</p><p>第三次作业再次被高并发的数据点hack（<del>有时候真的被自己蠢笑了</del>），因为我调度策略大改，然后这个地方又没考虑周全，当时想着我重置状态的电梯可以分配请求应该就没问题吧，就没细想，然后再次被hackT_T。原因就出在我的score在“请求队列人数多”这个特殊情况只是简单的翻倍，bug修复我把这里改成score *&#x3D; 请求队列人数 &#x2F; 该电梯最大限乘人数。</p><h2 id="心得体会"><a href="#心得体会" class="headerlink" title="心得体会"></a>心得体会</h2><p>其实很喜欢这个单元结合实际、贴近生活的题目，虽然刚开始写多线程非常地痛苦，因为无法单步调试，debug十分困难，尤其是在第二次作业，需要把未完成的请求者扔回总请求队列，并且ScheduleThread、ElevatorThread线程的结束条件要改变，稍有不甚就死锁了，我反复删删改改才比较完美地实现了线程控制。不过虽然过程很痛苦，结果还是不错的，至少这个单元我在强测没有因为同步控制不当出现线程不安全的bug。</p><p>以下是一些个人实现同步控制过程中困惑&#x2F;不理解的概念的总结。</p><p>synchronized修饰方法的理解：</p><ul><li>如果一个类A里有多个synchronized修饰的方法，对于这个类的一个实例对象a，同一时刻只有一个synchronized方法可能被访问。因为锁的是这个实例对象。</li><li>如果一个类A里有个synchronized修饰的方法，对于这个类的多个实例对象a1,a2,a3…每个实例的这个方法都可以被不同的线程同时访问。</li><li>对于一类的对象，在synchronized修饰的方法里调用此对象的另一个synchronized修饰的方法是可行的。同样因为这个对象已经获得了锁。</li></ul><p>传给方法的参数是对对象的引用，在方法里改变这个对象是在改变这个对象本身</p><p>wait和sleep的使用：</p><p>synchronized修饰的代码块里(假设对象叫a)如果需要等待应该用a.wait(); 方法里需要线程sleep可以写成Thread.sleep()</p><table><thead><tr><th></th><th>直接调用run</th><th>线程调度执行run</th></tr></thead><tbody><tr><td></td><td>不会创建新的线程。因此，它不会表现出任何并发性。</td><td><code>start</code>方法会启动一个新的线程，并在该新线程的上下文中异步执行<code>run</code>方法</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> OO </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>视觉开发认知和检测</title>
      <link href="/2024/04/20/deeplearning/2024-04-20-yolo-world/"/>
      <url>/2024/04/20/deeplearning/2024-04-20-yolo-world/</url>
      
        <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>zero-shot learning(零样本学习)：让机器具有推理能力，例如在目标检测中，希望模型可以对从未见过的类别进行分类</p><p>开放世界目标检测：在每一个场景中检测每一个类别，应该有能力利用具有异构标签空间的多个来源的图像用于训练和推广到开放世界进行推理</p><p>开放的含义：一般情况下，模型是根据预先打好的标签来检测目标，但是这样的模型能够检测的目标类型是有限的。“开放”就是希望模型不受预先定义好的标签类别限制。</p><h2 id="多模态"><a href="#多模态" class="headerlink" title="多模态"></a>多模态</h2><p>概念：多种形态的信息（例如声音、文字、图像等）一起协作推理</p><p>结合计算机视觉和自然语言处理领域的多模态任务：让机器通过构建能够联合多种模态信息的模型来捕捉不同模态之间的对应关系和语义特征，从而能够同时处理多种形式的数据（图像、音频、文本等），加深机器对现实世界的感知。例如图像描述，我们不仅希望机器识别出实体对象及其标签，还希望它能够描述图像中实体之间的关系，以文本的形式描述出来。</p><h2 id="yolo-world：轻量级的开放词汇检测器"><a href="#yolo-world：轻量级的开放词汇检测器" class="headerlink" title="yolo-world：轻量级的开放词汇检测器"></a>yolo-world：轻量级的开放词汇检测器</h2><p><a href="https://www.bilibili.com/read/cv31740783/">参考</a></p><p>没有使用在线词汇，而是提出了一种“先提示后检测”的推理范式。具体如下：</p><ul><li><p>使用在线词汇进行训练。在训练过程中，为每个包含4张图像的mosaic样本构建一个在线词汇T。具体做法是，从mosaic图像中抽样所有涉及的正面名词，并从相应的数据集中随机抽样一些负面名词。</p></li><li><p>随后使用离线词汇进行推理。在推理阶段，采用一种”先提示-再检测”的策略，使用离线词汇以提高效率。用户可以定义一系列自定义提示，然后利用文本编码器对这些提示进行编码，并获得离线词汇嵌入。</p></li></ul><p>架构：</p><ol><li>文本编码器对输入文本进行编码。</li><li>图像编码器将输入图像编码为多尺度图像特征</li><li>图像和文本特征利用RepVL-PAN实现多级跨模态融合。</li><li>YOLO-World预测回归的边界框和对象嵌入，以匹配输入文本中出现的类别或名词。</li></ol>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>进程管理</title>
      <link href="/2024/04/10/os/2024-04-10-os-jin-cheng/"/>
      <url>/2024/04/10/os/2024-04-10-os-jin-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h1><h2 id="进程概念的引入"><a href="#进程概念的引入" class="headerlink" title="进程概念的引入"></a>进程概念的引入</h2><h3 id="两个基本概念：并发与并行"><a href="#两个基本概念：并发与并行" class="headerlink" title="两个基本概念：并发与并行"></a>两个基本概念：并发与并行</h3><p>并发：宏观同时，微观交替</p><p>并行：同时</p><h3 id="并发性的确定–Bernstein条件"><a href="#并发性的确定–Bernstein条件" class="headerlink" title="并发性的确定–Bernstein条件"></a>并发性的确定–Bernstein条件</h3><p>定义：</p><ul><li>R(Si)：Si的读子集, 其值在Si中被引用的变量的集合</li><li>W(Si)：Si的写子集, 其值在Si中被改变的变量的集合</li></ul><p>Bernstein条件：</p><p>两个进程S1和S2可并发，当且仅当下列条件同时成</p><p>立：</p><ul><li>R(S1) ∩ W(S2) &#x3D; Φ</li><li>W(S1) ∩ R(S2) &#x3D; Φ</li><li>W(S1) ∩ W(S2) &#x3D; Φ</li></ul><p>Bernstein条件是判断程序并发执行结果是否可再现的充分条件。</p><p>进程的定义和特征</p><ul><li>进程是程序的一次执行；</li><li>进程是可以和别的计算并发执行的计算；</li><li>进程可定义为一个数据结构，及能在其上进行操作的一个程序；</li><li>进程是一个程序及其数据在处理机上顺序执行时所发生的活动；</li><li>进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。</li></ul><p>一个进程应该包括：</p><ul><li>程序的代码</li><li>程序的数据</li><li>PC中的值</li><li>一组通用的寄存器的当前值，堆、栈</li><li>一组系统资源（如打开的文件）</li></ul><p>进程与程序的区别</p><table><thead><tr><th></th><th>进程</th><th>程序</th></tr></thead><tbody><tr><td></td><td>动态</td><td>静态</td></tr><tr><td></td><td>暂时</td><td>永久</td></tr><tr><td>组成</td><td>程序、数据和进程控制块</td><td></td></tr><tr><td>两者之间的对应关系</td><td>通过多次执行，一个程序可以对应多个进程</td><td>通过调用关系，一个进程可包括多个程序</td></tr></tbody></table><h2 id="进程状态与控制"><a href="#进程状态与控制" class="headerlink" title="进程状态与控制"></a>进程状态与控制</h2><h3 id="进程控制"><a href="#进程控制" class="headerlink" title="进程控制"></a>进程控制</h3><p>进程控制的主要任务是创建和撤销进程，以及实现进程的状态转换。<strong>由内核来实现</strong></p><h4 id="原语"><a href="#原语" class="headerlink" title="原语"></a>原语</h4><p>由若干条指令所组成的指令序列，来实现某个特定操作功能。</p><ul><li>指令序列是连续的，不可分割</li><li>是操作系统核心组成部分</li><li>必须在管态（内核态）下执行，且常驻内存</li></ul><p>与系统调用的区别：不可中断</p><p>创建原语：fork, exec</p><p>在fork函数执行完毕后，如果创建新进程成功，则出现两个进程，一个是子进程，一个是父进程。在子进程中，fork函数返回0，在父进程中，fork返回新创建<strong>子进程的进程ID</strong>。我们可以通过fork返回的值来判断当前进程是子进程还是父进程。如果出现错误，fork返回一个负值。</p><p>撤消原语：kill</p><h3 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h3><p>就绪状态：进程已获得除处理机外的所需资源，等待分配处理机资源；只要分配CPU就可执行。</p><p>执行状态：占用处理机资源；处于此状态的进程的数目小于等于CPU的数目。在没有其他进程可以执行时（如所有进程都在阻塞状态），通常会自动执行系统的idle进程（相当于空操作）。</p><p>阻塞状态：正在执行的进程，由于发生某种事件而暂时无法执行，便放弃处理机处于暂停状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">A[执行状态] --&gt; |等待某个事件|B[阻塞状态]</span><br><span class="line">B --&gt; |事件发生|C[就绪状态]</span><br><span class="line">A --&gt; |时间片到|C</span><br><span class="line">C --&gt; |调度|A</span><br></pre></td></tr></table></figure><h3 id="进程控制块"><a href="#进程控制块" class="headerlink" title="进程控制块"></a>进程控制块</h3><p>系统为每个进程定义了一个数据结构：进程控制块PCB（Process Control Block）。</p><p>作用：</p><ul><li>进程创建、撤消；</li><li>进程唯一标志；</li></ul><p>进程控制块是进程管理和控制的最重要的数据结构，每一个进程均有一个PCB，在创建进程时，建立PCB，伴随进程运行的全过程，直到进程撤消而撤消</p><p>内容：</p><ul><li>进程标识符：唯一。可以是字符串，也可以是一个数字（Linux系统中是一个整型数）。在进程创建时由系统赋予。</li><li>程序和数据地址</li><li>当前状态：为了管理的方便，系统设计时会将相同的状态的进程组成一个队列，如就绪进程队列，等待进程则要根据等待的事件组成多个等待队列，如等待打印机队列、等待磁盘I&#x2F;O完成队列等等</li><li>现场保留区</li><li>互斥和同步机制：用于实现进程间互斥、同步和通信所需的信号量等</li><li>进程通信机制</li><li>优先级：反映进程的紧迫程度，通常由用户指定和系统设置。</li><li>资源清单：列出所拥有的除CPU外的资源记录，如拥有的I&#x2F;O设备、打开的文件列表等。</li><li>链接字：根据进程所处的执行状态，进程相应的PCB加入到不同队列中。PCB链接字指出该进程所在队列中下一个进程PCB的首地址。</li><li>家族关系 …</li></ul><h3 id="PCB组织方式"><a href="#PCB组织方式" class="headerlink" title="PCB组织方式"></a>PCB组织方式</h3><p>线性表：适用于系统中进程数目不多的情况</p><p>索引方式：是线性表的改进，系统按照进程的状态分别建立就绪索引表、阻塞索引表。</p><h3 id="辨析：进程上下文切换vs陷入内核"><a href="#辨析：进程上下文切换vs陷入内核" class="headerlink" title="辨析：进程上下文切换vs陷入内核"></a>辨析：进程上下文切换vs陷入内核</h3><table><thead><tr><th></th><th>进程上下文切换（Process Context Switch</th><th>陷入&#x2F;退出内核（也称为模态切换，Mode Switch）</th></tr></thead><tbody><tr><td></td><td>通常由调度器执行，保存进程执行断点，切换内存映射(页表基址，flush TLB)</td><td>CPU状态改变，由中断、异常、Trap指令（系统调用）引起，需要保存执行现场（寄存器、堆栈等）</td></tr><tr><td></td><td>进程上下文切换过程一定会陷入内核</td><td>陷入内核不一定会导致进程切换</td></tr><tr><td></td><td></td><td>系统调用涉及到进程从用户态到内核态的切换（mode switch），这个时候涉及到的切换主要是寄存器上下文的切换，和通常所说的进程上下文切换不同，mode switch的消耗相对要小得多</td></tr></tbody></table><h2 id="线程概念的引入"><a href="#线程概念的引入" class="headerlink" title="线程概念的引入"></a>线程概念的引入</h2><h3 id="线程的提出"><a href="#线程的提出" class="headerlink" title="线程的提出"></a>线程的提出</h3><p>进程的不足：</p><ul><li>进程只能在一个时间处理一个任务，不能同时处理多个任务。</li><li>如果进程在执行时阻塞，整个进程都无法继续执行。</li></ul><p>需要一种新的实体，满足：</p><ul><li>实体之间可以并发地执行</li><li>实体之间共享相同的地址空间</li></ul><h3 id="进程与线程-1"><a href="#进程与线程-1" class="headerlink" title="进程与线程"></a>进程与线程</h3><p>实际上，进程包含了两个概念：资源拥有者和可执行单元。现代操作系统<strong>将资源拥有者称为进程，将可执行单元称为线程</strong>。线程将资源与计算分离，提高并发效率。</p><table><thead><tr><th></th><th>进程</th><th>线程</th></tr></thead><tbody><tr><td>基本概念</td><td>程序的一次执行</td><td>进程中的可执行单元，进程中的一个实体，可以与其他同进程的线程共享进程拥有的所有资源，同时也拥有栈、PC等私有资源</td></tr><tr><td>资源共享</td><td>资源分配的单位，拥有运行程序所需要的全部资源</td><td>CPU调度的单位，只拥有必不可少的少量资源</td></tr><tr><td>系统开销</td><td>创建&#x2F;撤销&#x2F;切换&#x2F;同步进程的开销大</td><td>系统开销小</td></tr><tr><td>并发程度</td><td>低</td><td>高</td></tr></tbody></table><p>创建一个线程比一个进程快19-100倍。对于存在大量计算和大量I&#x2F;O处理的应用，大幅度提高性能。在多CPU&#x2F;多核CPU系统中更有优势。</p><h2 id="线程的实现方式"><a href="#线程的实现方式" class="headerlink" title="线程的实现方式"></a>线程的实现方式</h2><h3 id="用户级线程"><a href="#用户级线程" class="headerlink" title="用户级线程"></a>用户级线程</h3><p>线程在用户空间,通过library模拟的thread,不需要或仅需要极少的kernel支持。上下文切换比较快,因为不用更改page table等,使用起来较为轻便快速。提供操控视窗系统的较好的解决方案</p><p>优点：</p><ul><li>线程切换与内核无关</li><li>线程的调度由应用决定，容易进行优化。</li><li>可运行在任何操作系统上，只需要线程库的支持</li></ul><p>不足：</p><ul><li>很多系统调用会引起阻塞，内核会因此而阻塞所有相关的线程。</li><li>内核只能将处理器分配给进程，即使有多个处理器，也无法实现一个进程中的多个线程的并行执行</li></ul><h3 id="内核级线程"><a href="#内核级线程" class="headerlink" title="内核级线程"></a>内核级线程</h3><p>内核级线程就是kernel有好几个分身，一个分身可以处理一件事。这用来处理非同步事件很有用，kernel可以对每个非同步事件产生一个分身来处理。支持内核线程的操作系统内核称作多线程内核。</p><p>优点：</p><ul><li>内核可以在多个处理器上调度一个进程的多个线程实现同步并行执行</li><li>阻塞发生在线程级别</li><li>内核中的一些处理可以通过多线程实现</li></ul><p>缺点：</p><ul><li>一个进程中的线程切换需要内核参与，线程的切换涉及到两个模式的切换（进程-进程、线程-线程）</li><li>降低效率</li></ul><h3 id="用户级线程和内核级线程的比较"><a href="#用户级线程和内核级线程的比较" class="headerlink" title="用户级线程和内核级线程的比较"></a>用户级线程和内核级线程的比较</h3><ul><li>用户级线程执行系统调用指令时将导致其所属进程的执行被暂停，而内核级线程执行系统调用指令时，只导致该线程被暂停。</li><li>在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核级线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度</li><li>用户级线程的程序实体是运行在用户态下的程序，而内核级线程的程序实体则是可以运行在任何状态下的程序</li></ul><h3 id="混合实现方式"><a href="#混合实现方式" class="headerlink" title="混合实现方式"></a>混合实现方式</h3><p>线程在用户空间创建和管理，需要实现从用户空间的线程到内核空间线程（轻量级进程）的映射。</p><h1 id="同步与互斥"><a href="#同步与互斥" class="headerlink" title="同步与互斥"></a>同步与互斥</h1><h2 id="同步与互斥问题"><a href="#同步与互斥问题" class="headerlink" title="同步与互斥问题"></a>同步与互斥问题</h2><p>临界资源：一次仅允许一个进程访问的资源。</p><p>临界区：每个进程中访问临界资源的那段<strong>代码</strong>称为临界区。</p><p>进程互斥：某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。互斥无法限制访问者对资源的访问顺序，即访问是<strong>无序访问</strong>。</p><p>进程同步：指<strong>在互斥的基础上</strong>，通过其他机制实现访问者对资源的<strong>有序访问</strong>。在大多数情况下，同步已经实现了互斥，特别是所有对资源的写入的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源。</p><p>临界区管理应满足的条件：</p><ul><li><strong>空闲让进</strong>：临界资源处于空闲状态，允许进程进入临界区。临界区内仅有一个进程运行。</li><li><strong>忙则等待</strong>：临界区有正在执行的进程，所有其他进程则不可以进入临界区。</li><li><strong>有限等待</strong>：对要求访问临界区的进程，应保证在有限时间内进入自己的临界区，避免死等。</li><li><strong>让权等待</strong>：当进程（长时间）不能进入自己的临界区时，应立即释放处理机，尽量避免忙等。</li></ul><h2 id="基于忙等待的互斥方法"><a href="#基于忙等待的互斥方法" class="headerlink" title="基于忙等待的互斥方法"></a>基于忙等待的互斥方法</h2><h3 id="软件方法"><a href="#软件方法" class="headerlink" title="软件方法"></a>软件方法</h3><h4 id="Dekker算法"><a href="#Dekker算法" class="headerlink" title="Dekker算法"></a>Dekker算法</h4><p>第一个不需要严格轮换的互斥算法。</p><p>引入变量turn，以便在竞争时选出进入临界区的进程</p><p>pturn&#x2F;qturn表示“我”想进入临界区，turn表示该哪个进程进入临界区了（轮流进）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">P:</span><br><span class="line">......</span><br><span class="line">pturn = true;//I want to enter</span><br><span class="line">while(qturn) &#123;// other wants to enter</span><br><span class="line">if (turn == 1) &#123;//it&#x27;s not my turn</span><br><span class="line">pturn = false;//I (temporarily) don&#x27;t want to enter</span><br><span class="line">while(turn == 1); // The other is automatically allowed to enter</span><br><span class="line">// other don&#x27;t want to enter</span><br><span class="line">pturn = true;// I want to enter</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">// other doesn&#x27;t want to enter</span><br><span class="line">//临界区</span><br><span class="line">turn = 1;// it&#x27;s the other&#x27;s turn</span><br><span class="line">pturn = false;// I don&#x27;t want to enter</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">Q:</span><br><span class="line">......</span><br><span class="line">qturn = true;</span><br><span class="line">while(pturn) &#123;</span><br><span class="line">if (turn == 0) &#123;</span><br><span class="line">pturn = false;</span><br><span class="line">while(turn == 0);</span><br><span class="line">qturn = true;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">//临界区</span><br><span class="line">turn = 0;</span><br><span class="line">qturn = false;</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h4 id="Peterson算法"><a href="#Peterson算法" class="headerlink" title="Peterson算法"></a>Peterson算法</h4><p>解决了互斥访问的问题，而且克服了强制轮流法的缺点，可以完全正常地工作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#define FALSE O</span><br><span class="line">#define TRUE 1</span><br><span class="line">#define N 2 //进程的个数</span><br><span class="line">int turn; //轮到谁?</span><br><span class="line">int interested[N]; //兴趣数组，初始值均为FALSE</span><br><span class="line">void enter_region(int process)//process=0或1</span><br><span class="line">&#123;</span><br><span class="line">//另外一个进程的进程号</span><br><span class="line">    int other;</span><br><span class="line">    other = 1 - process;</span><br><span class="line">    //表明本进程感兴趣</span><br><span class="line">    interested[process]=TRUE;</span><br><span class="line">    turn = other;//设置标志位</span><br><span class="line">    //other也可以换成process，这其实是两种方式：谦让式vs争夺式</span><br><span class="line">    while(turn == other &amp;&amp; interested[other]==TRUE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void leave_region(int process) &#123;</span><br><span class="line">interested[process] = FALSE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Bakery-Algorithm-面包店算法"><a href="#Bakery-Algorithm-面包店算法" class="headerlink" title="Bakery Algorithm(面包店算法)"></a>Bakery Algorithm(面包店算法)</h4><ul><li>在进入临界区之前，进程收到一个数字，具有最小数字的进程被允许进入临界区</li><li>如果进程 Pi 和 Pj 接收到相同数字, if i &lt; j, then Pi 进入临界区；否则，Pj 进入临界区</li><li>产生的数字总是递增的，例如：1,2,3,3,3,3,4,5…</li></ul><h3 id="硬件方法"><a href="#硬件方法" class="headerlink" title="硬件方法"></a>硬件方法</h3><h4 id="中断屏蔽方法"><a href="#中断屏蔽方法" class="headerlink" title="中断屏蔽方法"></a>中断屏蔽方法</h4><p>使用“开关中断”指令。执行“关中断”指令，进入临界区操作；退出临界区之前，执行“开中断”指令。</p><p>优点：简单</p><p>缺点：</p><p>不适用于多CPU系统</p><p>往往会带来很大的性能损失。很多日常任务都是靠中断机制触发的，比如时钟，如果屏蔽中断，会影响时钟和系统效率。</p><p>用户进程的使用可能很危险，例如：关中断之后，不再打开中断，会导致整个系统无法继续运行。所以，使用范围一般为内核进程（少量使用）。</p><h4 id="使用test-and-set指令"><a href="#使用test-and-set指令" class="headerlink" title="使用test and set指令"></a>使用test and set指令</h4><p>TS（test-and-set ）是一种不可中断的基本原语（指令）。它会把“1”写到某个内存位置并传回其旧值。在多进程可同时访问内存的情况下，如果一个进程正在执行TS指令，在它执行完成前，其它的进程不可以执行TS指令。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TestAndSet(boolean_ref *lock) &#123; </span><br><span class="line">    boolean initial = *lock; </span><br><span class="line">    *lock = true; </span><br><span class="line">    return initial; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="自旋锁Spinlocks"><a href="#自旋锁Spinlocks" class="headerlink" title="自旋锁Spinlocks"></a>自旋锁Spinlocks</h4><p>利用test_and_set硬件原语提供互斥支持。通过对总线的锁定实现对某个内存位置的原子读与更新。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">acquire(int *lock) &#123;</span><br><span class="line">    while(test_and_set(lock) == 1)</span><br><span class="line">    /* do nothing */;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">release(int *lock) &#123;</span><br><span class="line">*lock = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当lock &#x3D;&#x3D; 0时，线程执行完acquire获得锁，lock被修改为1。其他线程想获得锁时，执行acquire会被卡在while循环里，直到获得线程的锁执行完释放锁。</p><h3 id="几个算法的共性问题"><a href="#几个算法的共性问题" class="headerlink" title="几个算法的共性问题"></a>几个算法的共性问题</h3><p>无论是软件还是硬件方法，解法都是正确的，但它们都有一个特点：当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。造成：</p><ul><li>忙等待，浪费CPU时间</li><li>优先级反转：低优先级进程先进入临界区，高优先级进程一直忙等。如果使用用户级线程，低优先级线程不会被高优先级线程抢占(进入临界区一般需要系统调用，其他线程也同时会被阻塞)，因为抢占发生在进程级别。但是对于内核级线程的实现，这个是可能发生的。</li></ul><h4 id="补充：优先级反转"><a href="#补充：优先级反转" class="headerlink" title="补充：优先级反转"></a>补充：优先级反转</h4><p>是指一个低优先级的任务持有一个被高优先级任务所需要的共享资源。高优先任务由于因资源缺乏而处于受阻状态，一直等到低优先级任务释放资源为止。而低优先级获得的CPU时间少，如果此时有优先级处于两者之间的任务，并且不需要那个共享资源，则该中优先级的任务反而超过这两个任务而获得CPU时间。如果高优先级等待资源时不是阻塞等待，而是忙循环，则可能永远无法获得资源，因为此时低优先级进程无法与高优先级进程争夺CPU时间，从而无法执行，进而无法释放资源，造成的后果就是高优先级任务无法获得资源而继续推进。</p><ol><li>优先级置顶：给临界区一个高优先级，进入临界区的进程都将获得这个高优先级</li><li>优先级继承：当一个高优先级进程等待一个低优先级进程持有的资源时，低优先级进程将暂时获得高优先级进程的优先级别，在释放共享资源后，低优先级进程回到原来的优先级别</li><li>中断屏蔽：通过禁止中断来保护临界区，采用此种策略的系统只有两种优先级——可抢占优先级和中断禁止优先级。前者为一般进程运行时的优先级，后者为运行于临界区的优先级。</li></ol><h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><p>将忙等变为阻塞。见下节</p><h2 id="基于信号量的同步方法"><a href="#基于信号量的同步方法" class="headerlink" title="基于信号量的同步方法"></a>基于信号量的同步方法</h2><p>同步中，进程经常需要等待某个条件的发生，如果使用忙等待的解决方案，势必浪费大量CPU时间。</p><p>解决方法：将忙等变为阻塞，可使用两条进程间的通信原语：Sleep和Wakeup。Sleep原语将引起调用进程的阻塞，直到另外一个进程用Wakeup原语将其唤醒。很明显，wakeup原语的调用需要一个参数——被唤醒的进程ID。</p><h3 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h3><p>是Dijkstra提出，它使用一个整型变量来累计唤醒次数，供以后使用。在他的建议中引入了一个新的变量类型，称作信号量（semaphore）。建议设立两种操作，P（也叫semWait）、V（也叫semSignal）。PV操作属于进程的低级通信。</p><p>信号量是一类特殊的变量，程序对其访问都是原子操作，且只允许对它进行P(信号变量)和V(信号变量)操作。</p><h3 id="信号量的定义"><a href="#信号量的定义" class="headerlink" title="信号量的定义"></a>信号量的定义</h3><p>一个确定的二元组(s, q)，其中s是一个具有非负初值的整型变量，q是一个初始状态为空的队列. 当发出P操作时：</p><ul><li>s为正，则该值等于可立即执行的进程的数量；s &lt;&#x3D; 0，那么发出P操作后的进程被阻塞（即发出P操作后s先减一，此时若s&lt;0，则该进程被阻塞），│s │是被阻塞的进程数。</li><li>q是一个初始状态为空的队列，当有进程被阻塞时就会进入此队列。</li></ul><h3 id="信号量的分类"><a href="#信号量的分类" class="headerlink" title="信号量的分类"></a>信号量的分类</h3><p>二元信号量和一般信号量</p><ul><li>二元信号量：取值仅为“0”或“1”，主要用作实现互斥；</li><li>一般信号量：初值为<strong>可用物理资源的总数</strong>，用于进程间的协作同步问题。</li></ul><p>强信号量和弱信号量</p><ul><li><p>强信号量：进程从被阻塞队列释放时采取FIFO</p><p>–不会出现“饥饿”（某个进程长时间被阻塞）</p></li><li><p>弱信号量：没有规定进程从阻塞队列中移除顺序</p><p>–可能出现“饥饿“</p></li></ul><h3 id="信号量的操作"><a href="#信号量的操作" class="headerlink" title="信号量的操作"></a>信号量的操作</h3><ul><li>一个信号量可能被初始化为一个非负整数.</li><li>semWait 操作（P操作）使信号量减1。若值为负，则执行semWait的进程被阻塞。否则进程继续执行。</li><li>semSignal操作（V操作）使信号量加1。若值小于或等于零，则被semWait操作阻塞的进程被解除阻塞。</li></ul><h3 id="信号量在并发中的典型应用"><a href="#信号量在并发中的典型应用" class="headerlink" title="信号量在并发中的典型应用"></a>信号量在并发中的典型应用</h3><p>互斥：可以用初始值为1的信号量实现。一个进程在进入临界区之前执行P操作，退出临界区后执行V操作。这是实现临界区资源互斥使用的一个二元信号量。</p><p>有限并发：可以用初始值为c的信号量实现n（1&lt;&#x3D;n&lt;&#x3D;c)个进程的并发执行一个函数或一个资源。</p><p>进程同步：指当⼀个进程Pi想要执⾏⼀个ai操作时，它只在进程Pj执⾏完aj后，才会执⾏ai操作。可以⽤信号量如下实现：将信号量初始为0，Pi执⾏ai操作前执⾏⼀个semWait操作；⽽Pj执⾏aj操作后，执⾏⼀个semSignal操作。</p><p>屏障Barriers：只有当该线程&#x2F;进程组中所有线程到达屏障点（可称之为同步点）时，整个程序才得以继续执行。信号量实现如下：n个进程就有n个信号量，屏障进入前对除本进程对应信号量以外的其他进程进行V操作，然后对本进程对应信号量进行P操作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//两个进程</span><br><span class="line">semaphore s0 = 0</span><br><span class="line">semaphore s1 = 0</span><br><span class="line">P0:</span><br><span class="line">//code before barrier</span><br><span class="line">V(s0)</span><br><span class="line">P(s1)</span><br><span class="line">//code after barrier</span><br><span class="line"></span><br><span class="line">P1:</span><br><span class="line">//code before barrier</span><br><span class="line">V(s1)</span><br><span class="line">P(s0)</span><br><span class="line">//code after barrier</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">//多个进程</span><br><span class="line">n = the number of threads</span><br><span class="line">count = 0//到达汇合点的线程数</span><br><span class="line">semaphore mutex = 1//互斥对count的访问</span><br><span class="line">semaphore barrier = 0 //线程到达之前都是0或者负值，到达后取正值</span><br><span class="line"></span><br><span class="line">P:</span><br><span class="line">P(mutex)</span><br><span class="line">count++</span><br><span class="line">if count == n:</span><br><span class="line">V(barrier) //唤醒一个线程</span><br><span class="line">V(mutex)</span><br><span class="line"></span><br><span class="line">P(barrier)</span><br><span class="line">V(barrier)//一旦线程被唤醒，有责任唤醒下一个线程</span><br><span class="line"></span><br><span class="line">P(mutex)</span><br><span class="line">count--</span><br><span class="line">if count == 0:</span><br><span class="line">P(barrier)//“关门”</span><br><span class="line">V(mutex)</span><br></pre></td></tr></table></figure><h3 id="P、V操作的优缺点"><a href="#P、V操作的优缺点" class="headerlink" title="P、V操作的优缺点"></a>P、V操作的优缺点</h3><p>优点：简单，而且表达能力强（用P、V操作可以<strong>解决任何同步、互斥问题</strong>）</p><p>缺点：不够安全，PV操作使用不当会出现死锁，遇到复杂同步互斥问题时实现复杂。</p><h2 id="基于管程的同步与互斥"><a href="#基于管程的同步与互斥" class="headerlink" title="基于管程的同步与互斥"></a>基于管程的同步与互斥</h2><h3 id="管程的定义和组成"><a href="#管程的定义和组成" class="headerlink" title="管程的定义和组成"></a>管程的定义和组成</h3><p>管程（Monitor）是在程序设计语言当中引入的一种高级同步机制。</p><p>一个管程定义了一个数据结构和能（在该数据结构上）被并发进程所执行的一组操作，这组操作能同步进程和改变管程中的数据。（挺像Java里一个类的组成）</p><p>管程由四部分组成：</p><ol><li>管程的名称</li><li>局部于管程内部的共享数据结构（变量）说明</li><li>对该数据结构进行操作的一组互斥执行的过程（可以理解为函数 &#x2F; Java里被synchronized的方法）</li><li>对局部于管程内部的共享数据设置初始值的语句</li></ol><h3 id="条件变量与信号量的区别"><a href="#条件变量与信号量的区别" class="headerlink" title="条件变量与信号量的区别"></a>条件变量与信号量的区别</h3><table><thead><tr><th>条件变量</th><th>信号量</th></tr></thead><tbody><tr><td>值不可增减</td><td>可增减</td></tr><tr><td>wait操作一定会阻塞当前进程</td><td>P操作只有当信号量的值小于0时才会阻塞</td></tr><tr><td>如果没有等待的进程，signal将会丢失</td><td>V操作增加了信号量的值，不会丢失</td></tr><tr><td>访问条件变量必须拥有管程的锁</td><td></td></tr></tbody></table><h2 id="进程通信（Interprocess-Communication）的主要方法"><a href="#进程通信（Interprocess-Communication）的主要方法" class="headerlink" title="进程通信（Interprocess Communication）的主要方法"></a>进程通信（Interprocess Communication）的主要方法</h2><ul><li><p>低级通信：只能传递状态和整数值（控制信息），包括进程互斥和同步所采用的信号量和管程机制。</p><p>缺点：传送信息量小；编程复杂</p></li><li><p>高级通信：适用于分布式系统、基于共享内存的多处理机系统、单处理机系统。</p><p>主要包括三类：管道、共享内存、消息系统</p></li></ul><h3 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h3><h4 id="无名管道（Pipe）"><a href="#无名管道（Pipe）" class="headerlink" title="无名管道（Pipe）"></a>无名管道（Pipe）</h4><ul><li>管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道；</li><li>只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）；</li><li>单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是单独构成一种文件系统，并且<strong>只存在于内存</strong>中。</li><li>数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。</li></ul><h4 id="有名管道（Named-Pipe，又称FIFO）"><a href="#有名管道（Named-Pipe，又称FIFO）" class="headerlink" title="有名管道（Named Pipe，又称FIFO）"></a>有名管道（Named Pipe，又称FIFO）</h4><p>FIFO不同于无名管道之处在于它提供一个路径名与之关联，以FIFO的文件形式存在于文件系统中。这样，即使与FIFO的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过FIFO相互通信（能够访问该路径的进程以及FIFO的创建进程之间），因此，通过FIFO不相关的进程也能交换数据。</p><p>注意：FIFO严格遵循先进先出（first in first out），对管道及FIFO的读总是从开始处返回数据，对它们的写则把数据添加到末尾</p><h3 id="消息传递"><a href="#消息传递" class="headerlink" title="消息传递"></a>消息传递</h3><ul><li>管程：过度依赖编译器；适用于单机环境。</li><li>消息传递——两个通信原语（OS系统调用）<ul><li>send (destination, &amp;message)</li><li>receive(source, &amp;message)</li></ul></li></ul><p>调用方式</p><ul><li>阻塞调用</li><li>非阻塞调用</li></ul><p>主要问题：</p><ul><li>解决消息丢失、延迟问题（TCP协议）</li><li>编址问题：mailbox</li></ul><h3 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h3><p>共享内存是最有用的进程间通信方式，也是最快的IPC形式（因为它避免了其它形式的IPC必须执行的开销巨大的缓冲复制）。</p><p>两个不同进程A、B共享内存的意义是，同一块物理内存被映射到进程A、B各自的进程地址空间。当多个进程共享同一块内存区域，由于共享内存可以同时读但不能同时写，则需要同步机制约束（互斥锁和信号量都可以）。</p><p>共享内存通信的效率高（因为进程可以直接读写内存）。</p><p>进程之间在共享内存时，保持共享区域直到通信完毕。</p><h2 id="经典同步与互斥问题"><a href="#经典同步与互斥问题" class="headerlink" title="经典同步与互斥问题"></a>经典同步与互斥问题</h2><h3 id="生产者-消费者问题"><a href="#生产者-消费者问题" class="headerlink" title="生产者-消费者问题"></a>生产者-消费者问题</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">semaphore empty = N//空闲数量</span><br><span class="line">semaphore full = 0//产品数量</span><br><span class="line">semaphore mutex = 1</span><br><span class="line">producer() &#123;</span><br><span class="line">while(true) &#123;</span><br><span class="line">P(empty);</span><br><span class="line">P(mutex);</span><br><span class="line">...</span><br><span class="line">V(mutex);</span><br><span class="line">V(full)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">consumer() &#123;</span><br><span class="line">P(full)</span><br><span class="line">P(mutex)</span><br><span class="line">...</span><br><span class="line">V(mutex)</span><br><span class="line">V(empty)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="读者-写者"><a href="#读者-写者" class="headerlink" title="读者-写者"></a>读者-写者</h3><p>读者优先</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">int readcount=0;//正在读的进程数</span><br><span class="line">semaphore rmutex=1;//用户readcount的互斥访问</span><br><span class="line">semaphore mutex=1;//用户数据访问的互斥</span><br><span class="line"></span><br><span class="line">read() &#123;</span><br><span class="line">P(rmutex)</span><br><span class="line">if readcount == 0 then P(mutex)</span><br><span class="line">readcount++</span><br><span class="line">V(rmutex)</span><br><span class="line">...</span><br><span class="line">P(rmutex)</span><br><span class="line">readcount--</span><br><span class="line">if readcount == 0 then V(mutex)</span><br><span class="line">V(rmutex)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">write()&#123;</span><br><span class="line">P(mutex)</span><br><span class="line">...</span><br><span class="line">V(mutex)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>读写公平(先来先服务)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">int readcount=0;//正在读的进程数</span><br><span class="line">semaphore rmutex=1;//用户readcount的互斥访问</span><br><span class="line">semaphore mutex=1;//用户数据访问的互斥</span><br><span class="line">semaphore rwmutex = 1;</span><br><span class="line">read() &#123;</span><br><span class="line">P(rwmutex)</span><br><span class="line">P(rmutex)</span><br><span class="line">if readcount == 0 then P(mutex)</span><br><span class="line">readcount++</span><br><span class="line">V(rmutex)</span><br><span class="line">V(rwmutex)</span><br><span class="line">...</span><br><span class="line">P(rmutex)</span><br><span class="line">readcount--</span><br><span class="line">if readcount == 0 then V(mutex)</span><br><span class="line">V(rmutex)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">write()&#123;</span><br><span class="line">P(rwmutex)</span><br><span class="line">P(mutex)</span><br><span class="line">    V(rwmutex)</span><br><span class="line">...</span><br><span class="line">V(mutex)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>写者优先(TODO</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">readSwitch = Lightswitch() </span><br><span class="line">writeSwitch = Lightswitch() </span><br><span class="line">noReaders = Semaphore(1) </span><br><span class="line">noWriters = Semaphore(1)</span><br><span class="line"></span><br><span class="line">Reader：</span><br><span class="line">noReaders.wait() </span><br><span class="line">readSwitch.lock(noWriters)</span><br><span class="line">noReaders.signal()</span><br><span class="line"># critical section for readers</span><br><span class="line">readSwitch.unlock(noWriters)</span><br><span class="line"></span><br><span class="line">Writer：</span><br><span class="line">writeSwitch.lock(noReaders) </span><br><span class="line">noWriters.wait() </span><br><span class="line"># critical section for writers </span><br><span class="line">noWriters.signal() </span><br><span class="line">writeSwitch.unlock(noReaders) </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最初信号量都是解锁态。如果reader在临界区，会给noWriter上锁。但是不会给noReader上锁。如果这时候writer到来，会给noReader加锁，会让后续读者排队在noReader。当最后一个读者离开，他会signal noWriter，这时写者可以进入。</p><p>当写者进入临界区，他同时拿着noreader和nowriter两个锁。一方面，其他读者和写者不能同时访问临界区。另一方面，writeSwitch 允许其他写者通过，并在noWriter等待。但是读者只能在noReader等待。这样，所有排队的写者能够通过临界区，而不需要signal noreader。当最后一个写者离开，noreader才解锁。写者才能进入。</p><h3 id="哲学家就餐"><a href="#哲学家就餐" class="headerlink" title="哲学家就餐"></a>哲学家就餐</h3><p>求解思路</p><ol><li>至多只允许四个哲学家同时（尝试）进餐,以保证至少有一个哲学家能够进餐,最终总会释放出他所使用过的两支筷子,从而可使更多的哲学家进餐。设置信号量room&#x3D;4。（破除资源互斥）</li><li>对筷子进行编号，每个哲学家按编号从低到高拿起筷子。或者对哲学家编号，奇数号哲学家先拿左，再拿右；偶数号相反。（破除循环等待）</li><li>同时拿起两根筷子，否则不拿起。（破除保持等待）</li></ol><h1 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="调度的类型"><a href="#调度的类型" class="headerlink" title="调度的类型"></a>调度的类型</h3><ul><li>高级调度：又称为“宏观调度”、“作业调度”。时间单位通常是分钟、小时、天</li><li>中级调度：又称为“内外存交换”</li><li>低级调度：又称为“微观调度”、“进程或线程调度”。时间单位通常是毫秒</li></ul><h3 id="面向用户的调度性能准则"><a href="#面向用户的调度性能准则" class="headerlink" title="面向用户的调度性能准则"></a>面向用户的调度性能准则</h3><ul><li><p>周转时间（批处理系统）：作业从提交到完成所经历的时间</p><p>带权周转时间 &#x3D; 周转时间 &#x2F; 服务时间（即执行时间）</p></li><li><p>响应时间（分时系统）：用户输入一个请求到系统给出首次响应的时间</p></li><li><p>截止时间（实时系统）：开始截止时间和完成截止时间，与周转时间有些相似</p></li><li><p>优先级</p></li><li><p>公平性</p></li></ul><h3 id="面向系统的调度性能准则"><a href="#面向系统的调度性能准则" class="headerlink" title="面向系统的调度性能准则"></a>面向系统的调度性能准则</h3><ul><li>吞吐量（批处理系统）：单位时间完成的作业数</li><li>处理机利用率（大中型主机）</li><li>各种资源的均衡利用（大中型主机）：如CPU繁忙的作业和I&#x2F;O繁忙的作业搭配</li></ul><h3 id="调度算法本身的调度性能准则"><a href="#调度算法本身的调度性能准则" class="headerlink" title="调度算法本身的调度性能准则"></a>调度算法本身的调度性能准则</h3><ul><li>易于实现</li><li>执行&#x2F;开销比小</li></ul><h2 id="设计调度算法要考虑的问题"><a href="#设计调度算法要考虑的问题" class="headerlink" title="设计调度算法要考虑的问题"></a>设计调度算法要考虑的问题</h2><ol><li><p>进程优先级（数）</p><p>优先级和优先数是不同的，优先级表现了进程的重要性和紧迫性，优先数实际上是一个数值，反映了某个优先级。</p><p>有静态、动态优先级之分，主要看优先级会不会在运行过程中改变。</p></li><li><p>进程优先级就绪队列的组织</p></li><li><p>抢占式调度与非抢占式调度</p></li><li><p>进程的分类</p><ol><li><p>I&#x2F;O Bound（密集型）与CPU Bound</p></li><li><p>批处理进程、交互式进程、实时进程</p></li></ol></li><li><p>时间片</p></li></ol><h2 id="批处理系统的调度算法"><a href="#批处理系统的调度算法" class="headerlink" title="批处理系统的调度算法"></a>批处理系统的调度算法</h2><h3 id="先来先服务（FCFS）"><a href="#先来先服务（FCFS）" class="headerlink" title="先来先服务（FCFS）"></a>先来先服务（FCFS）</h3><p>特点：有利于长作业，不利于短作业；有利于CPU繁忙的作业，不利于I&#x2F;O繁忙的作业</p><h3 id="最短作业优先（SJF）-短进程优先（SPN）"><a href="#最短作业优先（SJF）-短进程优先（SPN）" class="headerlink" title="最短作业优先（SJF）&#x2F;短进程优先（SPN）"></a>最短作业优先（SJF）&#x2F;短进程优先（SPN）</h3><p>这是对FCFS算法的改进，其目标是减少平均周转时间。做法是对预计执行时间短的作业（进程）优先分派处理机。<strong>通常后来的短作业不抢占正在执行的作业</strong>。</p><p>优点：与FCFS相比改善了平均（&amp;带权）周转时间、作业的等待时间；提高系统的吞吐量。</p><p>缺点：长作业可能长时间得不到执行；未能依据作业的紧迫程度来划分执行的优先级；难以准确估计作业的执行时间，从而影响调度性能。</p><h3 id="最短剩余时间优先（SRTF）"><a href="#最短剩余时间优先（SRTF）" class="headerlink" title="最短剩余时间优先（SRTF）"></a>最短剩余时间优先（SRTF）</h3><p>上面的方法SJF修改条件“通常后来的短作业不抢占正在执行的作业”为<strong>抢占式</strong></p><h3 id="最高响应比优先（HRRF）"><a href="#最高响应比优先（HRRF）" class="headerlink" title="最高响应比优先（HRRF）"></a>最高响应比优先（HRRF）</h3><p>实际上是FCFS算法和SJF算法的折衷既考虑作业等待时间，又考虑作业的运行时间，既照顾短作业又不使长作业的等待时间过长，改善了调度性能。</p><p>在每次选择作业投入运行时，先计算后备作业队列中每个作业的响应比RP，然后选择其值最大的作业投入运行。<br>$$<br>RP &#x3D; \frac{作业已等待时间 + 作业的服务时间}{作业的服务时间} &#x3D; 1 + \frac{作业已等待时间}{作业的服务时间}<br>$$<br>响应比的计算时机：每当调度一个作业运行时，都要计算后备作业队列中每个作业的响应比，选择响应比最高者投入运行。</p><h2 id="交互式系统的调度算法"><a href="#交互式系统的调度算法" class="headerlink" title="交互式系统的调度算法"></a>交互式系统的调度算法</h2><h3 id="时间片轮转-RR：Round-Robin）"><a href="#时间片轮转-RR：Round-Robin）" class="headerlink" title="时间片轮转(RR：Round Robin）"></a>时间片轮转(RR：Round Robin）</h3><h3 id="多级队列（MQ：Multi-level-Queue）"><a href="#多级队列（MQ：Multi-level-Queue）" class="headerlink" title="多级队列（MQ：Multi-level Queue）"></a>多级队列（MQ：Multi-level Queue）</h3><p>本算法引入多个就绪队列，通过各队列的区别对待，达到综合的调度目标；</p><p>不同队列可有不同的优先级、时间片长度、调度策略等；在运行过程中还可改变进程所在队列。如：系统进程、用户交互进程、批处理进程等</p><h3 id="多级反馈队列（MFQ：-Multi-level-Feedback-Queue-）"><a href="#多级反馈队列（MFQ：-Multi-level-Feedback-Queue-）" class="headerlink" title="多级反馈队列（MFQ： Multi-level Feedback Queue ）"></a>多级反馈队列（MFQ： Multi-level Feedback Queue ）</h3><p>是时间片轮转算法和优先级算法的综合和发展</p><ol><li>设置多个就绪队列，分别赋予不同的优先级（如逐级降低），队列1的优先级最高。每个队列执行时间片的长度也不同，规定<strong>优先级越低则时间片越长</strong>（如逐级加倍）。</li><li>新进程进入内存后，先投入队列1的末尾，按FCFS算法调度；若按队列1一个时间片未能执行完，则降低投入到队列2的末尾，同样按FCFS算法调度；如此下去，降低到最后的队列，则按“时间片轮转”算法调度直到完成。</li><li>仅当较高优先级的队列为空，才调度较低优先级的队列中的进程执行。如果进程执行时有新进程进入较高优先级的队列，则抢先执行新进程，并把被抢先的进程投入原队列的末尾</li><li>如果进程执行时有新进程进入较高优先级的队列，则<strong>抢先</strong>执行新进程，并把被抢先的进程投入<strong>原</strong>队列的末尾</li></ol><p><strong>优先级反转问题</strong></p><h2 id="实时系统的调度算法"><a href="#实时系统的调度算法" class="headerlink" title="实时系统的调度算法"></a>实时系统的调度算法</h2><p>实时系统是一种时间起着主导作用的系统。分为硬实时（绝对满足截止时间要求，如汽车和飞机的控制系统）和软实时（可以偶尔不满足）</p><h3 id="实时调度的前提条件"><a href="#实时调度的前提条件" class="headerlink" title="实时调度的前提条件"></a>实时调度的前提条件</h3><ul><li>任务集（S）是已知的；</li><li>所有任务都是<strong>周期性</strong>（T）的，</li><li>必须在限定的时限D内完成；</li><li>任务之间都是独立的，每个任务不依赖于其他任务；</li><li>每个任务的运行时间（c）是不变的；</li><li>调度, 任务切换的时间忽略不计</li></ul><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><ul><li><p>静态表调度（Static table-driven scheduling）：通过对所有周期性任务的分析预测，事先确定一个固定的调度方案。</p></li><li><p>单调速率调度（RMS：Rate Monotonic Scheduling） 静态最优调度算法：任务的周期越小，其优先级越高，优先级最高的任务最先被调度；如果两个任务的优先级一样，当调度它们时，RM算法将随机选择一个调度。静态、<strong>抢先式调度</strong>。前提<br>  $$<br>  \sum_{i&#x3D;1}^n \frac{C_i}{T_i} &lt;&#x3D; n(\sqrt[n]{2} - 1) \to ln2 \approx 0.69 (n \to \infty)<br>  $$</p></li><li><p>最早截止时间优先算法（EDF：Earliest Deadline First）：任务的绝对截止时间越早，其优先级越高，优先级最高的任务最先被调度。如果两个任务的优先级一样，当调度它们时，RM算法将随机选择一个调度。<strong>抢占式</strong>。任务集可调度的充分必要条件(C是执行时间，T是周期)：<br>  $$<br>  \sum_{i&#x3D;1}^n \frac{C_i}{T_i} &lt;&#x3D; 1<br>  $$</p></li><li><p>最低松弛度优先算法（LLF：Least Laxity First）：根据任务紧急&#x2F;松弛程度，来确定任务的优先级，使优先级高的优先执行。</p><p>  $$<br>  松弛度Laxity &#x3D; 任务截止时间 - 本身剩余运行时间 - 当前时间<br>  $$</p><p>  调度时机：有任务执行完时，或有进程Laxity为0时（直接抢占）</p></li></ul><h2 id="多处理机调度"><a href="#多处理机调度" class="headerlink" title="多处理机调度"></a>多处理机调度</h2><p>与单处理机调度的区别：</p><ul><li>注重整体运行效率，而不是个别处理机的利用率</li><li>更多样的调度算法</li><li>多处理访问os数据结构时的互斥（对于共享内存的系统）</li></ul><p>调度单位广泛采用线程</p><ol><li><p>非对称式多处理系统(AMP：Asymmetric Multi-Processor)：指多处理器系统中各个处理器的地位不同。</p><ul><li><p>主－从处理机系统，由主处理机管理一个公共就绪队列，并分派进程给从处理机执行。</p></li><li><p>各个处理机有固定分工，如执行OS的系统功能，I&#x2F;O处理，应用程序。</p></li><li><p>有潜在的不可靠性（主机故障造成系统崩溃）。</p></li></ul></li><li><p>对称式多处理系统（SMP）</p><ul><li><p>集中控制</p><ul><li><p>静态调度：每个CPU设立一个就绪队列，进程从开始执行到完成，都在同一个CPU上。</p><p>优点：调度算法开销小。</p><p>缺点：容易出现忙闲不均</p></li><li><p>动态调度：各个CPU采用一个公共就绪队列，<strong>队首</strong>进程每次分派到当前空闲的CPU上执行。可防止系统中多个处理器忙闲不均。</p></li></ul></li><li><p>分散控制</p><ul><li>自调度：所有CPU采用一个公共就绪队列，每个处理机都可以从队列中<strong>选择适当进程</strong>来执行。需要对就绪队列的数据结构进行<strong>互斥访问控制</strong>。最常用的算法，实现时易于移植，采用单处理机的调度技术</li></ul></li></ul></li></ol><h1 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h1><h2 id="死锁的概念"><a href="#死锁的概念" class="headerlink" title="死锁的概念"></a>死锁的概念</h2><h3 id="死锁发生的四个必要条件"><a href="#死锁发生的四个必要条件" class="headerlink" title="死锁发生的四个必要条件"></a>死锁发生的四个必要条件</h3><ol><li>互斥条件：在一段时间内某资源只由一个进程占用</li><li>请求和保持条件：进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放</li><li>不可剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放</li><li>环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源</li></ol><h3 id="活锁livelock"><a href="#活锁livelock" class="headerlink" title="活锁livelock"></a>活锁livelock</h3><p>是指任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。</p><p>活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，即所谓的“活” ， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。避免活锁的简单方法是采用先来先服务的策略</p><h3 id="饥饿（starvation-："><a href="#饥饿（starvation-：" class="headerlink" title="饥饿（starvation)："></a>饥饿（starvation)：</h3><p>某些进程可能由于资源分配策略的不公平导致长时间等待。当等待时间给进程推进和响应带来明显影响时，称发生了进程饥饿，当饥饿到一定程度的进程所赋予的任务即使完成也不再具有实际意义时称该进程被饿死</p><h2 id="处理死锁的基本方法"><a href="#处理死锁的基本方法" class="headerlink" title="处理死锁的基本方法"></a>处理死锁的基本方法</h2><ul><li><p>不允许死锁发生</p><p>预防死锁（静态）：防患于未然，破坏死锁的产生条件</p><p>避免死锁（动态）：在资源分配前进行判断</p></li><li><p>允许死锁发生</p><p>检测与接触死锁</p><p>无所作为：鸵鸟算法</p></li></ul><h3 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h3><h4 id="安全序列"><a href="#安全序列" class="headerlink" title="安全序列"></a>安全序列</h4><p>安全序列的定义：一个序列{P1，P2，…，Pn}安全的，是指若对于每一个进程Pi，它需要的资源可以被系统中当前可用资源加上所有进程Pj（j &lt; i）当前占有资源之和所满足，则{P1，P2，…，Pn}为一个安全序列。</p><p>如果系统不存在这样一个安全序列，则系统是不安全的。</p><p>系统进入不安全状态也未必会产生死锁。产生死锁后系统一定处于不安全状态</p><h4 id="银行家算法-避免死锁算法"><a href="#银行家算法-避免死锁算法" class="headerlink" title="银行家算法(避免死锁算法)"></a>银行家算法(避免死锁算法)</h4><p>设n为进程数量，m为资源类型数量</p><ul><li>可利用资源向量Available：m维向量</li><li>最大需求矩阵Max：n x m 矩阵</li><li>分配矩阵Allocation：n x m矩阵</li><li>需求矩阵Need：n x m矩阵</li></ul><p>$$<br>Need(i, j) &#x3D; Max(i,j) - Allocation(i,j)<br>$$</p><p><img src="/../../images/OS/%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95.png" alt="银行家算法"></p><h3 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h3><h4 id="资源分配图-进程-资源图"><a href="#资源分配图-进程-资源图" class="headerlink" title="资源分配图&#x2F;进程-资源图"></a>资源分配图&#x2F;进程-资源图</h4><p>用有向图描述系统资源和进程的状态。二元组G&#x3D;（ N， E），N： 结点的集合，N&#x3D;P∪R。</p><p>P为进程， R为资源，P &#x3D; {p1, p2, … , pn}，R &#x3D; {r1, r2, … , rm}，两者为互斥资源。E：有向边的集合，e属于E，e &#x3D; (pi , rj ) 或e &#x3D; (rj , pi )。</p><ul><li>e &#x3D; (pi, rj)是请求边，进程pi请求一个单位的rj资源；</li><li>e &#x3D; (rj, pi)是分配边，为进程pi分配了一个单位的rj资源</li></ul><h4 id="资源分配图-RAG-算法"><a href="#资源分配图-RAG-算法" class="headerlink" title="资源分配图(RAG)算法"></a>资源分配图(RAG)算法</h4><p>资源分配图的化简：首先，找到一个非孤立点进程结点且只有分配边，去掉分配边，将其变为孤立结点。接着，将相应的资源分配给一个等待该资源的进程，即将某进程的申请边变为分配边。重复以上步骤，直到所有进程化简完成，即进程与资源间无连线，则系统无死锁</p><p>在经过一系列的简化后，若能消去图中的所有边，使所有的进程都成为孤立结点，则称该图是<strong>可完全化简的</strong>；反之的是<strong>不可完全化简的</strong></p><p><strong>死锁定理</strong>：系统中某个时刻t为死锁状态的充要条件是t时刻系统的资源分配图是不可完全化简的。</p><h3 id="死锁解除"><a href="#死锁解除" class="headerlink" title="死锁解除"></a>死锁解除</h3><p>剥夺资源</p><p>撤销进程</p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>内存管理</title>
      <link href="/2024/03/22/os/2024-03-22-os-nei-cun-guan-li/"/>
      <url>/2024/03/22/os/2024-03-22-os-nei-cun-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="预备知识：链接与装载"><a href="#预备知识：链接与装载" class="headerlink" title="预备知识：链接与装载"></a>预备知识：链接与装载</h1><p>gcc调用包含的几个工具</p><ul><li>cc1: 预处理和编译器</li><li>as: 汇编器</li><li>collect2: 链接器</li></ul><p>ELF(Executable and Linkable Format)——可执行文件格式</p><p><img src="/../../images/OS/ELF%E7%BB%93%E6%9E%84.png" alt="ELF结构图"></p><p><strong>几个重要节头：</strong></p><ul><li>.bss: 存储未初始化的全局变量和静态变量。此节类型是SHT_NOBITS,因此不占⽂件空间</li><li>.data: 存储已初始化的全局变量和静态变量。</li><li>.text: 存放正文，也称程序的执行指令</li></ul><p>.bss、.data节是数据段的组成部分</p><p>ELF文件头</p><ul><li>e_ident： 这一部分是文件的标志，用于表明该文件是一个ELF文件。ELF文件的头四个字节为magic number。</li><li>e_type： 用于标明该文件的类型，如可执行文件、动态连接库、可重定位文件等。</li><li>e_machine： 表明体系结构，如x86，x86_64，MIPS，PowerPC等等。</li><li>e_version： 文件版本</li><li>e_entry： 程序入口的虚拟地址</li><li>e_phoff： 程序头表在该ELF文件中的位置(具体地说是偏移)。ELF文件可以没有程序头表。</li><li>e_shoff： 节头表的位置。</li><li>e_eflags： 针对具体处理器的标志。</li><li>e_ehsize： ELF 头的大小。</li><li><strong>e_phentsize： 程序头表（段头表）每项的大小。</strong></li><li><strong>e_phnum： 程序头表项的个数。</strong></li><li><strong>e_shentsize： 节头表每项的大小。</strong></li><li><strong>e_shnum： 节头表项的个数。</strong></li><li>e_shstrndx： 与节名字符串表相关的节头表。</li></ul><p>节头表更关注于文件内部各个节的<strong>属性</strong>信息，而程序（段）头表则关注于程序<strong>执行时</strong>的段信息。</p><p>段是由多个节组成的，多个节经过重定位后形成一个段。段主要用于描述程序在内存中的布局和加载方式。例如，在创建两个汇编文件时，每个文件都有自己的数据节（.data）。当这两个文件链接在一起时，它们的数据节会组合在一起形成一个数据段。同样，代码节也会组合形成代码段。</p><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p>将.o文件链接到一起，形成最终的可执行文件</p><ul><li>E重定位目标文件</li><li>U未解析符号</li><li>D已定义符号</li></ul><p>程序入口点：_start函数</p><p>三种链接方式</p><ul><li>静态链接：装入前连接成一个完整装入模块</li><li>装入时动态链接：运行前边装入边链接</li><li>运行时动态链接：运行时需要目标模块才装入并链接</li></ul><p>三种装入方式</p><ol><li>绝对装入：编译时产生绝对地址（单道程序阶段，无操作系统）</li><li>可重定位装入：装入时将逻辑地址转换为物理地址（早期多道批处理阶段）</li><li>动态运行时装入：运行时将逻辑地址转换为物理地址，需设置重定位寄存器（现代操作系统）</li></ol><h2 id="装载和运行"><a href="#装载和运行" class="headerlink" title="装载和运行"></a>装载和运行</h2><ul><li>shell调用fork()系统调用，创建出一个子进程（装载前的工作）</li><li>子进程调用execve()加载program（开始装载）</li><li>读取ELF头部的魔数(Magic Number)，以确认该文件确实是ELF文件</li><li>找到段表项</li><li>对于每个段表项解析出各个段应当被加载的虚地址，在文件中的偏移。以及在内存中的大小和在文件中的大小。（段在文件中的大小 &lt;&#x3D; 内存中的大小）</li><li>对于每一个段，根据其在内存中的大小，为其分配足够的物理页，并映射到指定的虚地址上。再将文件中的内容拷贝到内存中</li><li>若ELF中记录的段在内存中的大小大于在文件中的大小，则多出来的部分用0进行填充。</li><li>设置进程控制块中的PC为ELF文件中记载的入口地址</li><li>控制权交给进程开始执行！</li></ul><h1 id="存储管理基础"><a href="#存储管理基础" class="headerlink" title="存储管理基础"></a>存储管理基础</h1><h2 id="存储保护"><a href="#存储保护" class="headerlink" title="存储保护"></a>存储保护</h2><p>保证各进程在自己的内存空间内运行，不会越界访问</p><p>两种方法：</p><ol><li><p>界限寄存器方法</p><p>两种方式：</p><ul><li>设置上下限寄存器</li><li>利用重定位寄存器（基址寄存器）、界地址寄存器（限长寄存器）进行判断</li></ul></li><li><p>存储保护键方法<br>给每个存储块分配一个单独的保护键，它相当于一把锁。进入系统的每个作业也赋予一个保护键，它相当于一把钥匙。当作业运行时，检查钥匙和锁是否匹配，如果不匹配，则系统发出保护性中断信号，停止作业运行</p></li></ol><h2 id="覆盖与交换：解决分区管理问题"><a href="#覆盖与交换：解决分区管理问题" class="headerlink" title="覆盖与交换：解决分区管理问题"></a>覆盖与交换：解决分区管理问题</h2><h3 id="覆盖技术（主要用于早期的OS）"><a href="#覆盖技术（主要用于早期的OS）" class="headerlink" title="覆盖技术（主要用于早期的OS）"></a>覆盖技术（主要用于早期的OS）</h3><ol><li>一个固定区：存放最活跃的程序段，固定区中的程序段在运行中不会调入调出</li><li>若干个覆盖区：不可能同时被访问程序段可共享一个覆盖区，覆盖区中的程序段在运行过程中会根据需要调入调出</li></ol><p>必须由程序员声明覆盖结构，操作系统完成自动覆盖</p><p>缺点：对用户不透明，增加了用户编程负担</p><h4 id="补充：计算机领域“透明”的含义"><a href="#补充：计算机领域“透明”的含义" class="headerlink" title="补充：计算机领域“透明”的含义"></a>补充：计算机领域“透明”的含义</h4><p>在计算机术语中，”透明”通常指的是一种操作或过程对用户或其他系统的影响被隐藏或减轻到最小程度，以使其表现为<strong>无缝、不可察觉或无需用户干预</strong>。这种透明性的目标是使系统<strong>更易于使用、更具可靠性，并减少对终端用户或其他系统组件的干扰</strong>。</p><p>通俗来讲：看不见，不用管它（系统管理员或者开发者无需显式干预和管理）。那么“不透明”就是指开发人员要考虑怎么用它。</p><h3 id="交换技术"><a href="#交换技术" class="headerlink" title="交换技术"></a>交换技术</h3><p>内存紧张时，换出某些进程以腾出内存空间，再换入某些进程。</p><p>磁盘分为文件区和对换区，换出的进程放在对换区。</p><h3 id="覆盖与交换的区别"><a href="#覆盖与交换的区别" class="headerlink" title="覆盖与交换的区别"></a>覆盖与交换的区别</h3><ul><li>覆盖：同一个程序或进程中的</li><li>交换：不同进程（或作业）之间的</li></ul><h2 id="连续分配管理"><a href="#连续分配管理" class="headerlink" title="连续分配管理"></a>连续分配管理</h2><h3 id="单一连续分配：只支持单道程序，内存分为系统区和用户区，用户程序放在用户区。"><a href="#单一连续分配：只支持单道程序，内存分为系统区和用户区，用户程序放在用户区。" class="headerlink" title="单一连续分配：只支持单道程序，内存分为系统区和用户区，用户程序放在用户区。"></a>单一连续分配：只支持单道程序，内存分为系统区和用户区，用户程序放在用户区。</h3><p>无外部碎片，有内部碎片</p><h3 id="固定分区分配：支持多道程序，内存用户空间分为若干个固定大小的分区，每个分区只能装一道作业"><a href="#固定分区分配：支持多道程序，内存用户空间分为若干个固定大小的分区，每个分区只能装一道作业" class="headerlink" title="固定分区分配：支持多道程序，内存用户空间分为若干个固定大小的分区，每个分区只能装一道作业"></a>固定分区分配：支持多道程序，内存用户空间分为若干个固定大小的分区，每个分区只能装一道作业</h3><p>无外部碎片，有内部碎片</p><p>两种分区方式</p><ul><li>分区大小相同</li><li>分区大小不同</li></ul><p>两种分配方式</p><ul><li>单一队列的分配方式：当需要加载程序时，选择一个当前闲置且容量足够大的分区进行加载，可采用共享队列的固定分区（多个用户程序排在一个共同的队列里面等待分区）分配</li><li>多队列分配方式：给每个分区一个队列，程序按照所需内存的大小排在相应的队列里。避免小程序占用大分区，导致大程序无法加载。</li></ul><h3 id="可变式分区（动态分区分配）：支持多道程序，在进程装入内存时，根据进程动态地建立分区"><a href="#可变式分区（动态分区分配）：支持多道程序，在进程装入内存时，根据进程动态地建立分区" class="headerlink" title="可变式分区（动态分区分配）：支持多道程序，在进程装入内存时，根据进程动态地建立分区"></a>可变式分区（动态分区分配）：支持多道程序，在进程装入内存时，根据进程动态地建立分区</h3><p>无内部碎片，有外部碎片。外部碎片可用<strong>紧凑</strong>技术解决</p><h2 id="闲置空间管理"><a href="#闲置空间管理" class="headerlink" title="闲置空间管理"></a>闲置空间管理</h2><p>在管理内存时，OS需要知道内存空间有多少空闲。这就必须跟踪内存的使用，跟踪的办法有两种：</p><ul><li><p>位图表示法（分区表）</p><ul><li><p>空间开销固定：不依赖于内存中的程序数量。</p></li><li><p>时间开销低：操作简单，直接修改其位图值即可。</p></li><li><p>没有容错能力：如果一个分配单元对应的标志位为1，不能确定是否因错误变成1。</p></li></ul></li><li><p>链表表示法（分区链表）</p><ul><li><p>空间开销：取决于程序的数量。</p></li><li><p>时间开销：链表扫描速度较慢，还要进行链表项的插入、删除和修改</p></li><li><p>有一定容错能力：因为链表有被占空间和闲置空间的表项，可相互验证</p></li></ul></li></ul><h2 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h2><p>若m.size（空闲分区的大小）- u.size（请求的分区大小）≤size （规定当剩余空闲分区≤ size时，不再进一步分割），将整个分区分配给请求者。否则，从该分区中按请求的大小划分出一块内存空间分配出去，余下的部分仍留在空闲分区表&#x2F;链中</p><h2 id="回收内存"><a href="#回收内存" class="headerlink" title="回收内存"></a>回收内存</h2><ol><li>待回收分区与前一个空闲分区邻接：合并后首地址为空闲分区的首地址，大小为二者之和。</li><li>待回收分区与后一个空闲分区邻接：合并后首地址为回收分区的首地址，大小为二者之和。</li><li>待回收分区与前后两个空闲分区邻接：合并后首地址为前一个空闲分区的首地址，大小为三者之和。</li><li>待回收分区不与空闲分区邻接：在空闲分区表中新建</li></ol><h2 id="分配算法"><a href="#分配算法" class="headerlink" title="分配算法"></a>分配算法</h2><h3 id="基于顺序搜索的分配算法：适合于较小的系统"><a href="#基于顺序搜索的分配算法：适合于较小的系统" class="headerlink" title="基于顺序搜索的分配算法：适合于较小的系统"></a>基于顺序搜索的分配算法：适合于较小的系统</h3><ul><li><p>首次适应：每个空闲区按其在存储空间中地址递增的顺序连在一起。为作业分配存储空间时，从这个空闲区域链始端开始查找，选择第一个满足的空白块</p><p>缺点：留下碎片，查找时间开销大</p></li><li><p>下次适应：把空闲区构建成一个循环链表。每次从上次查找结束的地方开始，只要找到能装的就分配出去</p><p>优点：存储空间利用更均衡</p><p>缺点：缺乏大的空闲分区</p></li><li><p>最佳适应：找大小与作业所需存储区域最接近的</p><p>缺点：留下碎片</p></li><li><p>最坏适应：每次都找最大空闲区</p><p>优点：分给一个作业后剩下的空闲分区也较大，可以装下其他作业</p><p>缺点：大作业的空间申请难以满足</p></li></ul><h3 id="基于索引搜索的分配算法：大中型系统，提高搜索空闲分区的速度"><a href="#基于索引搜索的分配算法：大中型系统，提高搜索空闲分区的速度" class="headerlink" title="基于索引搜索的分配算法：大中型系统，提高搜索空闲分区的速度"></a>基于索引搜索的分配算法：大中型系统，提高搜索空闲分区的速度</h3><ul><li><p>快速适应算法（&#x2F;分类搜索法）：把空闲分区按容量大小进行分类，常用大小的空闲区设立单独的空闲区链表。系统为多个空闲链表设立一张管理索引表</p><p>优点：查找效率高；保留大分区，不会产生内存碎片</p><p>缺点：分区回收算法复杂</p></li><li><p><strong>伙伴系统</strong>（Linux系统采用）：在分配存储块时将一个大的存储块分裂成两个大小相等的小块，这两个小块就称为“伙伴”。介于固定分区与可变分区之间的动态分区技术</p></li></ul><h3 id="紧凑技术"><a href="#紧凑技术" class="headerlink" title="紧凑技术"></a>紧凑技术</h3><p>实现支撑：动态重定位（作业在内存中的位置发生了变化，这就必须对其地址加以修改或变换。）</p><h3 id="可重定位分区分配"><a href="#可重定位分区分配" class="headerlink" title="可重定位分区分配"></a>可重定位分区分配</h3><p>结合紧凑技术的动态分区技术</p><p><img src="/../../images/OS/%E5%8F%AF%E9%87%8D%E5%AE%9A%E4%BD%8D%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AE%97%E6%B3%95%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="算法示意图"></p><h3 id="多重分区分配"><a href="#多重分区分配" class="headerlink" title="多重分区分配"></a>多重分区分配</h3><p>为了支持结构化程序设计，操作系统往往把一道作业分成若干片段（如子程序、主程序、数据组等）。这样，片段之间就不需要连续了。只要增加一些重定位寄存器，就可以有效地控制一道作业片段之间的调用</p><h1 id="页式内存管理"><a href="#页式内存管理" class="headerlink" title="页式内存管理"></a>页式内存管理</h1><p>基本思想：把一个逻辑地址连续的程序分散存放到若干个不连续的内存区域，并保证程序的正确执行。</p><p>纯分页&#x2F;基本分页存储管理方式：在调度一个作业时，必须把它的所有页一次装到主存的页框内；如果当时页框数不足，则该作业必须等待，系统再调度另外作业。不具备页面对换功能，不支持虚拟存储器功能。</p><h2 id="补充知识：作业、进程和程序"><a href="#补充知识：作业、进程和程序" class="headerlink" title="补充知识：作业、进程和程序"></a>补充知识：作业、进程和程序</h2><p>作业通常包括程序、数据和操作说明书三部分。</p><p>每一个进程由进程控制块PCB、程序和数据集合组成。这说明程序是进程的一部分，是进程的实体。</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li>页面&#x2F;页：逻辑地址空间</li><li>页框&#x2F;存储块：物理内存的存储空间，与页面相同大小的片</li><li>页表项：每个页面到页框的映射</li><li>页表：分页系统为每个进程配置的一张表，页表项的集合。存放在内存中</li></ul><p>页面大小</p><ul><li>小：页内碎片少，利于提高内存利用率；页表占用内存较大；页面换进换出速度降低</li><li>大：与小相反</li></ul><h2 id="地址变换机构"><a href="#地址变换机构" class="headerlink" title="地址变换机构"></a>地址变换机构</h2><ol><li>内存系统区的PCB（进程控制块）将页表信息传给页表寄存器（存储<u>页表起始地址+页表长度</u>信息）</li><li>根据逻辑地址计算页号、页内偏移量</li><li>判断是否越界：页号 &lt;&#x3D; 页表长度 ？</li><li>查询页表，找到页号对应的页表项，确定页号对应的页框号</li><li>用页框号+页内偏移量计算出物理地址</li><li>访问目标内存单元</li></ol><h2 id="二级页表"><a href="#二级页表" class="headerlink" title="二级页表"></a>二级页表</h2><p>目录-页表-偏移量</p><h3 id="多级页表为什么省空间"><a href="#多级页表为什么省空间" class="headerlink" title="多级页表为什么省空间"></a>多级页表为什么省空间</h3><p>因为多级页表允许操作系统根据进程实际使用的内存量来动态分配页表空间（想想实验课的MOS）</p><p>多级页表的设计允许操作系统在创建进程时只需为每个进程分配一个一级页表，然后根据进程申请的内存空间，再为进程分配二级页表。这种按需分配的方式避免了单级页表在进程创建时为可能用到的所有页表项分配空间，从而减少了不必要的内存占用。</p><h2 id="快表-TLB（转换表查找缓冲区）-联想存储器"><a href="#快表-TLB（转换表查找缓冲区）-联想存储器" class="headerlink" title="快表&#x2F;TLB（转换表查找缓冲区）&#x2F;联想存储器"></a>快表&#x2F;TLB（转换表查找缓冲区）&#x2F;联想存储器</h2><p>为了解决页表机制带来的内存访问效率严重下降问题</p><p>快表一种特殊的cache，内容是页表中的一部分或全部内容</p><p>结构：Valid + Virtual page + Modified + Protection + Page frame</p><h2 id="哈希页表：处理超过32位地址空间的一种常用方法"><a href="#哈希页表：处理超过32位地址空间的一种常用方法" class="headerlink" title="哈希页表：处理超过32位地址空间的一种常用方法"></a>哈希页表：处理超过32位地址空间的一种常用方法</h2><p>将虚拟页号转换为哈希值，据此访问哈希表的表项（链表）。用虚拟页号与链表中的元素的第一个域相比较。如果匹配，那么相应的页框号（第二个域）就用来形成物理地址；如果不匹配，那么就进一步比较链表的下一个节点，以找到匹配</p><h2 id="反置页表"><a href="#反置页表" class="headerlink" title="反置页表"></a>反置页表</h2><p>页表按页框号排序，页表项内容是逻辑页号+隶属进程标识符</p><p>优点：页表占用的内存空间小</p><h2 id="页共享与保护"><a href="#页共享与保护" class="headerlink" title="页共享与保护"></a>页共享与保护</h2><p>保护：</p><ul><li>地址越界保护</li><li>在页表中设置保护位（定义操作权限：只读，读写，执行等）</li></ul><p>共享：分段存储管理（解决共享数据和不共享数据出现在同一个页框的问题）</p><h1 id="段式内存管理（类比页式）"><a href="#段式内存管理（类比页式）" class="headerlink" title="段式内存管理（类比页式）"></a>段式内存管理（类比页式）</h1><p>将地址空间按照程序自身的逻辑关系划分为若干个段（类比页式的”分成若干页面“）。</p><p>段表项：段号（隐含在地址下标）、<strong>段长</strong>+基址（区别于页式，段的长度不固定，页的大小固定）</p><p>地址变换（类比页式的地址变换，需增加一步：根据段表内的段长检查段内地址&#x2F;偏移是否越界）</p><h2 id="分段和分页对比"><a href="#分段和分页对比" class="headerlink" title="分段和分页对比"></a>分段和分页对比</h2><table><thead><tr><th></th><th>分段</th><th>分页</th></tr></thead><tbody><tr><td>对用户</td><td>可见</td><td>不可见</td></tr><tr><td>地址空间</td><td>二维</td><td>一维</td></tr><tr><td>信息共享和保护实现难易程度</td><td>更容易实现</td><td>更难实现</td></tr><tr><td>长度</td><td>不固定</td><td>固定</td></tr><tr><td>都需要两次访存，都可引入快表机构</td><td></td><td></td></tr></tbody></table><h2 id="段页式内存管理"><a href="#段页式内存管理" class="headerlink" title="段页式内存管理"></a>段页式内存管理</h2><p>段里再分页</p><p>逻辑地址结构：段号+页号+页内偏移量</p><p>段表项：段号（隐含在地址下标）、页表长度（一个段里有几页）+页表存放块号（页表起始地址）</p><p>页表项：页号（隐含在地址下标）、页框号</p><p>地址变换机构：段式和页式的结合，三次访存，可引入快表机构（段号+页号）</p><h1 id="虚拟内存管理"><a href="#虚拟内存管理" class="headerlink" title="虚拟内存管理"></a>虚拟内存管理</h1><h2 id="局部性原理"><a href="#局部性原理" class="headerlink" title="局部性原理"></a>局部性原理</h2><p>时间局部性：程序中存在大量循环</p><p>空间局部性：很多数据在内存中是连续存放的</p><p>基于局部性原理产生了高速缓存技术</p><h2 id="虚拟内存的定义和特征"><a href="#虚拟内存的定义和特征" class="headerlink" title="虚拟内存的定义和特征"></a>虚拟内存的定义和特征</h2><p>定义：程序不需全部装入即可运行，运行时根据需要动态调入数据，若内存不够，还需换出一些数据</p><table><thead><tr><th>特征比较</th><th>虚拟内存</th><th>传统存储管理方式</th></tr></thead><tbody><tr><td></td><td>多次性</td><td>一次性</td></tr><tr><td></td><td>对换性</td><td>驻留性</td></tr><tr><td></td><td>虚拟性</td><td></td></tr><tr><td></td><td>离散性</td><td></td></tr></tbody></table><h2 id="虚拟内存的实现"><a href="#虚拟内存的实现" class="headerlink" title="虚拟内存的实现"></a>虚拟内存的实现</h2><ul><li>请求分页式存储</li><li>请求分段式存储</li><li>请求段页式存储</li></ul><p>操作系统要提供请求调页（调段）功能，页面置换（段置换）功能</p><h2 id="请求分页管理方式"><a href="#请求分页管理方式" class="headerlink" title="请求分页管理方式"></a>请求分页管理方式</h2><h3 id="一些基本概念"><a href="#一些基本概念" class="headerlink" title="一些基本概念"></a>一些基本概念</h3><ol><li><p>进程的逻辑空间：一个进程的逻辑空间的建立是通过链接器（Linker），将构成进程所需要的所有程序及运行所需环境，按照某种规则装配链接而形成的一种规范格式(布局)，这种格式按字节从0开始编址所形成的空间也称为该进程的逻辑地址空间</p></li><li><p>虚拟地址空间和虚拟存储空间：进程的虚拟地址空间即为进程在内存中存放的逻辑视图。因此，一个进程的虚拟地址空间的大小与该进程的虚拟存储空间的大小相同，都从0开始编址。</p></li><li><p>交换分区（交换文件）：一段连续的磁盘空间（按页划分的），并且对用户不可见。</p><p>功能：在物理内存不够的情况下，OS先把内存中暂时不用的数据，存到磁盘的交换空间，腾出物理内存来让别的程序运行。</p><p>在Linux系统中，交换分区为swap；在Windows系统中则以文件的形式存在（pagefile.sys)。</p><p>交换分区的大小：应当与系统物理内存（M）的大小保持线性比例关系(Linux中）：</p><p>If (M &lt; 2GB) swap &#x3D; 2*M</p><p>else swap &#x3D; M + 2GB</p></li></ol><h3 id="请求式分页管理的页表项"><a href="#请求式分页管理的页表项" class="headerlink" title="请求式分页管理的页表项"></a>请求式分页管理的页表项</h3><ul><li>逻辑页号（隐含）</li><li>访问位（用于页面置换算法）</li><li>修改位（表明此页在内存中是否被修改过）</li><li>保护位（只读、可写、可执行）</li><li>驻留位（1：该页位于内存中；2：该页还在外存中）</li><li>物理页帧号</li></ul><h2 id="页面调入策略"><a href="#页面调入策略" class="headerlink" title="页面调入策略"></a>页面调入策略</h2><ol><li><p>按需调页&#x2F;请求式调页：当且仅当需要某页时才将其调入内存的技术</p></li><li><p>预调页：同时将所需要的所有页一起调入内存</p><p>优缺点：与按需调页相比，阻止了大量的页错误（也叫缺页异常）；但若程序执行的局部性较差，则预先装入的很多页面不会很快被引用，并会占用大量的内存空间，反而降低系统的效率。</p><p>实际应用中，可以为每个进程维护一个当前工作集（<strong>进程运行正在使用的页面集合</strong>）中的页的列表，如果进程在暂停之后需要重启时，根据这个列表使用预调页将所有工作集合中的页一次性调入内存</p></li></ol><h2 id="页面置换策略"><a href="#页面置换策略" class="headerlink" title="页面置换策略"></a>页面置换策略</h2><table><thead><tr><th>算法</th><th>算法规则</th><th>优缺点</th></tr></thead><tbody><tr><td>最优置换（OPT）</td><td>从主存中移出永远不再需要的页面，如这样的页面不存在，则应选择最长时间不需要访问的页面。</td><td>所有页置换算法中页错误率最低<br />但它需要引用串（即页面访问序列）的先验知识，因此无法实现。但通常用于比较性研究，衡量其他页置换算法的效果</td></tr><tr><td>先进先出（FIFO）</td><td>优先淘汰最先进入的页面</td><td>性能较差，较早调入的页往往是经常被访问的页，导致它们被反复调入调出，可能出现belady异常（在使用FIFO算法作为缺页置换算法时，随着分配的页框增多，缺页率反而提高）</td></tr><tr><td>Second Chance（改进的FIFO算法）</td><td></td><td></td></tr><tr><td>Clock（改进的FIFO算法&amp;Second Chance）</td><td>通过一个环形队列，避免将数据在FIFO队列中移动</td><td></td></tr><tr><td>最近最少使用（LRU）</td><td>选择最近一段时间最久不用的页面去置换</td><td>是局部性原理的合理近似，性能接近OPT算法<br />但需记录页面使用的先后关系，实现开销大</td></tr><tr><td>*老化算法（AGING，LRU近似）</td><td>为每个页面设置一个移位寄存器，每隔一段时间（clocktick），所有寄存器右移1位，并将访问位R值从左移入。淘汰寄存器中数值最小的页面</td><td></td></tr><tr><td>*工作集算法</td><td>给定一个进程，记录其工作集，当需要进行页面替换时，选择不在工作集中的页面进行替</td><td></td></tr><tr><td>WSClock工作集时钟页面置换算法</td><td>和时钟算法很像，将页框组成一个循环表，每个表项包含来自基本工作集算法的上次使用时间</td><td></td></tr></tbody></table><hr><p>前面是从一个进程的角度讨论虚存管理的相关问题，下面是从系统管理者（OS）的角度讨论多个进程情况下虚存管理的问题</p><h3 id="概念：工作集和驻留集"><a href="#概念：工作集和驻留集" class="headerlink" title="概念：工作集和驻留集"></a>概念：工作集和驻留集</h3><ul><li>进程的工作集（working set）：当前正在使用的页面的集合。</li><li>进程的驻留集（resident set ）：虚拟存储系统中，每个进程驻留在内存的页面集合，或进程分到的物理页框集合。</li></ul><h2 id="多进程页面分配策略"><a href="#多进程页面分配策略" class="headerlink" title="多进程页面分配策略"></a>多进程页面分配策略</h2><ul><li>固定：每个进程分配固定数量的页框</li><li>可变</li></ul><h2 id="多进程页面置换策略"><a href="#多进程页面置换策略" class="headerlink" title="多进程页面置换策略"></a>多进程页面置换策略</h2><ul><li>局部：系统在进程自身的驻留集中判断当前是否存在空闲页框，并在其中进行置换</li><li>全局</li></ul><h2 id="分配与置换的搭配"><a href="#分配与置换的搭配" class="headerlink" title="分配与置换的搭配"></a>分配与置换的搭配</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph LR;</span><br><span class="line">    A[固定分配策略]--&gt;C[局部置换策略];</span><br><span class="line">    B[可变分配策略]--&gt;C;</span><br><span class="line">    B--&gt;D[全局置换策略];</span><br></pre></td></tr></table></figure><h2 id="抖动问题（thrashing）"><a href="#抖动问题（thrashing）" class="headerlink" title="抖动问题（thrashing）"></a>抖动问题（thrashing）</h2><p>随着驻留内存的进程数目增加，即进程并发程度的提高，处理器利用率先上升，然后下降。因为每个进程的驻留集不断减小，当驻留集小于工作集后，缺页率急剧上升，频繁调页使得调页开销增大。</p><h3 id="抖动的消除与预防"><a href="#抖动的消除与预防" class="headerlink" title="抖动的消除与预防"></a>抖动的消除与预防</h3><p>局部置换策略：使抖动局限在一个小的范围内，但是并未消除抖动的方式。</p><p>引入工作集算法</p><p>预留部分页面</p><p>挂起若干进程</p><h3 id="负载控制"><a href="#负载控制" class="headerlink" title="负载控制"></a>负载控制</h3><p>主要解决系统应当保持多少个活动进程驻留在内存的问题，即控制多道程序系统的度。当内存中的活动进程数太少时，负载控制将增加新进程或激活一些挂起进程进入内存；反之，当内存中的进程数太多时，负载控制将暂时挂起一些进程，减少内存中的活动进程数。</p><h3 id="页面缓冲算法"><a href="#页面缓冲算法" class="headerlink" title="页面缓冲算法"></a>页面缓冲算法</h3><p>对FIFO算法的发展</p><p>被置换页面的选择和处理：用FIFO算法选择被置换页，把被置换的页面放入两个链表之一。即：如果页面未被修改，就将其归入到空闲页面链表的末尾，否则将其归入到已修改页面链表。</p><h3 id="写时复制技术"><a href="#写时复制技术" class="headerlink" title="写时复制技术"></a>写时复制技术</h3><p>两个进程共享同一块物理内存，每个页面都被标志成了写时复制。共享的物理内存中每个页面都是只读的。如果某个进程想改变某个页面时，就会与只读标记冲突，而系统在检测出页面是写时复制的，则会在内存中复制一个页框，然后进行写操作。新复制的页框对执行写操作的进程是私有的，对其他共享写时复制页面的进程是不可见的。</p><p>优点：</p><p>传统的fork()系统调用直接把所有的资源复制给新创建的进程。这种实现过于简单而效率低下，因为它拷贝的数据也许并不共享，如果新进程打算立即执行一个新的映像，那么所有的拷贝都将前功尽弃。</p><p>Linux的fork()使用写时复制实现，它<strong>可以推迟甚至免除拷贝数据的技术</strong>。内核此时并不复制整个进程地址空间，而是让父进程和子进程共享同一个拷贝。只有在需要写入的时候，数据才会复制，从而使各个进程都拥有各自的拷贝。也就是说，资源的复制只有在需要写入的时候才进行。</p><h1 id="页目录自映射"><a href="#页目录自映射" class="headerlink" title="页目录自映射"></a>页目录自映射</h1><p>以二级页表为例：设页表基址$ PT_{base} $（4MB对齐，即低22位为0，非必须，这是为了让页目录表在一个单独页表内，也可以简化计算），则页目录表基址$ PD_{base}&#x3D;PT_{base} | (PT_{base} &gt;&gt; 10) $，自映射目录表项$ PDE_{self-mapping}&#x3D;PT_{base} | (PT_{base} &gt;&gt; 10) | (PT_{base} &gt;&gt; 20) $。可推广到多级页表。</p><p>自映射的数学意义：手持北京地图在北京，必有地图上一点与其表示的地理位置与该点的实际地理位置重合。(压缩映像)</p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>OOpre反思总结</title>
      <link href="/2024/03/19/oo/2023-11-04-oopre-summary/"/>
      <url>/2024/03/19/oo/2023-11-04-oopre-summary/</url>
      
        <content type="html"><![CDATA[<h2 id="作业最终架构"><a href="#作业最终架构" class="headerlink" title="作业最终架构"></a>作业最终架构</h2><p>如图</p><p><img src="/../../images/OO/OOpre%E4%BD%9C%E4%B8%9A%E7%B1%BB%E5%9B%BE.png" alt="OOpre作业类图"></p><h2 id="迭代中的架构调整及考虑"><a href="#迭代中的架构调整及考虑" class="headerlink" title="迭代中的架构调整及考虑"></a>迭代中的架构调整及考虑</h2><ul><li>operate指令执行调整：可以说是我花时间最久，改动最大的一次架构调整了。最初我使用if-else处理指令输入(<del>因为switch-case要消耗更多行，所有没用</del>)，但是每次迭代指令种类都在增加，无法满足“方法不超过60行“的限制，最后是看了老师分享的博客以及自己学习了一下<em>表驱动法</em>，并用此方法优化了自己的代码。<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 表驱动法</span></span><br><span class="line"><span class="title class_">Map</span>&lt;<span class="title class_">Integer</span>, <span class="title class_">Function</span>&lt;<span class="title class_">ArrayList</span>&lt;<span class="title class_">String</span>&gt;, <span class="title class_">Void</span>&gt;&gt; actionsMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"><span class="comment">// 初试配置对应动作</span></span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">1</span>, operate.<span class="title function_">getOp1</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">2</span>, operate.<span class="title function_">getOp2</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">3</span>, operate.<span class="title function_">getOp3</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">4</span>, operate.<span class="title function_">getOp4</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">5</span>, operate.<span class="title function_">getOp5</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">6</span>, operate.<span class="title function_">getOp6</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">7</span>, operate.<span class="title function_">getOp7</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">8</span>, operate.<span class="title function_">getOp8</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">9</span>, operate.<span class="title function_">getOp9</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">10</span>, operate.<span class="title function_">getOp10</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">11</span>, operate.<span class="title function_">getOp11</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">12</span>, operate.<span class="title function_">getOp12</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">13</span>, operate.<span class="title function_">getOp13</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">14</span>, operate.<span class="title function_">getOp14</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">15</span>, operate.<span class="title function_">getOp15</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">16</span>, operate.<span class="title function_">getOp16</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">17</span>, operate.<span class="title function_">getOp17</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">18</span>, operate.<span class="title function_">getOp18</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">19</span>, operate.<span class="title function_">getOp19</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">20</span>, operate.<span class="title function_">getOp20</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">21</span>, operate.<span class="title function_">getOp21</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">22</span>, operate.<span class="title function_">getOp22</span>());</span><br><span class="line">        actionsMap.<span class="title function_">put</span>(<span class="number">23</span>, operate.<span class="title function_">getOp23</span>());</span><br><span class="line">        <span class="comment">// 省略 null 判断</span></span><br></pre></td></tr></table></figure></li><li>指令输入处理和执行分离：这个是参考了PPT里给出的架构，用两个类MyScanner和Manager分别进行输入处理和执行（也是从这里开始真正领悟到了第一节课反复提到的”万物皆可为对象“的含义）。</li><li>特别复杂的指令，如14号指令，将其根据步骤分成若干个函数，分步处理，结构更清晰。</li></ul><h1 id="使用Junit的心得体会"><a href="#使用Junit的心得体会" class="headerlink" title="使用Junit的心得体会"></a>使用Junit的心得体会</h1><p>Junit能够很好地进行单元测试，检查每个方法写的有没有问题。遇到bug时，通过编写单元测试，可以更方便地定位错误位置。</p><p>讲真，最开始总感觉我的Junit没啥用，完全是为了覆盖率而编写测试代码。但是随着迭代，Junit真的帮我de出了很多错误，例如一些访问到空指针的错误，逐渐体会到它的妙用。不过我感觉我对Junit的使用还不太成熟，没有发挥它最大的作用，还有许多要反思的地方。以下是我使用Junit后的总结与反思：</p><ul><li>尽量<strong>不要使用Junit的输出人工判断对错</strong>，交给断言去判断。这是一个我没太注意的点，以后需要注意！</li><li>编写单元测试注意代码覆盖率，尽量都测试到。</li><li>考虑一些极端情况，如数据范围边界处。</li></ul><h1 id="学习oopre的心得体会"><a href="#学习oopre的心得体会" class="headerlink" title="学习oopre的心得体会"></a>学习oopre的心得体会</h1><ul><li>”万物皆可为对象“！前面也提到过，老师第一节课反复提到的话我在经历了几次迭代作业后才真正体会到，尤其是调整自己代码架构的时候，经常会感叹”原来这也可以写一个类啊“。最开始几次的迭代，几乎每次都把代码大改了一遍，因为每次上完课都会觉得“自己之前写的什么玩意儿”&gt;_&lt;（泪目)，虽然耗时特别长，但是在修改过程中还是挺有收获的，对“对象”的理解也更深入了，看着自己的代码结构逐渐清晰非常开心！</li><li>代码模块化。跟第一条有相似之处，最开始我把很多东西都放在Main类里面，但是随着迭代，main方法越来越冗长，看着很不优雅（<del>还有方法不超过60行的限制</del>），所以不得不做出大改动。通过将处理过程分步骤，代码架构更清晰，debug的时候也方便定位错误。</li><li>变量的保护，即关于权限修饰符private，public，protected使用区别的体会。Java是面向对象编程，涉及到顾客使用时的问题，为了不让其他人随意修改一些变量值，必须限制一些变量、方法的访问权限，这在面向过程编程里是没有的。</li></ul><h1 id="对OOpre课程的一点点小建议"><a href="#对OOpre课程的一点点小建议" class="headerlink" title="对OOpre课程的一点点小建议"></a>对OOpre课程的一点点小建议</h1><p>1.每次的作业指导书对我学习这门课帮助挺大的，<strong>但是</strong>第一次作业指导书真的有点难看懂&gt;_&lt;，结构很混乱，甚至不知道从何看起，感觉可以改进一下。</p>]]></content>
      
      
      <categories>
          
          <category> OO </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>OO第一单元总结</title>
      <link href="/2024/03/19/oo/2024-03-19-oo-unit1-summary/"/>
      <url>/2024/03/19/oo/2024-03-19-oo-unit1-summary/</url>
      
        <content type="html"><![CDATA[<h2 id="第一次作业架构与心得分享"><a href="#第一次作业架构与心得分享" class="headerlink" title="第一次作业架构与心得分享"></a>第一次作业架构与心得分享</h2><h3 id="一、架构设计"><a href="#一、架构设计" class="headerlink" title="一、架构设计"></a>一、架构设计</h3><p>如下图：</p><p><img src="/../../images/OO/unit1-1.png"></p><h3 id="二、总体思路"><a href="#二、总体思路" class="headerlink" title="二、总体思路"></a>二、总体思路</h3><p>最开始觉得<code>&#39;(表达式)^n&#39;</code>去括号这块很难解决，后来发现其实可以把题目看作一个多项式化简的问题，而**化简后的每一项都可以表示为<code>系数*x^非负指数</code>**，所以在训练题第二题的基础上增加了幂函数因子类及预处理多项式相乘、合并同类项等过程，具体流程如下：</p><ol><li>输入表达式预处理：删掉所有空白项，去掉连续加减号 </li><li>解析输入表达式：方法类似训练题第二题，采用递归下降的方法，不过训练题只有‘+’，而这里‘+’、‘-’都有，所以需要存储运算符号，而我后续要将Expr化简成Term的集合，所以就用Term的系数coefficient记录‘+’、‘-’</li><li>化简表达式：采用多项式相乘的方法去掉括号，Term类增加了coefficient、exponent属性，将表达式转化成若干项的集合</li><li>合并同类项：将指数相同的项合并</li><li>输出：第一项系数若非负则不输出符号，后续项按照项的sign输出符号及项</li></ol><h3 id="三、bug分析"><a href="#三、bug分析" class="headerlink" title="三、bug分析"></a>三、bug分析</h3><p>本次作业未被hack。我测试别人的方法是造一些和0、1相关的数据，如(0)^0, 1*x, 2-2等等</p><h2 id="第二次作业架构"><a href="#第二次作业架构" class="headerlink" title="第二次作业架构"></a>第二次作业架构</h2><h3 id="一、架构设计-1"><a href="#一、架构设计-1" class="headerlink" title="一、架构设计"></a>一、架构设计</h3><p><img src="/../../images/OO/unit1-2.png" alt="类图"></p><p>与第一次相比：</p><ul><li>增加了Poly、Mono类</li><li>增加了SelfFunction类处理函数</li></ul><h3 id="二、总体思路-1"><a href="#二、总体思路-1" class="headerlink" title="二、总体思路"></a>二、总体思路</h3><p>第二次作业新增的主要任务如下：</p><ol><li>支持嵌套多层括号。</li><li>新增指数函数因子，指数函数括号内部包含任意因子。</li><li>新增自定义函数因子，但自定义函数的函数表达式中不会调用其他自定义函数。</li></ol><p>第一个任务我在第一次作业就已经完成了（事实上感觉只要用了递归下降，这块不需要刻意实现）对于第二个任务，我新建了ExpFunction类来处理。</p><p>第三个任务，我原本尝试了一下在解析表达式的时候处理函数，但是发现很麻烦，再加上我第一次作业的架构不是很好，把标准项放在Term里一并处理，导致解析表达式非常混乱，结构很不清晰，最后还有深浅拷贝的问题，以上种种原因造成了这条路走不通。于是我请教了同学，在交流中发现了自己架构的不足，最后决定重构。</p><p>首先，添加了Poly、Mono类，然后把解析完的Expr转化为Poly来管理。Poly、Mono的主要作用就是存储标准项（标准项的形式为 $${coef*x^{xexpo}*\exp (eexpo)}$$ ,最终的表达式一定能转化为若干标准项相加的形式）,这么做可以把解析和化简分离开，结构更清晰，同时规避了一些深浅拷贝的问题。</p><p>其次，对于自定义函数的处理我选择了在预处理阶段进行字符串替换。这么做解析阶段就不用处理函数了，而且对于处理第三次作业新增的“函数定义式可以调用已经定义的函数”这一新任务意外地地方便，不过需要注意的是：</p><ul><li>函数定义式里的形参替换成因子时因子外面要加一层括号</li><li>函数表达式替换表达式里的函数调用的时候表达式外面要加一层括号<br>这么做是为了避免运算优先级出错，例如：<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span></span><br><span class="line">f(x)=x+<span class="number">1</span></span><br><span class="line">f(x)*<span class="number">2</span></span><br><span class="line">不加括号的结果是x+<span class="number">1</span>*<span class="number">2</span>=x+<span class="number">2</span>,显然不对</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span></span><br><span class="line">f(x)=x^<span class="number">2</span>;</span><br><span class="line">f(-<span class="number">2</span>)</span><br><span class="line">不加括号的结果是-<span class="number">2</span>^<span class="number">2</span>=-<span class="number">4</span>,显然也不对</span><br></pre></td></tr></table></figure><h3 id="三、bug分析-1"><a href="#三、bug分析-1" class="headerlink" title="三、bug分析"></a>三、bug分析</h3><p>这次作业在写的时候遇到了很多bug：</p><ul><li>深、浅拷贝问题：第一次作业我把标准项放到Term里，第二次我本来打算沿用的，然而对深、浅拷贝认识不透彻导致我第二次作业debug出现了“闹鬼”，有的数据明明没有动它但它自己变了，由于这个变动的数据在很深层，很难找出哪里的拷贝出现了问题，我决定直接新建两个类Poly、Mono来管理处理完的表达式，并在Poly类中专门写了一个方法<code>public Poly copy()</code>来进行拷贝，避免出现“闹鬼”事件</li><li>指数函数化简问题：我的做法是把表达式转化成Poly类的时候把指数函数的指数因子乘进去，作为指数函数的指数的一部分（即Poly中的属性ArrayList&lt;Monos&gt;数组的一个Mono管理），如何最后输出时，如果<code>exp(因子)</code>的因子是<code>coef*x^xexpo</code>形式或者<code>coef*exp(...)^eexpo</code>形式，就把系数coef提到括号外，减少一个括号的使用,即<code>exp(...)^coef</code>。但是最开始忽略了一点：如果系数coef是负数，不能提出来，否则指数就是负数，不符合指数<strong>非负</strong>的要求，即<code>exp(...)^coef</code>(coef不能是负数)。（利用这一点，我成功hack了房间里一位同学，不过ta的问题是只把<code>|coef|</code>提出来，负号<code>-</code>留里面，但是同样不行。例如<code>exp((-3*x)) -&gt; exp(-x)^3</code>，变量因子是不能有负号的，这里提取来之后里面还是一个表达式，需要再加一层括号，<code>exp((-x))^3</code>才是正确的）</li></ul><p>本次作业未被hack，但是强测有一个数据点幂函数指数爆int了，并且由此发现自己合并同类项的方法时间复杂度较高，进行了优化。互测阶段我造数据的方法就是拿我自己写代码时候遇到的bug点去测，比如指数函数化简问题（如上）。</p><h2 id="第三次作业架构"><a href="#第三次作业架构" class="headerlink" title="第三次作业架构"></a>第三次作业架构</h2><h3 id="一、架构设计-2"><a href="#一、架构设计-2" class="headerlink" title="一、架构设计"></a>一、架构设计</h3><p>最终总体架构如下：</p><p><img src="/../../images/OO/unit1-3.png" alt="第三次作业架构图"></p><p>与之前相比，新增了Derivative类管理求导因子，主要修改了Poly、Mono里的一些方法用来求导</p><h3 id="二、基本思路"><a href="#二、基本思路" class="headerlink" title="二、基本思路"></a>二、基本思路</h3><p>这次作业相比第二次作业增加了两点：</p><ol><li>自定义函数支持调用其他“已定义的”函数</li><li>支持求导操作</li></ol><p>对于第一点，由于我第二次作业采用的是在预处理阶段字符串替换掉函数，即：读入函数的名称、参数和表达式，放在ArrayList&lt;SelfFunction&gt;数组中存储，然后在预处理阶段替换掉表达式里出现函数名的地方，所以本次作业我直接把替换阶段的函数列表反着遍历就可以了。</p><p>对于第二点，我的解决办法是新开一个Derivative类，在解析表达式的时候遇到“dx”就把它括号后面的表达式解析完后存储在Derivative中的expr属性中，然后在Expr转换为Poly时再求导</p><p>由于我把Derivative里的expr转化为Poly类再求导，所以求导公式非常固定，即：</p><p>$$dx\left( {coef<em>x^{xexpo}<em>\exp \left(eexpo\right)} \right) &#x3D; coef</em>xexpo</em>x^{xexpo - 1}<em>\exp (eexpo) + coef</em>dx(ab)*x^{xexpo}*\exp (eexpo)$$</p><p>求导中也用到了递归下降的思想，对Poly求导，即对Poly的每个Mono求导；对Mono求导，应用上述公式，得到的是Poly&#x2F;ArrayList&lt;Mono&gt;</p><h3 id="三、bug分析-2"><a href="#三、bug分析-2" class="headerlink" title="三、bug分析"></a>三、bug分析</h3><p>本次作业无强测bug，未被hack。第二次作业的架构调整对第三次作业帮助很大，在其上迭代开发非常清晰，不容易出现问题</p><h2 id="度量分析"><a href="#度量分析" class="headerlink" title="度量分析"></a>度量分析</h2><p>方法复杂度</p><p><img src="/../../images/OO/%E6%96%B9%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6.png" alt="方法复杂度"></p><p>类复杂度</p><p><img src="/../../images/OO/%E7%B1%BB%E5%A4%8D%E6%9D%82%E5%BA%A6.png" alt="类复杂度"></p><p>各类代码行数</p><p><img src="/../../images/OO/%E7%B1%BB%E4%BB%A3%E7%A0%81%E9%87%8F.png" alt="代码行数"></p><h2 id="架构设计体验"><a href="#架构设计体验" class="headerlink" title="架构设计体验"></a>架构设计体验</h2><p>我的架构是基于第一次实验提供的递归下降方法，主要用Lexer、Parser类解析表达式，用Expr、Term、Factor保存，然后根据每次迭代增加相应的类与方法（见每次作业的架构设计部分）。在第二次作业经历了一次重构，主要是增加了Poly、Mono类，将表达式解析和化简分离。</p><p>新的可能迭代场景：表达式中增加三角函数。需要新增三角函数类Trigo，标准项变成$$coef*x^{xexpo}*\exp \left(eexpo\right)*sin\left(poly\right)^{triExpo}$$, 可以将cos化为sin一并处理。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><ul><li>在第二次作业强测由于爆int发现自己合并同类项的复杂度太高（因为我是找出x的指数最大值max，然后从max到0遍历每个指数，再遍历每个项找到满足当前条件的指数项合并，但是事实上可能表达式中根本就没有或很少比max小的指数项，比如表达式为$x^{100000000000}$, 我要从100000000000遍历到0，非常费时）。于是优化后的化简方式为：遍历多项式（Poly）里的每个单项式（Mono），以当前单项式为基准，遍历它后面的单项式看是否有它的同类项。</li><li>最开始去括号化简我是采用先全部乘开再合并同类项，后来发现边乘开边合并同类项不仅速度更快，而且指数函数的指数多项式比较起来更方便。</li></ul><h2 id="心得体会"><a href="#心得体会" class="headerlink" title="心得体会"></a>心得体会</h2><ul><li>对深、浅拷贝的问题有了很深刻的认识（de这种bug的感觉实在是印象深刻）</li><li>对继承和接口的作用有了更清晰的了解：继承是数据层面的抽象（有相同属性），接口是行为层面的抽象（有类似的方法，但是可能实现过程不太一样）</li></ul><h2 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h2><p>个人认为性能分的计算方式可以适当调整一下，寻找更合理的计算方式。以这次作业为例，在实际生活中可能人们更习惯于看到多项式按一定规律排列（比如按x的降次&#x2F;升次排列），但是为了性能分不得不把最高次系数为负数的项挪到后面，感觉不是很美观。如果换种方式，比如可以让输出表达式少于某一长度就得多少分，而不是以所有人作业的输出最短长度为基准（或者其他更好的办法），或许也不错。</p>]]></content>
      
      
      <categories>
          
          <category> OO </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>yolov5训练总结</title>
      <link href="/2024/03/12/deeplearning/2024-03-12-yolov5-training-summary/"/>
      <url>/2024/03/12/deeplearning/2024-03-12-yolov5-training-summary/</url>
      
        <content type="html"><![CDATA[<h2 id="yolov5前期配置和运行"><a href="#yolov5前期配置和运行" class="headerlink" title="yolov5前期配置和运行"></a>yolov5前期配置和运行</h2><p>参考资料：<a href="http://t.csdnimg.cn/MjIs3">Yolov5训练自己的数据集（详细完整版）</a></p><p>注：VOCData文件夹（可以自己命名）下的images和labels文件夹不能叫别的名字！</p><p>使用镜像源安装库：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt -i  https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>运行train.py的命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --weights weights/yolov5s.pt  --cfg models/yolov5s.yaml  --data data/myvoc.yaml --epoch 200 --batch-size 8 --img 640   --device cpu --resume True</span><br></pre></td></tr></table></figure><h2 id="yolov5项目目录结构理解"><a href="#yolov5项目目录结构理解" class="headerlink" title="yolov5项目目录结构理解"></a>yolov5项目目录结构理解</h2><p>参考资料：<a href="https://zhuanlan.zhihu.com/p/669304006">YOLOv5系列(二) 解析项目目录结构(详尽)</a></p><ol><li>models&#x2F;yolov5_.yaml:模型的配置文件，有n、s、m、l、x版本，逐渐增大（随着架构的增大，训练时间也是逐渐增大）</li><li>data&#x2F;hyps&#x2F;hyp.scratch-_.yaml:超参数配置文件，有low、med、high版本，数据增强效果递增</li></ol><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>我用git拉取了yolov5源代码（如下图，右边有点点的就是我修改了的文件）</p><p><img src="/../../images/%E7%9B%AE%E5%BD%95.png" alt="dir"></p><p>就按这个顺序依次说明</p><ol><li>data文件夹：新建了myvoc.yaml文件</li><li>models文件夹：新建了yolo5s_well.yaml文件，复制了yolo5s里的内容，仅修改了类</li><li>VOCData文件夹：存储自己的数据集，两个py文件顾名思义：用来生成训练集和验证集以及将数据集由xml转化为txt供模型训练</li><li>random_search.py:没有用，可忽略</li><li>train.py:修改了其中的一些参数，主要是路径修改<br><img src="/../../images/resume%E5%8F%82%E6%95%B0.png" alt="resume"><br>在九天上我把resume参数default改为true了，这样可以在训练意外中断后，能在之前训练的基础上继续训练，具体做法如下：</li></ol><ul><li>命令行里输入cd yolov5进入文件夹</li><li>输入conda activate pytorch激活我配置好的虚拟环境</li><li>输入nohup python train.py在原来的基础上继续训练，nohup可以把输入放到nohup.txt文件里，保证不在该界面的时候训练依然可以继续（官方文档的ReadMe有写），可以继续训练是因为我改了train.py里的参数，这么输入就可以了</li></ul><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><h3 id="yolov5源代码中自带的数据增强方法：需激活"><a href="#yolov5源代码中自带的数据增强方法：需激活" class="headerlink" title="yolov5源代码中自带的数据增强方法：需激活"></a>yolov5源代码中自带的数据增强方法：需激活</h3><p>参考资料：<a href="http://t.csdnimg.cn/9WOJp">YOLOv5-6.x源码分析（七）—- 数据增强之augmentations.py</a> </p><p>此篇博客详细介绍了yolov5中使用的数据增强方法，包括：</p><ol><li>归一化和反规范化</li><li>hsv 色调-饱和度-亮度的图像增强</li><li>直方图均衡化增强</li><li>图像框的平移复制增强</li><li>图片缩放letterbox</li><li>随机透视变换</li><li>cutout</li><li>mixup</li><li>box_candidates</li></ol><p>相关文件：</p><ul><li>utils&#x2F;augmentations.py</li><li>utils&#x2F;dataloaders.py</li><li>models&#x2F;yolov5s_well.py</li><li>data&#x2F;hyps&#x2F;hyp.scrath-high.yaml</li></ul><p><strong>使用方法（每个方法启用的数据增强不一样）</strong></p><p><strong>1. 安装步骤</strong></p><ul><li>激活虚拟环境:<code>activate pytorch</code></li><li>下载库:<code>pip install albumentations -i https://pypi.tuna.tsinghua.edu.cn/simple</code></li></ul><p>_补充说明_：</p><p>“Albumentations——强大的数据增强库（图像分类、分割、关键点检测、目标检测）” <br>  “YOLOv5集成Albumentations，添加新的数据增强方法”</p><p>  根据augmentations.py的代码：<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class Albumentations:</span><br><span class="line">  # YOLOv5 Albumentations class (optional, only used if package is installed)</span><br></pre></td></tr></table></figure><br>  可推断必须安装albumentations库才能启动数据增强<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">T = [</span><br><span class="line">        A.RandomResizedCrop(height=size, width=size, scale=(0.8, 1.0), ratio=(0.9, 1.11), p=0.0),</span><br><span class="line">        A.Blur(p=0.01),</span><br><span class="line">        A.MedianBlur(p=0.01),</span><br><span class="line">        A.ToGray(p=0.01),</span><br><span class="line">        A.CLAHE(p=0.01),</span><br><span class="line">        A.RandomBrightnessContrast(p=0.0),</span><br><span class="line">        A.RandomGamma(p=0.0),</span><br><span class="line">        A.ImageCompression(quality_lower=75, p=0.0),</span><br><span class="line">]  # transforms</span><br></pre></td></tr></table></figure><br>  这部分可以看到具体应用了哪些数据增强方法</p><p><strong>2. hyp.scratch.yaml调整（可启用mixup）</strong></p><ul><li>方法一：直接用官方的配置文件，将train.py里–hyp参数的默认使用文件修改一下<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(&quot;--hyp&quot;, type=str, default=ROOT / &quot;data/hyps/hyp.scratch-low.yaml&quot;, help=&quot;hyperparameters path&quot;)</span><br></pre></td></tr></table></figure>把这里的<code>hyp.scratch-low.yaml</code>换成<code>hyp.scratch-med.yaml</code>或者<code>hyp.scratch-high.yaml</code></li><li>方法二：自己调整hyp.scratch.yaml文件里的参数（不太敢瞎调，或许可以找找文章参考一下别人的？）</li></ul><p> **<em>补充说明：</em>**Mixup是指将两张图片和其标签，按权重进行叠加，生成新的数据集和其所对应的标签。</p><p>Mixup的步骤如下：</p><ol><li>从训练数据中随机选择两个样本，记作样本A和样本B。</li><li>随机选择一个介于0和1之间的权重值λ。</li><li>将样本A和样本B的特征按照权重值λ进行线性组合：mixed_feature &#x3D; λ * feature_A + (1 - λ) * feature_B。</li><li>将样本A和样本B的标签按照权重值λ进行线性组合：mixed_label &#x3D; λ * label_A + (1 - λ) * label_B。</li><li>使用mixed_feature作为新的训练样本，使用mixed_label作为对应的标签</li></ol><p><strong>3. 启用cutout</strong></p><p>把utils&#x2F;dataloaders.py的被注释掉的cutout部分相关代码取消注释(光标处的下两行)<br><img src="/../../images/cutout%E4%BB%A3%E7%A0%81.png" alt="cutout代码"></p><p><strong><em>补充说明：</em></strong><br>Cutout是指随机的将样本中的部分区域cut掉，并且填充0像素值，分类的结果不变</p><h3 id="其他数据增强方法"><a href="#其他数据增强方法" class="headerlink" title="其他数据增强方法"></a>其他数据增强方法</h3><ol><li>Cutmix (参考资料：<a href="http://t.csdnimg.cn/iNl8H">数据增强方法Mixup、Cutout、CutMix、ClassMix</a>)</li></ol><p>  Cutmix综合了Mixup和Cutout的想法，把一张图片上的某个随机矩形区域剪裁到另一张图片上生成新图片。标签的处理和mixUp是一样的，都是按照新样本中两个原样本的比例确定新的混合标签的比例。</p><h2 id="用自己训练的模型预测-推理"><a href="#用自己训练的模型预测-推理" class="headerlink" title="用自己训练的模型预测&#x2F;推理"></a>用自己训练的模型预测&#x2F;推理</h2><p>修改detect.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_opt</span>():</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--weights&quot;</span>, nargs=<span class="string">&quot;+&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&quot;runs/train/exp1/weights/best.pt&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;model path or triton URL&quot;</span>) <span class="comment">#</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--source&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&quot;testData/images&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;file/dir/URL/glob/screen/0(webcam)&quot;</span>) <span class="comment">#</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--data&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&quot;data/myvoc.yaml&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;(optional) dataset.yaml path&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--imgsz&quot;</span>, <span class="string">&quot;--img&quot;</span>, <span class="string">&quot;--img-size&quot;</span>, nargs=<span class="string">&quot;+&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">640</span>], <span class="built_in">help</span>=<span class="string">&quot;inference size h,w&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--conf-thres&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.25</span>, <span class="built_in">help</span>=<span class="string">&quot;confidence threshold&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--iou-thres&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.45</span>, <span class="built_in">help</span>=<span class="string">&quot;NMS IoU threshold&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--max-det&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1000</span>, <span class="built_in">help</span>=<span class="string">&quot;maximum detections per image&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--device&quot;</span>, default=<span class="string">&quot;&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;cuda device, i.e. 0 or 0,1,2,3 or cpu&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--view-img&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;show results&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--save-txt&quot;</span>,  default=<span class="literal">True</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;save results to *.txt&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--save-csv&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;save results in CSV format&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--save-conf&quot;</span>,default=<span class="literal">True</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;save confidences in --save-txt labels&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--save-crop&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;save cropped prediction boxes&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--nosave&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;do not save images/videos&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--classes&quot;</span>, nargs=<span class="string">&quot;+&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;filter by class: --classes 0, or --classes 0 2 3&quot;</span>)</span><br></pre></td></tr></table></figure><p>weights: 修改为自己训练出的模型,即runs&#x2F;train&#x2F;exp&#x2F;weights目录下的.pt文件</p><p>source: 修改为自己想检测的图片集所在的目录</p><p>data: 修改为data目录下自己训练时新建的.yaml(里面有训练集、验证集的文件位置和分类信息)</p><p>save-txt: 因为我需要把检测结果存为txt文件，所以在这里添加了<code>default=True</code></p><p>save-conf:同样因为检测结果需要输出置信度,所以在这里添加了<code>default=True</code></p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>conda命令</title>
      <link href="/2024/03/04/deeplearning/2024-03-04-conda/"/>
      <url>/2024/03/04/deeplearning/2024-03-04-conda/</url>
      
        <content type="html"><![CDATA[<ul><li>查看已创建的环境。使用命令 <code>conda info --envs</code> 或 <code>conda env list</code> 可以显示所有已创建的环境。</li><li>创建新环境。使用命令 <code>conda create -n env_name python=3.7</code> 可以创建一个名为env_name的新环境，并安装指定版本的Python。</li><li>激活环境。使用命令 <code>conda activate env_name</code> 可以激活一个特定的环境。</li><li>停用环境。使用命令 <code>conda deactivate</code> 可以退出当前激活的环境。</li><li>列出当前环境中的所有软件包。使用命令 <code>conda list</code> 可以显示当前环境中已安装的所有包及其版本。</li><li>查找包信息。使用命令 <code>conda search package_name</code> 可以在Conda的源中搜索指定包的信息。</li><li>安装包。使用命令 <code>conda install package_name</code> 可以在当前活跃环境中安装指定的包。</li><li>更新包。使用命令 <code>conda update package_name</code> 可以更新指定的包到最新版本。</li><li>删除包。使用命令 <code>conda remove package_name</code> 可以从当前环境中删除指定的包。</li><li>删除环境。使用命令 <code>conda remove --name env_name --all</code> 可以删除一个完整的环境及其所有包。</li><li>更新Conda本身。使用命令 <code>conda update conda</code> 可以将Conda更新到最新版本。</li><li>更新<a href="https://www.baidu.com/s?wd=Anaconda&tn=15007414_5_dg&usm=1&ie=utf-8&rsv_pq=befb7000004e24f6&oq=conda%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4&rsv_t=1f0dKfK3WIypazc9aGRul9QdDPMiRPpeAng+JalQIddV0MmCY2I2wqFxm5YfdXd/oIayQg&sa=re_dqa_zy&icon=1">Anaconda<em></em></a>集合包。使用命令 <code>conda update anaconda</code> 可以更新Anaconda的集合包。</li><li>降级Conda版本。使用命令 <code>conda install -nbase conda==4.6.7</code> 可以将Conda降级到指定版本。</li></ul>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络CNN</title>
      <link href="/2024/03/01/deeplearning/2024-03-01-cnn/"/>
      <url>/2024/03/01/deeplearning/2024-03-01-cnn/</url>
      
        <content type="html"><![CDATA[<h1 id="卷积神经网络构成部分"><a href="#卷积神经网络构成部分" class="headerlink" title="卷积神经网络构成部分"></a>卷积神经网络构成部分</h1><p>$$n_H^{[l]} &#x3D; [\frac{ {n_H^{[l - 1]} + 2{p^{[l]}} - {f^{[l]}}}}{s^{[l]}}] + 1$$<br>$$n_W^{[l]} &#x3D; [\frac{ {n_W^{[l - 1]} + 2{p^{[l]}} - {f^{[l]}}}}{s^{[l]}}] + 1$$</p><ul><li>输入：$n_H^{[l-1]} \times n_W^{[l-1]} \times n_C^{[l-1]}$</li><li>权重参数$w^{[l]} : f^{[l]} \times f^{[l]} \times n_c^{[l-1]} \times n_c^{[l]}$ （$n_c^{[l]}$表示过滤器总数量）</li><li>偏差参数$b^{[l]}: 1 \times 1 \times 1 \times n_c^{[l]}$</li></ul><p>$$\begin{gathered}<br>  {a^{[0]}} &#x3D; x \<br>  a^{[1]} &#x3D; g({z^{[1]}}) \<br>  {z^{[1]}} &#x3D; {w^{[1]}}{a^{[0]}} + {b^{[1]}}\<br>\end{gathered}$$</p><p>${w^{[1]}}{a^{[0]}}$卷积计算，$+{b^{[1]}}$加上偏差</p><p>卷积网络通常有三层：</p><h2 id="卷积层（convolution-layer，简称Conv）"><a href="#卷积层（convolution-layer，简称Conv）" class="headerlink" title="卷积层（convolution layer，简称Conv）"></a>卷积层（convolution layer，简称Conv）</h2><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>提取输入图片的特征，使图像从具体到抽象</p><h3 id="填充-padding"><a href="#填充-padding" class="headerlink" title="填充(padding)"></a>填充(padding)</h3><p>如果有一个$n \times n$的图像，用$f \times f$的过滤器做卷积，那么输出的维度为$(n-f+1)\times (n-f+1)$。这样存在缺点：1. 输出缩小；2. 图像边缘的大部分信息都丢失了</p><p>padding：在图像四周均填充p个像素点，这样输出维度变成了（一般向下取整）$(n+2p-f+1)\times (n+wp-f+1)$</p><ul><li>Valid卷积：不填充</li><li>Same卷积：填充后输入大小和输出大小相同，即$n+2p-f+1&#x3D;n -&gt; p &#x3D; (f-1)&#x2F;2$</li></ul><p>在计算机视觉中，f通常是奇数，因为：</p><ul><li>如果f为偶数，只能使用不对称填充</li><li>奇数维过滤器有中心像素点，便于指出过滤器的位置</li></ul><h3 id="卷积步长-strided-convolutions"><a href="#卷积步长-strided-convolutions" class="headerlink" title="卷积步长(strided convolutions)"></a>卷积步长(strided convolutions)</h3><p>设步长为s，输出大小为$[\frac{n + 2p - f}{s} + 1] \times [\frac{n + 2p - f}{s} + 1]$(向下取整)</p><h3 id="三维卷积"><a href="#三维卷积" class="headerlink" title="三维卷积"></a>三维卷积</h3><p>$$<br>输入图像（n\times n \times {n_c}） * 过滤器(f\times f \times {n_c})\xrightarrow{s &#x3D; 1,p &#x3D; 0}输出((n-f+1)\times (n-f+1))<br>$$</p><p>${n_c}$表示通道数，对应位置相乘后全部数相加</p><blockquote><p>对于某个卷积层，无论输入图像有多少个通道，输出图像通道数总是等于卷积核数量</p></blockquote><h2 id="池化层-pooling-layer，简称Pool"><a href="#池化层-pooling-layer，简称Pool" class="headerlink" title="池化层(pooling layer，简称Pool)"></a>池化层(pooling layer，简称Pool)</h2><h3 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h3><ol><li>挑选不受位置干扰的图像信息。</li><li>对特征进行降维，提高后续特征的感受野，也就是让池化后的一个像素对应前面图片中的一个区域。</li><li>因为池化层是不进行反向传播的，而且池化层减少了特征图的变量个数，所以池化层可以减少计算量。</li></ol><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul><li>最大池化：将输入矩阵划分成若干小矩阵，选取每个小矩阵中的最大值</li><li>平均池化：将输入矩阵划分成若干小矩阵，选取每个小矩阵中的平均值</li></ul><p>超参数：f，s</p><h2 id="全连接层-fully-connected-layer，简称FC"><a href="#全连接层-fully-connected-layer，简称FC" class="headerlink" title="全连接层(fully connected layer，简称FC)"></a>全连接层(fully connected layer，简称FC)</h2><p>作用：将前一层得到的矩阵平整化为一个一维向量输出（类似普通的神经层）</p><h1 id="卷积神经网络常见模式"><a href="#卷积神经网络常见模式" class="headerlink" title="卷积神经网络常见模式"></a>卷积神经网络常见模式</h1><p>一个或多个Conv + 一个Pool + 一个或多个Conv + 一个Pool + 几个全连接层 + softmax</p><p>注：</p><ul><li>池化层和最大池化层没有参数</li><li>卷积层的参数相对较少，许多参数存在于神经网络的全连接层</li></ul><p><strong>尽量不要自己设置超参数，而是查看文献中别人采用了哪些超参数</strong></p><p>卷积的优点：</p><ul><li>参数共享 parameter sharing</li><li>稀疏链接 sparsity of connections</li></ul><h1 id="对抗攻防"><a href="#对抗攻防" class="headerlink" title="对抗攻防"></a>对抗攻防</h1><p>概念：训练样本中隐藏了微小噪声，人眼无法识别出来，但是会造成模型产生错误预测。</p><p>解决办法：强化学习，延迟奖励机制</p><p>监督学习试图基于训练数据预测其标签，并正确泛化至未经过训练的数据；但在强化学习中，由于延迟奖励，当前状态下的最优动作往往难以定义，且在智能体与环境交互的过程中，足以代表训练环境的数据往往难以获取。</p><p>对抗攻击：白盒设置、黑盒设置（主要）</p><p>目标：增强模型的鲁棒性</p><h1 id="多智能体"><a href="#多智能体" class="headerlink" title="多智能体"></a>多智能体</h1><p>把博弈论运用在人机对抗、机器与机器的对抗中。这些智能体都拥有自己的优化目标，比如最大化自身收益。</p><p>传统无生命的物理对象通过机器学习等方法正在逐渐被赋予如生命体一样的智能性。多智能体和自动控制的差距缩小</p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>OS概述</title>
      <link href="/2024/03/01/os/2024-03-07-os-gai-shu/"/>
      <url>/2024/03/01/os/2024-03-07-os-gai-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="操作系统的概念和功能"><a href="#操作系统的概念和功能" class="headerlink" title="操作系统的概念和功能"></a>操作系统的概念和功能</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>负责管理协调硬件、软件等计算机资源的工作，为上层用户、应用服务提供简单易用的服务，是一种系统软件</p><ul><li>UI</li><li>ABI：可以通过相应的编程语言使用这些接口，以操作计算机系统来完成某项特定任务</li><li>API：将程序与操作系统、硬件平台之间紧密协作需要遵守的特定规则保留出来</li><li>ISA：工业标准体系结构</li></ul><h2 id="功能和目标"><a href="#功能和目标" class="headerlink" title="功能和目标"></a>功能和目标</h2><ul><li>资源管理者<ul><li>处理机管理</li><li>存储器管理</li><li>文件管理</li><li>设备管理</li></ul></li><li>向上层提供服务<ul><li>直接给用户使用的<ul><li>GUI（图形用户界面）</li><li>命令接口：联机命令接口（一句一句执行），脱机命令接口（一批一起执行）</li></ul></li><li>给软件&#x2F;程序员使用的：程序接口（即系统调用）</li></ul></li><li>对硬件机器的扩展：虚拟机</li></ul><h2 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h2><ul><li>并发性：宏观上同时，微观上交替（区别于并行：同一时刻同时发生）<br>注：单核CPU各程序只能并发执行，多核CPU可以并行执行</li><li>共享性：并发和共享互为存在条件<ul><li>互斥共享方式（如对摄像头设备的共享使用）</li><li>同时共享方式（如对硬盘资源的共享使用）</li></ul></li><li>虚拟性：把一个物理上的实体变为若干个逻辑上的对应物<ul><li>空分复用技术（如虚拟存储技术）</li><li>时分复用技术（如虚拟处理器技术）</li></ul></li><li>异步性</li></ul><h2 id="发展与分类"><a href="#发展与分类" class="headerlink" title="发展与分类"></a>发展与分类</h2><p>冯·诺伊曼体系结构：存储程序式，指令与数据共同存储，通过一个总线访问</p><p>哈佛结构：将指令存储与数据存储分离</p><ol><li><p>手工操作阶段</p></li><li><p>批处理阶段</p><ol><li>单道批处理系统（引入脱机输入输出技术，即输入&#x2F;输出脱离主机控制）</li><li>多道批处理系统（操作系统开始出现）<br>多道程序设计技术，就是指允许多个程序同时进入内存并运行。即同时把多个程序放入内存中（前提是内存放的下），并允许它们交替在CPU中运行，它们共享系统中的各种硬、软件资源。当一道程序因<strong>I&#x2F;O请求</strong>而暂停运行时，CPU便立即转去运行另一道程序。<br>引入多道程序设计技术后形成多道批处理系统<br>优点：系统吞吐量大，资源利用率高<br>缺点：平均周转时间长，不能交互（上面所说的<strong>I&#x2F;O请求</strong>是指请求“读取文件”之类的操作，需要等待直到I&#x2F;O操作完成，所以不是在和用户交互）</li></ol></li><li><p>分时操作系统</p><p>分时系统：将CPU处理时间分割为多个时间片，将时间片分给不同程序，达到多个程序“同时”运行的效果<br>两种典型分时操作系统：(1) Multics&#x2F;Unix (1968&#x2F;1970) (2) IBM VM 360&#x2F;370</p></li><li><p>实时操作系统：能优先处理紧急任务，一般用于嵌入式</p><ul><li>硬实时系统：必须在绝对严格的限定时间内完成处理</li><li>软实时系统：能接受偶尔违反时间规定</li></ul></li><li><p>网络操作系统</p><p>在传统单机OS上加单独软件层，主要提供联网功能和资源的远程访问，实现多机互联、分布式与嵌入式系统</p></li><li><p>分布式操作系统</p><p>多台机器统一管理形成单一系统，相比于网络操作系统，对用户和应用高度透明</p></li><li><p>个人计算机操作系统</p></li></ol><p>注：</p><table><thead><tr><th>多道批处理</th><th>分时技术</th></tr></thead><tbody><tr><td>不可交互</td><td>可交互</td></tr><tr><td>侧重于作业的批量处理和长处理时间</td><td>强调用户与计算机的实时交互和独占使用</td></tr></tbody></table><h1 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h1><h2 id="程序运行原理"><a href="#程序运行原理" class="headerlink" title="程序运行原理"></a>程序运行原理</h2><p>高级语言编写的代码 –&gt; 机器指令<br>程序运行的过程就是CPU执行指令的过程</p><h2 id="两类程序"><a href="#两类程序" class="headerlink" title="两类程序"></a>两类程序</h2><ul><li>内核程序</li><li>应用程序</li></ul><h2 id="两类指令"><a href="#两类指令" class="headerlink" title="两类指令"></a>两类指令</h2><ul><li>特权指令</li><li>非特权指令</li></ul><h2 id="两种处理器状态"><a href="#两种处理器状态" class="headerlink" title="两种处理器状态"></a>两种处理器状态</h2><ul><li>内核态&#x2F;核心态&#x2F;管态</li><li>用户态&#x2F;目态</li></ul><h2 id="内核"><a href="#内核" class="headerlink" title="内核"></a>内核</h2><p>是操作系统最重要最核心的部分，由很多内核程序组成操作系统内核</p><p>如何改变CPU状态？</p><ul><li>内核态 –&gt; 用户态 ：一条修改PSW（程序状态字，也叫程序状态寄存器）的特权指令</li><li>用户态 –&gt; 内核态 ：由中断引起，硬件自动完成</li></ul><h1 id="中断和异常"><a href="#中断和异常" class="headerlink" title="中断和异常"></a>中断和异常</h1><ol><li><p>作用：<br>让操作系统内核强行夺回CPU控制权，使CPU从用户态变为内核态</p></li><li><p>分类</p><ul><li>异常（内中断）<ul><li>陷阱(trap)</li><li>故障</li><li>终止</li></ul></li><li>中断（外中断）<ul><li>时钟中断</li><li>I&#x2F;O中断请求</li></ul></li></ul></li><li><p>中断机制的基本实现原理</p><ol><li>检查中断信号<ul><li>异常：CPU在执行指令会检查是否有异常发生</li><li>中断：每个指令周期末尾，CPU都会检查是否有中断信号需要处理</li></ul></li><li>找到相应的中断处理程序：通过中断向量表实现</li></ol></li></ol><h1 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h1><ol><li><p>定义：操作系统对应用程序&#x2F;程序员提供的接口</p></li><li><p>系统调用和库函数的关系：有的库函数是对系统调用的进一步封装，有的库函数没有使用系统调用</p></li><li><p>什么功能要用系统调用实现：设备管理、文件管理、进程控制、进程通信、内存管理</p></li><li><p>系统调用的过程：</p><ol><li>传参</li><li>陷入(trap)指令</li><li>由操作系统内核程序处理系统调用请求</li><li>返回应用程序</li></ol></li></ol><h1 id="OS体系结构"><a href="#OS体系结构" class="headerlink" title="OS体系结构"></a>OS体系结构</h1><table><thead><tr><th></th><th>大内核</th><th>微内核</th></tr></thead><tbody><tr><td>特点</td><td>将操作系统的主要功能模块都作为系统内核，运行在核心态</td><td>只把最基本的功能保留在内核</td></tr><tr><td>例子</td><td>如Linux、UNIX</td><td>如Windows NT</td></tr></tbody></table><h1 id="系统引导"><a href="#系统引导" class="headerlink" title="系统引导"></a>系统引导</h1><p><img src="D:/mynotes/images/OS/系统引导.jpg" alt="系统引导过程图"></p><p>BootLoader(引导加载程序)：系统加电后运行的第一段软件代码，是在OS内核运行之前的一小段程序。（也就是说存放在图中PBR所在区域）</p><ul><li>boot：初始化嵌入式系统硬件使之运行起来，至少是部分运行起来。</li><li>load：将OS映像加载到内存中，并跳转到OS的代码运行</li></ul><table><thead><tr><th>处理器类型</th><th>常用bootloader</th></tr></thead><tbody><tr><td>MIPS处理器（大多用于嵌入式系统）</td><td>U-boot</td></tr><tr><td>x86处理器</td><td>LILO、GRUB</td></tr></tbody></table><p><strong>BootLoader的实现严重依赖于具体硬件</strong></p><h2 id="计算机的启动过程（MIPS）"><a href="#计算机的启动过程（MIPS）" class="headerlink" title="计算机的启动过程（MIPS）"></a>计算机的启动过程（MIPS）</h2><h3 id="U-boot"><a href="#U-boot" class="headerlink" title="U-boot"></a>U-boot</h3><p>大多数BootLoader都分为stage1和stage2两大部分，U-boot也不例外</p><ul><li>stage1：依赖于cpu体系结构的代码（如设备初始化代码等）通常都放在stage1且可以用汇编语言来实现</li><li>stage2：通常用C语言来实现，这样可以实现复杂的功能，而且有更好的可读性和移植性</li></ul><h3 id="MIPS基本地址空间"><a href="#MIPS基本地址空间" class="headerlink" title="MIPS基本地址空间"></a>MIPS基本地址空间</h3><p><img src="/../../images/OS/MIPS%E5%9F%BA%E6%9C%AC%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4.png" alt="MIPS基本地址空间"></p><ul><li>kuseg：用户态可用的地址,在有MMU的机器里,这些地址将一概被MMU作转换,除非MMU的设置被建立好,否则这2G的地址是不可用的</li><li>kseg0：将他们的最高位清零,即可映射到物理地址段512M(0x00000000 – 0x1fffffff).这种映射关系很简单,通常称之为”非转换的”地址区域,几乎全部对这段地址的存取都会通过cache,因此cache设置好之前,不能随便使用这段地址.</li><li>kseg1: 将这些地址的高三位清零可映射到相应的物理地址上,与kseg0映射的物理地址一样,但kseg1是非cache存取的. <strong>kseg1是唯一在系统重启时能正常工作的地址空间</strong></li><li>kseg2: 这块区域只能在核心态下使用并且要经过MMU的转换. 在MMU设置好之前,不要存取该区域. 除非在写一个真正的操作系统,否则没有理由用kseg2. 有时会看到该区域被分为kseg2和kseg3,意在强调低半部分(kseg2)可供运行在管理态的程序使用.</li></ul><h3 id="MIPS启动过程"><a href="#MIPS启动过程" class="headerlink" title="MIPS启动过程"></a>MIPS启动过程</h3><ol><li><p>start.S: 从_start开始执行</p><ul><li>初始化中断向量</li><li>寄存器清零</li><li>配置寄存器的CP0_STATUS, 设置所使用的协处理器，中断以及CPU运行级别（核心级）</li><li>配置gp寄存器</li></ul></li><li><p>lowlevel_init.S: 从lowlevel_init开始执行，工作频率配置（e.g: CPU主频、总线、DDR工作频率）</p></li><li><p>cache.S</p><ul><li>mips_cache_rest: 对cache进行初始化</li><li>mips_cache_lock: 设置堆栈</li></ul><p>由于此时ddr ram并没有配置好，而如果直接调用c语言的函数必须完成栈的设置，栈必定要在ram中。所以，只有先把一部分cache拿来当ram用。做法就是把一部分cache配置为栈的地址并锁定。这样，当读写栈的内存空间时，只会访问cache，而不会访问真的ram地址了</p></li></ol><p>第一阶段：三个汇编代码</p><hr><ol start="4"><li><p>board.c: </p><p>board_init_f</p><ul><li>time_init </li><li>env_init 环境变量初始化</li><li>init_baudrate 串口速率</li><li>serial_init  串口初始化</li><li>console_init_f 配置控制台</li><li>display_banner  显示U-boot启动信息，版本号等</li><li>init_func_ram 初始化内存，配置DDR controller</li></ul><p>board_init_r: 初始化flash、PCI以及外设（e.g: 网口），进入命令行直接启动Linux Kernel</p></li></ol><h2 id="MIPS下Linux系统引导过程"><a href="#MIPS下Linux系统引导过程" class="headerlink" title="MIPS下Linux系统引导过程"></a>MIPS下Linux系统引导过程</h2><p>BootLoader将Linux内核映像拷贝到RAM中</p><p>&#x2F;arch&#x2F;mips&#x2F;kernel&#x2F;head.s  kernel_entry(): 初始化内核堆栈段，为创建系统中的第一个进程进行准备，接着用另一段循环将内核映像的未初始化数据段清零，最后跳转到start_kernel()</p><p>&#x2F;init&#x2F;main.c  start_kernel(): 初始化硬件平台相关代码</p><h2 id="计算机的启动过程（x86"><a href="#计算机的启动过程（x86" class="headerlink" title="计算机的启动过程（x86)"></a>计算机的启动过程（x86)</h2><p><img src="/../../images/OS/x86%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B.png" alt="x86启动过程"></p><ol><li>加载BIOS   BIOS v.s. UEFI(统一可扩展固件接口)</li><li>读取MBR(主引导记录，即磁盘上第0磁头第0磁道第一个扇区)：启动代码及数据、分区表、幻数</li></ol><h2 id="x86下Linux系统引导过程"><a href="#x86下Linux系统引导过程" class="headerlink" title="x86下Linux系统引导过程"></a>x86下Linux系统引导过程</h2><ol start="3"><li>Boot Loader</li><li>加载内核</li><li>init进程执行</li><li>用户层init依据initab文件来设定运行等级</li><li>init进程执行rc.sysinit</li><li>启动内核模块</li><li>执行不同运行级别的脚本程序</li><li>执行&#x2F;etc&#x2F;rc.d&#x2F;rc.local(留给用户个性化的地方)</li><li>执行&#x2F;bin&#x2F;login程序，进入登录状态</li></ol><h1 id="虚拟机"><a href="#虚拟机" class="headerlink" title="虚拟机"></a>虚拟机</h1><table><thead><tr><th></th><th>第一类虚拟机</th><th>第二类虚拟机</th></tr></thead><tbody><tr><td>对物理资源的控制</td><td>直接运行在硬件之上，能直接控制和分配物理资源</td><td>运行在Host OS上，依赖于Host OS为其分配物理资源</td></tr><tr><td>资源分配方式</td><td>在安装Guest OS时，VMM要在原本的硬件上自行分配存储空间，类似于“外核”的分配方式，分配未经抽象的物理硬件</td><td>Guest OS拥有自己的虚拟磁盘，该盘实际上是Host OS文件系统中的一个大文件，Guest OS分配到的内存是虚拟内存</td></tr><tr><td>性能</td><td>好</td><td>差（需要Host OS作为中介）</td></tr><tr><td>可支持的虚拟机数量</td><td>更多（不需要和Host OS竞争资源，相同的硬件资源可以支持更多的虚拟机</td><td>更少（Host OS本身需要使用物理资源，Host OS上运行的其他进程也需要物理资源）</td></tr><tr><td>可迁移性</td><td>差</td><td>好</td></tr><tr><td>运行模式</td><td>运行在最高特权级（Ring 0），可以执行最高特权的指令</td><td>运行在用户态，部分运行在内核态， Guest OS发出的系统调用会被VMM截获，并转化为VMM对Host OS的系统调用</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>结构化机器学习项目</title>
      <link href="/2024/02/24/deeplearning/2024-02-24-jie-gou-hua-ji-qi-xue-xi-xiang-mu/"/>
      <url>/2024/02/24/deeplearning/2024-02-24-jie-gou-hua-ji-qi-xue-xi-xiang-mu/</url>
      
        <content type="html"><![CDATA[<h1 id="正交化"><a href="#正交化" class="headerlink" title="正交化"></a>正交化</h1><p>正交化是指每个参数只控制一个维度的效果</p><h1 id="单一数字评估标准"><a href="#单一数字评估标准" class="headerlink" title="单一数字评估标准"></a>单一数字评估标准</h1><p>评估分类器的一个合理方式：观察它的查准率(Precision)和查全率（Recall）</p><ul><li>查准率：衡量预测的准确性。如：分类器标记为猫的例子中，有多少真的是猫</li><li>查全率：衡量发现所有正例的能力。如：对于所有真猫图片，分类器正确识别出了多少百分比</li></ul><table><thead><tr><th></th><th>预测为正例</th><th>预测为负例</th></tr></thead><tbody><tr><td>实际为正例</td><td>TP</td><td>FP</td></tr><tr><td>实际为负例</td><td>FN</td><td>TN</td></tr></tbody></table><p>$$<br>Precision &#x3D; \frac{TP}{TP + FP} \<br>Recall &#x3D; \frac{TP}{TP + FN}<br>$$</p><p>两种指标都要顾及到，比较方法是F1分数，公式为$\frac{2}{\frac{1}{P}+\frac{1}{R}}$(越大越好)</p><h1 id="mAP-mean-Average-Precision-评价指标"><a href="#mAP-mean-Average-Precision-评价指标" class="headerlink" title="mAP(mean Average Precision)评价指标"></a>mAP(mean Average Precision)评价指标</h1><p>mAP是目标检测模型中常用的评价指标。</p><p>首先介绍一下交并比IoU(Intersection over union)的概念，它是用来度量预测边框与实际边框的重叠程度的。<br>$$<br>IoU &#x3D; \frac{预测边框与实际边框的交}{二者的并}<br>$$</p><p>tips:在训练时，常常依据候选区域和标定区域 的IoU值来确定正负样本。</p><ol><li><p>设置IoU阈值：在计算mAP之前，我们会先设置一个IoU（如0.5）阈值来判断预测是真阳性还是假阳性。</p></li><li><p>判断预测框的实际类别：对于一个预测框，与预测框所在图片里的所有标签框作比较，如果二者的IoU大于阈值，则认为该预测框为“实际为正例”，否则为“实际为负例”。</p><p>如果是多分类任务，则找与预测框预测的类别相同的所有标签框比较</p></li><li><p>判断预测框的预测类别：设置不同的置信度阈值，对于每一个置信度阈值，若预测框的置信度大于该阈值，说明预测结果可信，预测结果为正例；小于该阈值，说明预测结构不可信，预测结果为负例。</p></li><li><p>一般会将预测框先按置信度降序排序，所以可以按把每个预测框的置信度都取一遍来获得不同的置信度阈值。对于相同的Recall，Precision取最高的一个值，然后画出P-R曲线。</p></li><li><p>P-R曲线围成的面积就是平均精度（AP）。</p></li><li><p>把每个类别的AP都计算出来之后求它们的平均值，即可得到mAP。</p></li></ol><p>为何要使用AP&#x2F;mAP呢？因为我们通常希望模型的Precision和Recall值都很高，所有就需要把两个因素综合考虑。一种方法就是上节提到的F1分数，一种就是计算P-R曲线下的面积，越接近1越好。</p><h1 id="满足和优化指标"><a href="#满足和优化指标" class="headerlink" title="满足和优化指标"></a>满足和优化指标</h1><ul><li>优化指标optimizing metric:如准确率，越大越好</li><li>满足指标satisficing metric:如运行时间，只需小于100ms就算足够好，达到之后不在乎这个指标有多好</li></ul><p>一般来说，如果要考虑n个指标，有时候选择其中一个做为优化指标是合理的，然后剩下都是满足指标，只需满足设定的阈值就好。</p><h1 id="贝叶斯最优错误率：理论上限"><a href="#贝叶斯最优错误率：理论上限" class="headerlink" title="贝叶斯最优错误率：理论上限"></a>贝叶斯最优错误率：理论上限</h1><p>对于计算机视觉任务而言，常用人类水平的错误率估计或代替贝叶斯错误率&#x2F;贝叶斯最优错误率</p><p>$$可避免误差&#x3D;贝叶斯错误率（的估计）-训练错误率$$<br>如果想要提升机器学习系统的性能，建议关注训练错误率和贝叶斯错误率的距离（可避免误差）以及开发错误率和训练错误率的距离（方差），然后针对不同的问题采用不同的策略</p><p>解决可避免误差的常用方法：</p><ul><li>Train Bigger model</li><li>Train longer&#x2F;better optimization algorithms:momentum, RMSprop, Adam</li><li>NN archtecture &#x2F; hyperparameters search</li></ul><p>解决方差的常用方法:</p><ul><li>more data</li><li>rugularization: L2 dropout, data augmentation</li><li>NN archtecture &#x2F; hyperparameters search</li></ul><h1 id="进行错误分析-error-analysis"><a href="#进行错误分析-error-analysis" class="headerlink" title="进行错误分析(error analysis)"></a>进行错误分析(error analysis)</h1><p>找一组错误样本（可能是开发集或者测试集的），观察错误标记的样本，看看假阳性和假阴性，统计属于不同错误类型的错误数量。如此，可以知道哪些问题有改进的潜力</p><h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><p>任务A –&gt; 任务B</p><p>预训练    微调</p><p>注：</p><ul><li>任务A与任务B有同样的输入时(例如都是图像、都是音频)，迁移学习是有意义的</li><li>任务A比任务B的数据多得多时，迁移学习意义更大</li></ul><h1 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h1><p>同时开始学习，试图让单个神经网络做几件事情，并且希望这里每个任务都能帮到其他所有任务</p><h1 id="端到端的深度学习"><a href="#端到端的深度学习" class="headerlink" title="端到端的深度学习"></a>端到端的深度学习</h1><p>$$X \xrightarrow{直接映射} Y$$<br>注：需要足够多的数据</p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>改善深层神经网络</title>
      <link href="/2024/02/17/deeplearning/2024-02-17-gai-shan-shen-ceng-shen-jing-wang-luo/"/>
      <url>/2024/02/17/deeplearning/2024-02-17-gai-shan-shen-ceng-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习的实践方面"><a href="#深度学习的实践方面" class="headerlink" title="深度学习的实践方面"></a>深度学习的实践方面</h1><h2 id="训练集-验证集-测试集-Train-Dev-Test-set"><a href="#训练集-验证集-测试集-Train-Dev-Test-set" class="headerlink" title="训练集&#x2F;验证集&#x2F;测试集(Train&#x2F;Dev&#x2F;Test set)"></a>训练集&#x2F;验证集&#x2F;测试集(Train&#x2F;Dev&#x2F;Test set)</h2><table><thead><tr><th align="left"></th><th>Train</th><th>Dev</th><th>Test</th></tr></thead><tbody><tr><td align="left">小数量</td><td>70%</td><td></td><td>30%</td></tr><tr><td align="left">or</td><td>60%</td><td>20%</td><td>20%</td></tr><tr><td align="left">百万级数据样本</td><td>98%</td><td>1%</td><td>1%</td></tr><tr><td align="left">超过百万</td><td>99.5%</td><td>0.25%</td><td>0.25%</td></tr><tr><td align="left">or</td><td>99.5%</td><td>0.4%</td><td>0.1%</td></tr></tbody></table><h2 id="偏见与方差-bias-varience"><a href="#偏见与方差-bias-varience" class="headerlink" title="偏见与方差(bias&amp;varience)"></a>偏见与方差(bias&amp;varience)</h2><table><thead><tr><th align="left"></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td align="left">训练集错误率</td><td>1%</td><td>15%</td><td>15%</td><td>0.5%</td></tr><tr><td align="left">开发集错误率</td><td>11%</td><td>16%</td><td>30%</td><td>1%</td></tr><tr><td align="left"></td><td>high varience</td><td>high bias</td><td>high bias &amp; varience</td><td>low bias &amp; varience</td></tr><tr><td align="left"></td><td>过拟合overfitting</td><td>欠拟合unfitting</td><td>一些地方欠拟合，一些地方过拟合</td><td></td></tr></tbody></table><p>以上分析基于：human&#x3D;0% (optimal&#x2F;base error 理想误差&#x2F;基误差)</p><p>解决办法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">graph TD;</span><br><span class="line">    A[high bias]--&gt;B&#123;判断&#125;;</span><br><span class="line">    B--&gt;|no|C[high varience];</span><br><span class="line">    B--&gt;|yes|D[bigger network\n train longer\n NN architecture search];</span><br><span class="line">    D--&gt;A;</span><br><span class="line">    C--&gt;|no|E[Done];</span><br><span class="line">    C--&gt;|yes|F[more data\n regularization正则化\n NN architecture search];</span><br><span class="line">    F--&gt;A;</span><br></pre></td></tr></table></figure><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><h3 id="L2-regularization"><a href="#L2-regularization" class="headerlink" title="L2 regularization"></a>L2 regularization</h3><p>逻辑回归中：$J\left( {w,b} \right) &#x3D; \frac{1}{m}\sum\limits_{i &#x3D; 1}^m {L({\hat{y}^{(i)}},\mathop y\nolimits^{(i)} )} + \frac{\lambda}{2m}|w|^2$      $|w|^2&#x3D;\sum\limits_{j&#x3D;1}^{n_x}w_j^2&#x3D;w^Tw$</p><p>神经网络中：$J\left( {w^{[1]},b^{[1]}, …, w^{[l]},b^{[l]}} \right) &#x3D; \frac{1}{m}\sum\limits_{i &#x3D; 1}^m {L({\hat{y}^{(i)}},\mathop y\nolimits^{(i)} )} + \frac{\lambda}{2m}|w^{[l]}|^2$      $|w^{[l]}|^2&#x3D;\sum\limits_{i&#x3D;1}^{n^{[l-1]}}\sum\limits_{j&#x3D;1}^{n^{[l]}}{w_{ij}^{[l]}}^2$</p><p>用backprop计算dw的值：${\text{w}}^{[l]}: &#x3D; {\text{w}}^{[l]} - \partial (dw + \frac{\lambda }{m}{w^{[l]}}) &#x3D; (1 - \frac{\partial \lambda }{m}){w^{[l]}} - \partial dw$</p><p>正则化减少过拟合的原因：$\lambda$增大，新的${\text{w}}^{[l]}$减小，隐藏单元的影响减小，存在一个$\lambda$的中间值使得接近”just right”的中间状态</p><h3 id="随机失活正则化（Dropout-regularization-设置消除神经网络中节点的概率"><a href="#随机失活正则化（Dropout-regularization-设置消除神经网络中节点的概率" class="headerlink" title="随机失活正则化（Dropout regularization): 设置消除神经网络中节点的概率"></a>随机失活正则化（Dropout regularization): 设置消除神经网络中节点的概率</h3><p>在神经网络的训练过程中，随机地丢弃（屏蔽）一部分神经元的输出，即将它们的权重置为零。通过这种方式，可以防止神经网络过度依赖某些特征，从而提高模型的泛化能力和鲁棒性。Dropout技术通常应用于神经网络的隐藏层上，并按照一定的概率p随机失活部分节点，在后向传播时进行相应的参数更新</p><p>最常用的实施方法：反向随机失活</p><p>e.g.: 以一个三层随即网络为例</p><ol><li><p>定义向量d</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d3=np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep-prob</span><br></pre></td></tr></table></figure><p>keep-prop表示保留某个隐藏单元的概率</p></li></ol><h2 id="归一化输入（normalizing-inputs）-可以加速训练方法"><a href="#归一化输入（normalizing-inputs）-可以加速训练方法" class="headerlink" title="归一化输入（normalizing inputs）:可以加速训练方法"></a>归一化输入（normalizing inputs）:可以加速训练方法</h2><p>将所有图像的像素值缩放到一个特定的范围（通常是 [0, 1] 或 [-1, 1]）</p><p>step：</p><ol><li>零均值化：${M_j} &#x3D; \frac{1}{m}\sum\limits_{i &#x3D; 1}^m {x_j^{(i)}}$     $x_j:&#x3D;x_j-\mu _j$</li><li>归一化方差：${\sigma ^2} &#x3D; \frac{1}{m}{\sum\limits_{i &#x3D; 1}^m {({x^{(i)}})} ^2}$       ${x_j}: &#x3D; \frac{x_j}{\sigma }$</li></ol><h2 id="梯度消失和梯度爆炸"><a href="#梯度消失和梯度爆炸" class="headerlink" title="梯度消失和梯度爆炸"></a>梯度消失和梯度爆炸</h2><p>梯度爆炸：各层权重w都大于1，层数很大</p><p>梯度消失：各层权重w都小于1，层数很大</p><h2 id="神经网络的权重初始化"><a href="#神经网络的权重初始化" class="headerlink" title="神经网络的权重初始化"></a>神经网络的权重初始化</h2><p>${w^{[l]}} &#x3D; np.random.randn({n^{[l]}},{n^{[l - 1]}}.*np.sqrt(1&#x2F;{n^{[l - 1]}}))$</p><p>$n^{[l - 1]}$表示第l-1层神经元的数量；如果用的Relu激活函数，sqrt中的1改为2更好</p><h2 id="梯度检验：确保backprop正确实施"><a href="#梯度检验：确保backprop正确实施" class="headerlink" title="梯度检验：确保backprop正确实施"></a>梯度检验：确保backprop正确实施</h2><p>${\theta _{\text{i}}} &#x3D; (w_i^{[1]},b_i^{[1]},…,w_i^{[l]},b_i^{[l]})$连接成一个超大向量</p><p>$d{\theta _{approx[i]}} &#x3D; \frac{J({\theta _1},{\theta _2},…,{\theta _i} + \epsilon ,..) - J({\theta _1},{\theta _2},…,{\theta _i} - \epsilon ,..)}{2\epsilon }$验证是否逼近$d{\theta _{[i]}} &#x3D; \frac{\partial J}{\partial {\theta _i}}$</p><p>验证方法：计算两个向量的欧式距离$\frac{||d{\theta _{approx[i]} - d{\theta _{[i]}}||{^2}}}{||d{\theta _{approx[i]}}||{^2} + ||d{\theta _{[i]}}||{^2}}$,$\leqslant {10^{ - 7}}$没问题，$\approx {10^{ - 5}}$可能有问题&#x2F;bug，$\approx {10^{ - 3}}$有问题</p><p>注：</p><ol><li>不要在训练中使用grad check，它只用于调试</li><li>如果算法的梯度检验失败，要检查所有项，并试着找出bug，注意$\theta$的各项与b、w的各项都是一一对应的</li><li>在实施梯度检验时，如果使用正则化，请注意正则项</li><li>梯度检验不与dropout同时使用</li><li>现实中不会在随机初始化时运行梯度检验</li></ol><h1 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h1><h2 id="Mini-batch梯度下降法"><a href="#Mini-batch梯度下降法" class="headerlink" title="Mini-batch梯度下降法"></a>Mini-batch梯度下降法</h2><p>将整个训练样本分成若干份（mini-batch），然后迭代。</p><p>假设训练样本m个，分成n份，一次遍历训练集，可以做n次梯度梯度下降</p><ul><li>m&lt;2000时，直接batch gradient descent(就是之前讲的常规梯度下降法)</li><li>m很大时，建议分成$2^n$倍（跟电脑内存存储方式有关）</li></ul><h2 id="指数加权平均（Exponentially-weighted-averages）-统计学中称为指数加权移动平均"><a href="#指数加权平均（Exponentially-weighted-averages）-统计学中称为指数加权移动平均" class="headerlink" title="指数加权平均（Exponentially weighted averages）(统计学中称为指数加权移动平均)"></a>指数加权平均（Exponentially weighted averages）(统计学中称为指数加权移动平均)</h2><p>关键公式：${v_t} &#x3D; \beta {v_{t - 1}} + (1 - \beta ){\theta _t}$</p><p>其中$\theta_t$是实际值，整个式子可以看成$v_t$是$\frac{1}{1-\beta}$个数据的平均值</p><p>指数加权平均的偏差修正（bias correction）在预估初期，不用$v_t$，而用$\frac{v_t}{1-\beta^t}$</p><h2 id="动量梯度下降法（Gradient-descent-with-momentum）"><a href="#动量梯度下降法（Gradient-descent-with-momentum）" class="headerlink" title="动量梯度下降法（Gradient descent  with momentum）"></a>动量梯度下降法（Gradient descent  with momentum）</h2><p>基本想法：计算梯度的指数加权平均数，并利用该梯度更新权值</p><p>$$\left{ \begin{gathered}<br>  {v_{dw}} &#x3D; \beta {v_{dw}} + (1 - \beta )dw \hfill \<br>  {v_{db}} &#x3D; \beta {v_{db}} + (1 - \beta )db \hfill \<br>\end{gathered}  \right.$$</p><p>$$\left{ \begin{gathered}<br>  w: &#x3D; w - \partial {v_{dw}} \hfill \<br>  b: &#x3D; b - \partial {v_{db}} \hfill \<br>\end{gathered}  \right.$$</p><h2 id="RMSprop算法（RMS：root-mean-square均方根，标准差）"><a href="#RMSprop算法（RMS：root-mean-square均方根，标准差）" class="headerlink" title="RMSprop算法（RMS：root  mean  square均方根，标准差）"></a>RMSprop算法（RMS：root  mean  square均方根，标准差）</h2><p>$$\left{ \begin{gathered}<br>  {S_{dw}} &#x3D; \beta {S_{dw}} + (1 - \beta )(dw)^2 \hfill \<br>  {S_{db}} &#x3D; \beta {S_{db}} + (1 - \beta )(db)^2 \hfill \<br>\end{gathered}  \right.$$</p><p>$$\left{ \begin{gathered}<br>  w: &#x3D; w - \partial \frac{dw}{\sqrt {S_{dw}} } \hfill \<br>  b: &#x3D; b - \partial \frac{db}{\sqrt {S_{db}} } \hfill \<br>\end{gathered}  \right.$$</p><p>原理：<br><img src="/../../images/RMSprop%E7%AE%97%E6%B3%95%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt="RMSprop算法示意图"></p><p>我们希望在横轴（w方向）学习速度快，纵轴（b方向）减缓摆动，所有有了$S_{dw}$,、$S_{db}$，w要除以一个较小的数（$S_{dw}$相对较小），b要除以一个相对较大的数（$S_{db}$较大）。</p><h2 id="Adam优化算法（Momentum和RMSprop的结合）"><a href="#Adam优化算法（Momentum和RMSprop的结合）" class="headerlink" title="Adam优化算法（Momentum和RMSprop的结合）"></a>Adam优化算法（Momentum和RMSprop的结合）</h2><p>步骤：</p><ol><li><p>初始化：$v_{dw}&#x3D;0$ $S_{dw}&#x3D;0$ $v_{db}&#x3D;0$ $S_{db}&#x3D;0$</p></li><li><p>计算Momentum指数加权平均数：</p><p>$$\left{ \begin{gathered}<br>  {v_{dw}} &#x3D; \beta_1 {v_{dw}} + (1 - \beta_1 )dw \hfill \<br>  {v_{db}} &#x3D; \beta_1 {v_{db}} + (1 - \beta_1 )db \hfill \<br>\end{gathered}  \right.$$</p></li><li><p>使用RMSprop进行更新</p><p>$$\left{ \begin{gathered}<br>  {S_{dw}} &#x3D; \beta_2 {S_{dw}} + (1 - \beta_2 )(dw)^2 \hfill \<br>  {S_{db}} &#x3D; \beta_2 {S_{db}} + (1 - \beta_2 )(db)^2 \hfill \<br>\end{gathered}  \right.$$</p></li><li><p>使用Adam算法，一般要计算偏差修正</p><p>$v_{dw}^{corrected} &#x3D; \frac{v_{dw}}{1 - \beta _1^t}$</p><p>$v_{db}^{corrected} &#x3D; \frac{v_{db}}{1 - \beta _1^t}$</p><p>$S_{dw}^{corrected} &#x3D; \frac{S_{dw}}{1 - \beta _2^t}$ </p><p>$S_{db}^{corrected} &#x3D; \frac{S_{db}}{1 - \beta _2^t}$</p></li><li><p>更新权重</p><p>$$\left{ \begin{gathered}<br>  w: &#x3D; w - \partial \frac{v_{dw}^{corrected}}{\sqrt {S_{dw}^{corrected}} + \epsilon } \hfill \<br>  b: &#x3D; b - \partial \frac{v_{db}^{corrected}}{\sqrt {S_{db}^{corrected}} + \epsilon } \hfill \<br>\end{gathered}  \right.$$</p></li></ol><h2 id="学习率衰减（learning-rate-decay）"><a href="#学习率衰减（learning-rate-decay）" class="headerlink" title="学习率衰减（learning rate decay）"></a>学习率衰减（learning rate decay）</h2><p>加快学习算法的一个办法是随时间慢慢减少学习率</p><p>$\partial  &#x3D; \frac{1}{1 + decayrate \cdot epoch - num}{\partial _0}$，epoch-num是训练的代数</p><p>$\partial  &#x3D; {0.95^{epoch - num}}{\partial _0}$</p><p>$\partial  &#x3D; \frac{k}{\sqrt {epoch - num} }{\partial _0}$</p><p>$\partial  &#x3D; \frac{k}{\sqrt t }{\partial _0}$</p><h2 id="局部最优问题"><a href="#局部最优问题" class="headerlink" title="局部最优问题"></a>局部最优问题</h2><p><img src="/../../images/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E9%97%AE%E9%A2%98.jpg" alt="局部最优问题"></p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>神经网络基础知识</title>
      <link href="/2024/02/10/deeplearning/2024-02-10-nn-basic-kowledge/"/>
      <url>/2024/02/10/deeplearning/2024-02-10-nn-basic-kowledge/</url>
      
        <content type="html"><![CDATA[<h1 id="概念区分"><a href="#概念区分" class="headerlink" title="概念区分"></a>概念区分</h1><p>机器学习&gt;神经网络&gt;深度学习&#x3D;深度神经网络</p><p>机器学习</p><ul><li>神经网络<ul><li>浅层神经网络</li><li>深层神经网络&#x2F;深度学习：一种机器学习算法，“深度”指的是神经网络中的层次很深。</li></ul></li><li>逻辑回归：没有隐含层的神经网络</li><li>……</li></ul><h1 id="标注习惯"><a href="#标注习惯" class="headerlink" title="标注习惯"></a>标注习惯</h1><ul><li>上角小括号：训练集里的值</li><li>上角中括号：神经网络的层数</li><li>大括号：不同的mini-batch</li></ul><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h2 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h2><p>$z&#x3D;w^{T}x+b$</p><p>激活函数：$a &#x3D; \hat{y} &#x3D; \sigma (z)$</p><p>损失函数(衡量在单个训练样本上的表现)：</p><p>$L(\hat y, y) &#x3D; -ylog\hat y - (1-y)log(1-\hat{y})$</p><p>成本函数(衡量在全体训练样本上的表现)：$J\left( {w,b} \right) &#x3D; \frac{1}{m}\sum\limits_{i &#x3D; 1}^m {L({\hat{y}^{(i)}},\mathop y\nolimits^{(i)} )}$</p><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>梯度下降算法：</p><p>$$da &#x3D; \frac{\partial L}{\partial a} &#x3D;  - \frac{y}{a} + \frac{1 - y}{1 - a}$$</p><p>$$dz &#x3D; \frac{\partial L}{\partial z} &#x3D; \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial z} &#x3D; ( - \frac{y}{a} + \frac{1 - y}{1 - a}) \cdot a \cdot (1 - a) &#x3D; a - y$$</p><p>$$\left{ {\begin{array}{l}<br>{d\mathop w\nolimits_1  &#x3D; \frac{\partial L}{\partial \mathop w\nolimits_1 } &#x3D; \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial \mathop w\nolimits_1 } &#x3D; \mathop x\nolimits_1  \cdot (a - y)}\<br>{d\mathop w\nolimits_2  &#x3D; \frac{\partial L}{\partial \mathop w\nolimits_2 } &#x3D; \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial \mathop w\nolimits_2 } &#x3D; \mathop x\nolimits_2  \cdot (a - y)}\<br>{db &#x3D; \frac{\partial L}{\partial b} &#x3D; a - y}<br>\end{array}} \right.$$</p><p>更新：<br>$$\left{ {\begin{array}{l}<br>{\mathop w\nolimits_1 : &#x3D; \mathop w\nolimits_1  - \partial  \cdot d\mathop w\nolimits_1 }\<br>{\mathop w\nolimits_2 : &#x3D; \mathop w\nolimits_2  - \partial  \cdot d\mathop w\nolimits_2 }\<br>{b: &#x3D; b - \partial  \cdot db}<br>\end{array}} \right.$$</p><p>m个样本的梯度下降：<br>$$\left{ {\begin{array}{l}<br>{d{\rm{ }}{w_1} &#x3D; \frac{\rm{1}}{\rm{m}}\sum\limits_{i &#x3D; 1}^m {x_1^{(i)} \cdot ({a^{(i)}} - {y^{(i)}})} {\rm{ }}}\<br>{d{\rm{ }}{w_2} &#x3D; \frac{\rm{1}}{\rm{m}}\sum\limits_{i &#x3D; 1}^m {x_2^{(i)} \cdot ({a^{(i)}} - {y^{(i)}})} {\rm{ }}}\<br>{db &#x3D; \frac{\partial L}{\partial b} &#x3D; \frac{\rm{1}}{\rm{m}}\sum\limits_{i &#x3D; 1}^m {({a^{(i)}} - {y^{(i)}})} }<br>\end{array}} \right.$$</p><p>深层网络的向前传播：<br>$$z^{[l]}&#x3D;w^{[l]}a^{[l]-1}+b^{[l]}$$<br>$$a^{[l]} &#x3D;  \sigma (z^{[l]})$$</p><h2 id="常见激活函数"><a href="#常见激活函数" class="headerlink" title="常见激活函数"></a>常见激活函数</h2><h3 id="sigmiod函数"><a href="#sigmiod函数" class="headerlink" title="sigmiod函数"></a>sigmiod函数</h3><p>$$<br>f(x) &#x3D; \frac{1}{1 + e^{-x}}<br>$$</p><p>使用范围：常用于二分类问题。被广泛地使用在输出单元&#x2F;最后一层上，在隐藏层使用较少。</p><p>输出特点：值在0和1之间。</p><p>具有平滑性、可导性、单调性等良好的性质，使用sigmod激活函数的神经网络可以学习到非线性的特征，提高模型的拟合能力。</p><p>存在输出值偏置的问题，当输入值很大或很小时，函数的斜率会趋近于0，导致梯度消失，使得神经网络难以进行有效的学习。</p><h3 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h3><p>$$<br>S_i &#x3D; \frac{e^i}{\sum_j e^j}<br>$$<br>使用范围：多分类问题。用在输出单元。</p><p>输出特点：每一项的区间范围是(0, 1)，所有项相加的和为1。</p><h3 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h3><p>$$<br>tanh(x) &#x3D; \frac{1 - e^{-2x}}{1 + e^{-2x}}<br>$$</p><h3 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h3><p>$$<br>ReLU(x) &#x3D; max(x, 0)<br>$$<br>使用范围：当搭建的神经网络层数较多时，此时不宜选择sigmoid、tanh函数，应选用ReLU。</p><p>ReLU函数的求导表现得很好，要么让参数消失，要么让参数通过。ReLU减轻了神经网络的梯度消失问题。</p><h2 id="常见损失函数"><a href="#常见损失函数" class="headerlink" title="常见损失函数"></a>常见损失函数</h2><h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><p>$$<br>L(\hat y, y) &#x3D; -ylog\hat y - (1-y)log(1-\hat{y})<br>$$</p><h3 id="均方差"><a href="#均方差" class="headerlink" title="均方差"></a>均方差</h3><p>$$<br>MSE &#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} (y_i - \hat{y}_i)^2<br>$$</p>]]></content>
      
      
      <categories>
          
          <category> deepLearning </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
